{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The version of TensorFlow is 1.4.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from os import listdir\n",
    "from sklearn.model_selection import train_test_split\n",
    "print ('The version of TensorFlow is {}'.format(tf.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from ASRS database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = './data'\n",
    "\n",
    "appended_data = []\n",
    "for file_name in listdir(root_path):\n",
    "    file_path = root_path + '/' + file_name.encode().decode('utf-8')\n",
    "    data_from_one_csv = pd.read_csv(file_path, skiprows=1)\n",
    "    appended_data.append(data_from_one_csv)\n",
    "    \n",
    "data = pd.concat(appended_data, axis=0)\n",
    "data = data.drop(columns = ['ACN', 'Date', 'Local Time Of Day', 'Ceiling', 'Callback', 'Callback.1', 'Unnamed: 96'])\n",
    "data = data.rename(index=str, columns={\"Flight Phase\": \"Flight Phase1\"})\n",
    "\n",
    "X = data.drop(columns = 'Result')\n",
    "Y_raw = pd.DataFrame(data['Result'])\n",
    "\n",
    "processed_Y = []\n",
    "for index, row in Y_raw.iterrows():\n",
    "    #print (index, row['Result'])\n",
    "    outcome = row['Result']\n",
    "    if type(outcome) == np.float:\n",
    "        res = 'unknown'\n",
    "        processed_Y.append(res)\n",
    "    elif ';' in outcome:\n",
    "        res = str(outcome).split(';')[0]\n",
    "        processed_Y.append(res)\n",
    "    else:\n",
    "        res = outcome\n",
    "        processed_Y.append(res)\n",
    "\n",
    "Y = pd.DataFrame(processed_Y, columns = ['Result'])\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "#~~~~~~~~~~~~~~~~ Single file process ~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# file_name = 'ASRS_DBOnline.csv'\n",
    "# data = pd.read_csv(file_name)\n",
    "# data = data.drop(columns = ['ACN', 'Date', 'Local Time Of Day', 'Ceiling', 'Callback', 'Callback.1'])\n",
    "# X = data.drop(columns = 'Result')\n",
    "# Y = data['Result']\n",
    "\n",
    "# for i in range(Y.shape[0]):\n",
    "#     if ';' in str(Y[i]):\n",
    "#         Y.set_value(i, Y[i].split(';')[0])\n",
    "#     elif Y[i] is np.nan:\n",
    "#         Y.set_value(i, 'unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X['Crew Size'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\sklearn\\preprocessing\\label.py:111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "Y = pd.DataFrame(le.fit_transform(Y), index = X.index)\n",
    "        \n",
    "n_classes = int(Y.max()[0]) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Locale_Reference', 'State_Reference', 'Relative_Position.Angle.Radial',\n",
       "       'Relative_Position.Distance.Nautical_Miles',\n",
       "       'Altitude.AGL.Single_Value', 'Altitude.MSL.Single_Value',\n",
       "       'Flight_Conditions', 'Weather_Elements_Visibility',\n",
       "       'Work_Environment_Factor', 'Light', 'RVR.Single_Value', 'ATC_Advisory',\n",
       "       'Aircraft_Operator', 'Make_Model_Name', 'Aircraft_Zone', 'Crew_Size',\n",
       "       'Operating_Under_FAR_Part', 'Flight_Plan', 'Mission', 'Nav_In_Use',\n",
       "       'Flight_Phase1', 'Route_In_Use', 'Airspace',\n",
       "       'Maintenance_Status.Maintenance_Deferred',\n",
       "       'Maintenance_Status.Records_Complete',\n",
       "       'Maintenance_Status.Released_For_Service',\n",
       "       'Maintenance_Status.Required_Correct_Doc_On_Board',\n",
       "       'Maintenance_Status.Maintenance_Type',\n",
       "       'Maintenance_Status.Maintenance_Items_Involved', 'Cabin_Lighting',\n",
       "       'Number_Of_Seats.Number', 'Passengers_On_Board.Number',\n",
       "       'Crew_Size_Flight_Attendant.Number_Of_Crew', 'Aircraft_Component',\n",
       "       'Manufacturer', 'Aircraft_Reference', 'Problem', 'ATC_Advisory.1',\n",
       "       'Aircraft_Operator.1', 'Make_Model_Name.1', 'Aircraft_Zone.1',\n",
       "       'Crew_Size.1', 'Operating_Under_FAR_Part.1', 'Flight_Plan.1',\n",
       "       'Mission.1', 'Nav_In_Use.1', 'Flight_Phase.1', 'Route_In_Use.1',\n",
       "       'Airspace.1', 'Maintenance_Status.Maintenance_Deferred.1',\n",
       "       'Maintenance_Status.Records_Complete.1',\n",
       "       'Maintenance_Status.Released_For_Service.1',\n",
       "       'Maintenance_Status.Required_Correct_Doc_On_Board.1',\n",
       "       'Maintenance_Status.Maintenance_Type.1',\n",
       "       'Maintenance_Status.Maintenance_Items_Involved.1', 'Cabin_Lighting.1',\n",
       "       'Number_Of_Seats.Number.1', 'Passengers_On_Board.Number.1',\n",
       "       'Crew_Size_Flight_Attendant.Number_Of_Crew.1', 'Location_Of_Person',\n",
       "       'Location_In_Aircraft', 'Reporter_Organization', 'Function',\n",
       "       'Qualification', 'Experience', 'Cabin_Activity', 'Human_Factors',\n",
       "       'Communication_Breakdown', 'ASRS_Report_Number.Accession_Number',\n",
       "       'Location_Of_Person.1', 'Location_In_Aircraft.1',\n",
       "       'Reporter_Organization.1', 'Function.1', 'Qualification.1',\n",
       "       'Experience.1', 'Cabin_Activity.1', 'Human_Factors.1',\n",
       "       'Communication_Breakdown.1', 'ASRS_Report_Number.Accession_Number.1',\n",
       "       'Anomaly', 'Miss_Distance', 'Were_Passengers_Involved_In_Event',\n",
       "       'Detector', 'When_Detected', 'Contributing_Factors_Situations',\n",
       "       'Primary_Problem', 'Narrative', 'Narrative.1', 'Synopsis'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## change column names\n",
    "new_col_name = []\n",
    "for col in X.columns:\n",
    "    #print(type(col))\n",
    "    new_col_name.append(col.replace('/ ', '').replace(' ', '_'))\n",
    "    \n",
    "X.columns = new_col_name\n",
    "\n",
    "## output the headers from the csv file\n",
    "X.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output the data types of all the items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "The unique data types across all the items are: {<class 'numpy.float64'>, <class 'float'>, <class 'str'>}\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "data_type = []\n",
    "for item_name in X.keys():\n",
    "    data_type.append(type(X[item_name][0]))\n",
    "\n",
    "print ('\\n')\n",
    "print ('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "print ('The unique data types across all the items are:', set(data_type))\n",
    "print ('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count the number of missing values in each attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2.0\n",
       "1    2.0\n",
       "2    2.0\n",
       "3    2.0\n",
       "4    2.0\n",
       "Name: Crew_Size, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for item_name in X.keys():\n",
    "    ## find the number of NaN in this item\n",
    "    no = np.sum(X[item_name].isna().astype(int))\n",
    "    #print ('The number of {} with value equal to NaN is {}'.format(item_name, no))\n",
    "    \n",
    "    ## Replace the missing value with corresponding values\n",
    "    if no > 0:\n",
    "        if type(X[item_name][0]) == np.float64:\n",
    "            X[item_name].fillna(-1, inplace = True)\n",
    "        else:\n",
    "            X[item_name].fillna('unknown', inplace = True)\n",
    "X['Crew_Size'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Location\n",
    "Locale_Reference = tf.feature_column.categorical_column_with_hash_bucket('Locale_Reference', \n",
    "                                                                         hash_bucket_size = len(set(X['Locale_Reference'])))\n",
    "State_Reference = tf.feature_column.categorical_column_with_hash_bucket('State_Reference', \n",
    "                                                                        hash_bucket_size = len(set(X['State_Reference'])))\n",
    "\n",
    "\n",
    "## Environment\n",
    "Flight_Conditions = tf.feature_column.categorical_column_with_hash_bucket('Flight_Conditions', \n",
    "                                                                hash_bucket_size = len(set(X['State_Reference'])))\n",
    "Weather_Elements_Visibility = tf.feature_column.categorical_column_with_hash_bucket('Weather_Elements_Visibility', \n",
    "                                                            hash_bucket_size = len(set(X['Weather_Elements_Visibility'])))\n",
    "Work_Environment_Factor = tf.feature_column.categorical_column_with_hash_bucket('Work_Environment_Factor', \n",
    "                                                            hash_bucket_size = len(set(X['Work_Environment_Factor'])))\n",
    "Light = tf.feature_column.categorical_column_with_hash_bucket('Light', hash_bucket_size = len(set(X['Work_Environment_Factor'])))\n",
    "\n",
    "\n",
    "## Aircraft\n",
    "ATC_Advisory = tf.feature_column.categorical_column_with_hash_bucket('ATC_Advisory', \n",
    "                                                            hash_bucket_size = len(set(X['ATC_Advisory'])))\n",
    "Aircraft_Operator = tf.feature_column.categorical_column_with_hash_bucket('Aircraft_Operator', \n",
    "                                                                hash_bucket_size = len(set(X['Aircraft_Operator'])))\n",
    "Make_Model_Name = tf.feature_column.categorical_column_with_hash_bucket('Make_Model_Name', \n",
    "                                                            hash_bucket_size = len(set(X['Make_Model_Name'])))\n",
    "Crew_Size = tf.feature_column.numeric_column('Crew_Size', [1])\n",
    "Flight_Plan = tf.feature_column.categorical_column_with_hash_bucket('Flight_Plan', \n",
    "                                                            hash_bucket_size = len(set(X['Flight_Plan'])))\n",
    "Mission = tf.feature_column.categorical_column_with_hash_bucket('Mission', \n",
    "                                                                hash_bucket_size = len(set(X['Mission'])))\n",
    "Flight_Phase1 = tf.feature_column.categorical_column_with_hash_bucket('Flight_Phase1', \n",
    "                                                                      hash_bucket_size = len(set(X['Flight_Phase1'])))\n",
    "Route_In_Use = tf.feature_column.categorical_column_with_hash_bucket('Route_In_Use', \n",
    "                                                                     hash_bucket_size = len(set(X['Route_In_Use'])))\n",
    "Airspace = tf.feature_column.categorical_column_with_hash_bucket('Airspace', \n",
    "                                                                 hash_bucket_size = len(set(X['Airspace'])))\n",
    "\n",
    "## Component\n",
    "Aircraft_Component = tf.feature_column.categorical_column_with_hash_bucket('Aircraft_Component', \n",
    "                                                             hash_bucket_size = len(set(X['Aircraft_Component'])))\n",
    "Manufacturer = tf.feature_column.categorical_column_with_hash_bucket('Manufacturer', \n",
    "                                                        hash_bucket_size = len(set(X['Manufacturer'])))\n",
    "\n",
    "## Person\n",
    "Location_Of_Person = tf.feature_column.categorical_column_with_hash_bucket('Location_Of_Person', \n",
    "                                                                hash_bucket_size = len(set(X['Location_Of_Person'])))\n",
    "Location_In_Aircraft = tf.feature_column.categorical_column_with_hash_bucket('Location_In_Aircraft',\n",
    "                                                            hash_bucket_size = len(set(X['Location_In_Aircraft'])))\n",
    "Reporter_Organization = tf.feature_column.categorical_column_with_hash_bucket('Reporter_Organization',\n",
    "                                                            hash_bucket_size = len(set(X['Reporter_Organization'])))\n",
    "Function = tf.feature_column.categorical_column_with_hash_bucket('Function', hash_bucket_size = len(set(X['Function'])))\n",
    "Qualification = tf.feature_column.categorical_column_with_hash_bucket('Qualification', \n",
    "                                                                      hash_bucket_size = len(set(X['Qualification'])))\n",
    "Human_Factors = tf.feature_column.categorical_column_with_hash_bucket('Human_Factors', \n",
    "                                                                      hash_bucket_size = len(set(X['Human_Factors'])))\n",
    "\n",
    "## Events\n",
    "Anomaly = tf.feature_column.categorical_column_with_hash_bucket('Anomaly', \n",
    "                                                                hash_bucket_size = len(set(X['Anomaly'])))\n",
    "Detector = tf.feature_column.categorical_column_with_hash_bucket('Detector', \n",
    "                                                                 hash_bucket_size = len(set(X['Detector'])))\n",
    "When_Detected = tf.feature_column.categorical_column_with_hash_bucket('When_Detected', \n",
    "                                                                      hash_bucket_size = len(set(X['When_Detected'])))\n",
    "Were_Passengers_Involved_In_Event = tf.feature_column.categorical_column_with_hash_bucket('Were_Passengers_Involved_In_Event',\n",
    "                                                    hash_bucket_size = len(set(X['Were_Passengers_Involved_In_Event'])))\n",
    "\n",
    "## Assessments\n",
    "Contributing_Factors_Situations = tf.feature_column.categorical_column_with_hash_bucket('Contributing_Factors_Situations', \n",
    "                                                   hash_bucket_size = len(set(X['Contributing_Factors_Situations'])))\n",
    "Primary_Problem = tf.feature_column.categorical_column_with_hash_bucket('Primary_Problem', \n",
    "                                                        hash_bucket_size = len(set(X['Primary_Problem'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Place\n",
    "Locale_Reference = tf.feature_column.embedding_column(Locale_Reference, len(set(X['Locale_Reference'])))\n",
    "State_Reference = tf.feature_column.embedding_column(State_Reference, len(set(X['State_Reference'])))\n",
    "\n",
    "\n",
    "## Environment\n",
    "Flight_Conditions = tf.feature_column.embedding_column(Flight_Conditions,  len(set(X['Flight_Conditions'])))\n",
    "Weather_Elements_Visibility = tf.feature_column.embedding_column(Weather_Elements_Visibility,  \n",
    "                                                                 len(set(X['Weather_Elements_Visibility'])))\n",
    "Work_Environment_Factor = tf.feature_column.embedding_column(Work_Environment_Factor,  len(set(X['Work_Environment_Factor'])))\n",
    "Light = tf.feature_column.embedding_column(Light, len(set(X['Light'])))\n",
    "\n",
    "\n",
    "## Aircraft\n",
    "ATC_Advisory = tf.feature_column.embedding_column(ATC_Advisory, len(set(X['ATC_Advisory'])))\n",
    "Aircraft_Operator = tf.feature_column.embedding_column(Aircraft_Operator, len(set(X['Aircraft_Operator'])))\n",
    "Make_Model_Name = tf.feature_column.embedding_column(Make_Model_Name, len(set(X['Make_Model_Name'])))\n",
    "Flight_Plan = tf.feature_column.embedding_column(Flight_Plan, len(set(X['Flight_Plan'])))\n",
    "Mission = tf.feature_column.embedding_column(Mission, len(set(X['Mission'])))\n",
    "Flight_Phase1 = tf.feature_column.embedding_column(Flight_Phase1, len(set(X['Flight_Phase1'])))\n",
    "Route_In_Use = tf.feature_column.embedding_column(Route_In_Use, len(set(X['Route_In_Use'])))\n",
    "Airspace = tf.feature_column.embedding_column(Airspace, len(set(X['Airspace'])))\n",
    "\n",
    "## Component\n",
    "Aircraft_Component = tf.feature_column.embedding_column(Aircraft_Component, len(set(X['Aircraft_Component'])))\n",
    "Manufacturer = tf.feature_column.embedding_column(Manufacturer, len(set(X['Manufacturer'])))\n",
    "\n",
    "## Person\n",
    "Location_Of_Person = tf.feature_column.embedding_column(Location_Of_Person, len(set(X['Location_Of_Person'])))\n",
    "Location_In_Aircraft = tf.feature_column.embedding_column(Location_In_Aircraft, len(set(X['Location_In_Aircraft'])))\n",
    "Reporter_Organization = tf.feature_column.embedding_column(Reporter_Organization, len(set(X['Reporter_Organization'])))\n",
    "Function = tf.feature_column.embedding_column(Function, len(set(X['Function'])))\n",
    "Qualification = tf.feature_column.embedding_column(Qualification, len(set(X['Qualification'])))\n",
    "Human_Factors = tf.feature_column.embedding_column(Human_Factors, len(set(X['Human_Factors'])))\n",
    "\n",
    "## Events\n",
    "Anomaly = tf.feature_column.embedding_column(Anomaly, len(set(X['Anomaly'])))\n",
    "Detector = tf.feature_column.embedding_column(Detector, len(set(X['Detector'])))\n",
    "When_Detected = tf.feature_column.embedding_column(When_Detected, len(set(X['When_Detected'])))\n",
    "Were_Passengers_Involved_In_Event = tf.feature_column.embedding_column(Were_Passengers_Involved_In_Event,\n",
    "                                                                       len(set(X['Were_Passengers_Involved_In_Event'])))\n",
    "\n",
    "## Assessments\n",
    "Contributing_Factors_Situations = tf.feature_column.embedding_column(Contributing_Factors_Situations,\n",
    "                                                                     len(set(X['Contributing_Factors_Situations'])))\n",
    "Primary_Problem = tf.feature_column.embedding_column(Primary_Problem, len(set(X['Primary_Problem'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a neural network-based learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_sub = X[['Locale_Reference', 'State_Reference', 'Flight_Conditions', 'Weather_Elements_Visibility', \n",
    "            'Work_Environment_Factor', 'Light', 'ATC_Advisory', 'Aircraft_Operator', 'Make_Model_Name', \n",
    "            'Crew_Size', 'Flight_Plan', 'Mission', 'Flight_Phase1',\n",
    "            'Route_In_Use','Airspace', 'Aircraft_Component', 'Manufacturer', 'Location_Of_Person', 'Location_In_Aircraft',\n",
    "            'Reporter_Organization', 'Function', 'Qualification', 'Human_Factors', 'Anomaly', 'Detector', 'When_Detected',\n",
    "            'Were_Passengers_Involved_In_Event', 'Contributing_Factors_Situations', 'Primary_Problem' ]]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_sub, Y, test_size = 0.2, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp2ylss52e\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\ZHANGX~1\\\\AppData\\\\Local\\\\Temp\\\\tmp2ylss52e', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000026249CCCC88>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp2ylss52e\\model.ckpt.\n",
      "INFO:tensorflow:loss = 1791.4792, step = 1\n",
      "INFO:tensorflow:global_step/sec: 0.610393\n",
      "INFO:tensorflow:loss = 1067.7871, step = 101 (163.878 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.595327\n",
      "INFO:tensorflow:loss = 993.65, step = 201 (168.021 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.607531\n",
      "INFO:tensorflow:loss = 790.58813, step = 301 (164.573 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 354 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp2ylss52e\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.514993\n",
      "INFO:tensorflow:loss = 808.1138, step = 401 (194.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.59681\n",
      "INFO:tensorflow:loss = 701.25055, step = 501 (167.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.603774\n",
      "INFO:tensorflow:loss = 635.5126, step = 601 (165.773 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 698 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp2ylss52e\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.552132\n",
      "INFO:tensorflow:loss = 534.1996, step = 701 (180.929 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.608575\n",
      "INFO:tensorflow:loss = 557.3124, step = 801 (164.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.621705\n",
      "INFO:tensorflow:loss = 571.9858, step = 901 (160.856 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.608545\n",
      "INFO:tensorflow:loss = 456.62543, step = 1001 (164.325 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1057 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp2ylss52e\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.559177\n",
      "INFO:tensorflow:loss = 464.08972, step = 1101 (178.828 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.620744\n",
      "INFO:tensorflow:loss = 434.44623, step = 1201 (161.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.616816\n",
      "INFO:tensorflow:loss = 339.2378, step = 1301 (162.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.612165\n",
      "INFO:tensorflow:loss = 424.97046, step = 1401 (163.339 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1417 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp2ylss52e\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.542831\n",
      "INFO:tensorflow:loss = 380.35602, step = 1501 (184.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.600908\n",
      "INFO:tensorflow:loss = 342.22076, step = 1601 (166.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.601528\n",
      "INFO:tensorflow:loss = 358.43018, step = 1701 (166.234 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1767 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp2ylss52e\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.522886\n",
      "INFO:tensorflow:loss = 359.77066, step = 1801 (191.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.606922\n",
      "INFO:tensorflow:loss = 308.8764, step = 1901 (164.827 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.605881\n",
      "INFO:tensorflow:loss = 314.06625, step = 2001 (165.027 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.61173\n",
      "INFO:tensorflow:loss = 279.94202, step = 2101 (163.553 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2117 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp2ylss52e\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.549145\n",
      "INFO:tensorflow:loss = 269.04828, step = 2201 (182.015 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.595998\n",
      "INFO:tensorflow:loss = 336.16406, step = 2301 (167.788 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.610348\n",
      "INFO:tensorflow:loss = 286.9878, step = 2401 (163.850 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2472 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp2ylss52e\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.55652\n",
      "INFO:tensorflow:loss = 274.5362, step = 2501 (179.642 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.61443\n",
      "INFO:tensorflow:loss = 252.54263, step = 2601 (162.793 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.615035\n",
      "INFO:tensorflow:loss = 282.46002, step = 2701 (162.592 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.612866\n",
      "INFO:tensorflow:loss = 271.69238, step = 2801 (163.195 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2830 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp2ylss52e\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.544263\n",
      "INFO:tensorflow:loss = 203.85506, step = 2901 (183.711 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.616547\n",
      "INFO:tensorflow:loss = 234.32162, step = 3001 (162.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.612942\n",
      "INFO:tensorflow:loss = 191.30354, step = 3101 (163.148 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3186 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp2ylss52e\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.5614\n",
      "INFO:tensorflow:loss = 195.229, step = 3201 (178.093 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.621266\n",
      "INFO:tensorflow:loss = 242.25334, step = 3301 (161.003 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.615799\n",
      "INFO:tensorflow:loss = 184.48169, step = 3401 (162.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.617015\n",
      "INFO:tensorflow:loss = 197.1603, step = 3501 (162.071 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3545 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp2ylss52e\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.523353\n",
      "INFO:tensorflow:loss = 228.15646, step = 3601 (191.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.601767\n",
      "INFO:tensorflow:loss = 209.29314, step = 3701 (166.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.594649\n",
      "INFO:tensorflow:loss = 198.04448, step = 3801 (168.114 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3892 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp2ylss52e\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.548657\n",
      "INFO:tensorflow:loss = 259.55023, step = 3901 (182.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.613404\n",
      "INFO:tensorflow:loss = 224.05356, step = 4001 (163.063 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.614252\n",
      "INFO:tensorflow:loss = 212.78033, step = 4101 (162.793 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.604431\n",
      "INFO:tensorflow:loss = 182.76126, step = 4201 (165.444 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4248 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp2ylss52e\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.546387\n",
      "INFO:tensorflow:loss = 164.2359, step = 4301 (183.037 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.601135\n",
      "INFO:tensorflow:loss = 183.21053, step = 4401 (166.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.596486\n",
      "INFO:tensorflow:loss = 175.7424, step = 4501 (167.610 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4601 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp2ylss52e\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.560113\n",
      "INFO:tensorflow:loss = 192.26088, step = 4601 (178.493 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.604381\n",
      "INFO:tensorflow:loss = 176.59856, step = 4701 (165.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.592016\n",
      "INFO:tensorflow:loss = 181.06665, step = 4801 (168.920 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.59859\n",
      "INFO:tensorflow:loss = 188.56006, step = 4901 (167.051 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4952 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp2ylss52e\\model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp2ylss52e\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 124.157455.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x26249ccc860>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## define input function\n",
    "input_func = tf.estimator.inputs.pandas_input_fn(x = X_train, y = Y_train, batch_size = 500, \n",
    "                                                num_epochs = 2000, shuffle = True)\n",
    "\n",
    "## define the feature columns\n",
    "feat_cols = [Locale_Reference, State_Reference, Flight_Conditions, Weather_Elements_Visibility, Work_Environment_Factor, \n",
    "             Light, ATC_Advisory, Aircraft_Operator, Make_Model_Name, Crew_Size, Flight_Plan, Mission, Flight_Phase1, \n",
    "             Route_In_Use, Airspace, Aircraft_Component, Manufacturer, Location_Of_Person, Location_In_Aircraft, \n",
    "             Reporter_Organization, Function, Qualification, Human_Factors, Anomaly, Detector, When_Detected, \n",
    "             Were_Passengers_Involved_In_Event, Contributing_Factors_Situations, Primary_Problem]\n",
    "\n",
    "## build the model\n",
    "model = tf.estimator.DNNClassifier(hidden_units = [40, 40, 40, 40, 40, 40, 40, 40], feature_columns = feat_cols,\n",
    "                                   n_classes = n_classes, optimizer = tf.train.AdamOptimizer(learning_rate = 0.001))\n",
    "\n",
    "## train the model\n",
    "model.train(input_fn = input_func, steps = 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Test the performance of the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp2ylss52e\\model.ckpt-5000\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.36      0.32      0.34       968\n",
      "          2       0.26      0.25      0.26      1396\n",
      "          3       0.14      0.13      0.13       470\n",
      "          4       0.11      0.06      0.08       116\n",
      "          5       0.43      0.40      0.41       730\n",
      "          6       0.14      0.07      0.09        15\n",
      "          7       0.10      0.09      0.09       187\n",
      "          8       0.17      0.13      0.14       485\n",
      "          9       0.27      0.31      0.29       579\n",
      "         10       0.10      0.10      0.10       255\n",
      "         11       0.18      0.08      0.11        24\n",
      "         12       0.05      0.03      0.03        40\n",
      "         13       0.08      0.10      0.09       144\n",
      "         14       0.20      0.05      0.08        76\n",
      "         15       0.14      0.10      0.12       210\n",
      "         16       0.29      0.23      0.26       145\n",
      "         17       0.17      0.24      0.20       274\n",
      "         18       0.14      0.17      0.16       414\n",
      "         19       0.00      0.00      0.00         7\n",
      "         20       0.23      0.22      0.22       170\n",
      "         21       0.32      0.34      0.33       173\n",
      "         22       0.08      0.04      0.05       104\n",
      "         23       0.14      0.09      0.11       213\n",
      "         24       0.20      0.24      0.21       203\n",
      "         25       0.20      0.18      0.19       125\n",
      "         26       0.33      0.29      0.31       847\n",
      "         27       0.04      0.02      0.03        82\n",
      "         28       0.33      0.31      0.32        16\n",
      "         29       0.08      0.09      0.09       128\n",
      "         30       0.45      0.44      0.44       848\n",
      "         31       0.47      0.56      0.51      2824\n",
      "         32       0.21      0.16      0.18        80\n",
      "         33       0.00      0.00      0.00        11\n",
      "         34       0.02      0.06      0.03        36\n",
      "         35       0.31      0.32      0.32        28\n",
      "\n",
      "avg / total       0.30      0.31      0.30     12916\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\sklearn\\metrics\\classification.py:1428: UserWarning: labels size, 36, does not match size of target_names, 35\n",
      "  .format(len(labels), len(target_names))\n"
     ]
    }
   ],
   "source": [
    "eval_input = tf.estimator.inputs.pandas_input_fn(x = X_test, shuffle = False)\n",
    "prediction = list(model.predict(eval_input))\n",
    "\n",
    "pred_label = [int(pred['class_ids']) for pred in prediction]\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "target_names = [str(i) for i in range(1, n_classes)]\n",
    "print(classification_report(Y_test, pred_label, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
