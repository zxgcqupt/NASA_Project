{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The version of TensorFlow is 1.4.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "print ('The version of TensorFlow is {}'.format(tf.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from ASRS database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\ipykernel_launcher.py:12: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0\n",
       "0   1\n",
       "1   2\n",
       "2   1\n",
       "3   0\n",
       "4   2\n",
       "5   1\n",
       "6   4\n",
       "7  32\n",
       "8  23\n",
       "9   8"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = 'ASRS_DBOnline.csv'\n",
    "data = pd.read_csv(file_name)\n",
    "data = data.drop(columns = ['ACN', 'Date', 'Local Time Of Day', 'Ceiling', 'Callback', 'Callback.1'])\n",
    "\n",
    "X = data.drop(columns = 'Result')\n",
    "Y = data['Result']\n",
    "\n",
    "for i in range(Y.shape[0]):\n",
    "    if ';' in str(Y[i]):\n",
    "        Y.set_value(i, Y[i].split(';')[0])\n",
    "    elif Y[i] is np.nan:\n",
    "        Y.set_value(i, 'unknown')\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "Y = pd.DataFrame(le.fit_transform(Y), index = X.index)\n",
    "        \n",
    "n_classes = int(Y.max()[0]) + 1\n",
    "print (n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Locale_Reference', 'State_Reference', 'Relative_Position.Angle.Radial',\n",
       "       'Relative_Position.Distance.Nautical_Miles',\n",
       "       'Altitude.AGL.Single_Value', 'Altitude.MSL.Single_Value',\n",
       "       'Flight_Conditions', 'Weather_Elements_Visibility',\n",
       "       'Work_Environment_Factor', 'Light', 'RVR.Single_Value', 'ATC_Advisory',\n",
       "       'Aircraft_Operator', 'Make_Model_Name', 'Aircraft_Zone', 'Crew_Size',\n",
       "       'Operating_Under_FAR_Part', 'Flight_Plan', 'Mission', 'Nav_In_Use',\n",
       "       'Flight_Phase1', 'Route_In_Use', 'Airspace',\n",
       "       'Maintenance_Status.Maintenance_Deferred',\n",
       "       'Maintenance_Status.Records_Complete',\n",
       "       'Maintenance_Status.Released_For_Service',\n",
       "       'Maintenance_Status.Required_Correct_Doc_On_Board',\n",
       "       'Maintenance_Status.Maintenance_Type',\n",
       "       'Maintenance_Status.Maintenance_Items_Involved', 'Cabin_Lighting',\n",
       "       'Number_Of_Seats.Number', 'Passengers_On_Board.Number',\n",
       "       'Crew_Size_Flight_Attendant.Number_Of_Crew', 'Aircraft_Component',\n",
       "       'Manufacturer', 'Aircraft_Reference', 'Problem', 'ATC_Advisory.1',\n",
       "       'Aircraft_Operator.1', 'Make_Model_Name.1', 'Aircraft_Zone.1',\n",
       "       'Crew_Size.1', 'Operating_Under_FAR_Part.1', 'Flight_Plan.1',\n",
       "       'Mission.1', 'Nav_In_Use.1', 'Flight_Phase2', 'Route_In_Use.1',\n",
       "       'Airspace.1', 'Maintenance_Status.Maintenance_Deferred.1',\n",
       "       'Maintenance_Status.Records_Complete.1',\n",
       "       'Maintenance_Status.Released_For_Service.1',\n",
       "       'Maintenance_Status.Required_Correct_Doc_On_Board.1',\n",
       "       'Maintenance_Status.Maintenance_Type.1',\n",
       "       'Maintenance_Status.Maintenance_Items_Involved.1', 'Cabin_Lighting.1',\n",
       "       'Number_Of_Seats.Number.1', 'Passengers_On_Board.Number.1',\n",
       "       'Crew_Size_Flight_Attendant.Number_Of_Crew.1', 'Location_Of_Person',\n",
       "       'Location_In_Aircraft', 'Reporter_Organization', 'Function',\n",
       "       'Qualification', 'Experience', 'Cabin_Activity', 'Human_Factors',\n",
       "       'Communication_Breakdown', 'ASRS_Report_Number.Accession_Number',\n",
       "       'Location_Of_Person.1', 'Location_In_Aircraft.1',\n",
       "       'Reporter_Organization.1', 'Function.1', 'Qualification.1',\n",
       "       'Experience.1', 'Cabin_Activity.1', 'Human_Factors.1',\n",
       "       'Communication_Breakdown.1', 'ASRS_Report_Number.Accession_Number.1',\n",
       "       'Anomaly', 'Miss_Distance', 'Were_Passengers_Involved_In_Event',\n",
       "       'Detector', 'When_Detected', 'Contributing_Factors_Situations',\n",
       "       'Primary_Problem', 'Narrative1', 'Narrative2', 'Synopsis'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## change column names\n",
    "new_col_name = []\n",
    "for col in X.columns:\n",
    "    #print(type(col))\n",
    "    new_col_name.append(col.replace('/ ', '').replace(' ', '_'))\n",
    "    \n",
    "X.columns = new_col_name\n",
    "\n",
    "## output the headers from the csv file\n",
    "X.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output the data types of all the items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative_Position.Angle.Radial\n",
      "Relative_Position.Distance.Nautical_Miles\n",
      "Work_Environment_Factor\n",
      "RVR.Single_Value\n",
      "Aircraft_Zone\n",
      "Nav_In_Use\n",
      "Maintenance_Status.Maintenance_Deferred\n",
      "Maintenance_Status.Records_Complete\n",
      "Maintenance_Status.Released_For_Service\n",
      "Maintenance_Status.Required_Correct_Doc_On_Board\n",
      "Maintenance_Status.Maintenance_Type\n",
      "Maintenance_Status.Maintenance_Items_Involved\n",
      "Cabin_Lighting\n",
      "Number_Of_Seats.Number\n",
      "Passengers_On_Board.Number\n",
      "Crew_Size_Flight_Attendant.Number_Of_Crew\n",
      "Manufacturer\n",
      "ATC_Advisory.1\n",
      "Aircraft_Operator.1\n",
      "Make_Model_Name.1\n",
      "Aircraft_Zone.1\n",
      "Crew_Size.1\n",
      "Operating_Under_FAR_Part.1\n",
      "Flight_Plan.1\n",
      "Mission.1\n",
      "Nav_In_Use.1\n",
      "Flight_Phase2\n",
      "Route_In_Use.1\n",
      "Airspace.1\n",
      "Maintenance_Status.Maintenance_Deferred.1\n",
      "Maintenance_Status.Records_Complete.1\n",
      "Maintenance_Status.Released_For_Service.1\n",
      "Maintenance_Status.Required_Correct_Doc_On_Board.1\n",
      "Maintenance_Status.Maintenance_Type.1\n",
      "Maintenance_Status.Maintenance_Items_Involved.1\n",
      "Cabin_Lighting.1\n",
      "Number_Of_Seats.Number.1\n",
      "Passengers_On_Board.Number.1\n",
      "Crew_Size_Flight_Attendant.Number_Of_Crew.1\n",
      "Cabin_Activity\n",
      "Experience.1\n",
      "Cabin_Activity.1\n",
      "Human_Factors.1\n",
      "Communication_Breakdown.1\n",
      "Miss_Distance\n",
      "Were_Passengers_Involved_In_Event\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "The unique data types across all the items are: {<class 'numpy.float64'>, <class 'numpy.int64'>, <class 'str'>}\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "data_type = []\n",
    "for item_name in X.keys():\n",
    "    first_valid_index = X[item_name].first_valid_index()\n",
    "    if (first_valid_index != None):\n",
    "        data_type.append(type(X[item_name][first_valid_index]))\n",
    "    \n",
    "    no_NaNs = np.sum(X[item_name].isna().astype(int))\n",
    "    if (no_NaNs > 0.8 * X.shape[0]):\n",
    "        print (item_name)\n",
    "\n",
    "print ('\\n')\n",
    "print ('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "print ('The unique data types across all the items are:', set(data_type))\n",
    "print ('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count the number of missing values in each item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of items with value equal to NaN is 2779\n"
     ]
    }
   ],
   "source": [
    "item_name = 'Relative_Position.Angle.Radial'\n",
    "## find the number of NaN in this item\n",
    "no = np.sum(X[item_name].isna().astype(int))\n",
    "print ('The number of items with value equal to NaN is {}'.format(no))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace the missing value with corresponding values according to its data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique records in this item is 2818\n"
     ]
    }
   ],
   "source": [
    "for item_name in X.keys():\n",
    "    first_valid_index = X[item_name].first_valid_index()\n",
    "    if (first_valid_index != None):\n",
    "        if (type(X[item_name][first_valid_index]) == np.float64):\n",
    "            X[item_name].fillna(-1, inplace = True)\n",
    "        elif (type(X[item_name][first_valid_index]) is str):\n",
    "            X[item_name].fillna('unknown', inplace = True)\n",
    "        elif (type(X[item_name][first_valid_index]) == np.int64):\n",
    "            X[item_name].fillna(-11, inplace = True)\n",
    "\n",
    "print ('The number of unique records in this item is {}'.format(len(set(X[item_name]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Location\n",
    "Locale_Reference = tf.feature_column.categorical_column_with_hash_bucket('Locale_Reference', \n",
    "                                                                         hash_bucket_size = len(set(X['Locale_Reference'])))\n",
    "State_Reference = tf.feature_column.categorical_column_with_hash_bucket('State_Reference', \n",
    "                                                                        hash_bucket_size = len(set(X['State_Reference'])))\n",
    "\n",
    "\n",
    "## Environment\n",
    "Flight_Conditions = tf.feature_column.categorical_column_with_hash_bucket('Flight_Conditions', \n",
    "                                                                hash_bucket_size = len(set(X['State_Reference'])))\n",
    "Weather_Elements_Visibility = tf.feature_column.categorical_column_with_hash_bucket('Weather_Elements_Visibility', \n",
    "                                                            hash_bucket_size = len(set(X['Weather_Elements_Visibility'])))\n",
    "Work_Environment_Factor = tf.feature_column.categorical_column_with_hash_bucket('Work_Environment_Factor', \n",
    "                                                            hash_bucket_size = len(set(X['Work_Environment_Factor'])))\n",
    "Light = tf.feature_column.categorical_column_with_hash_bucket('Light', hash_bucket_size = len(set(X['Work_Environment_Factor'])))\n",
    "\n",
    "\n",
    "## Aircraft\n",
    "ATC_Advisory = tf.feature_column.categorical_column_with_hash_bucket('ATC_Advisory', \n",
    "                                                            hash_bucket_size = len(set(X['ATC_Advisory'])))\n",
    "Aircraft_Operator = tf.feature_column.categorical_column_with_hash_bucket('Aircraft_Operator', \n",
    "                                                                hash_bucket_size = len(set(X['Aircraft_Operator'])))\n",
    "Make_Model_Name = tf.feature_column.categorical_column_with_hash_bucket('Make_Model_Name', \n",
    "                                                            hash_bucket_size = len(set(X['Make_Model_Name'])))\n",
    "Crew_Size = tf.feature_column.numeric_column('Crew_Size', [1])\n",
    "Flight_Plan = tf.feature_column.categorical_column_with_hash_bucket('Flight_Plan', \n",
    "                                                            hash_bucket_size = len(set(X['Flight_Plan'])))\n",
    "Mission = tf.feature_column.categorical_column_with_hash_bucket('Mission', \n",
    "                                                                hash_bucket_size = len(set(X['Mission'])))\n",
    "Flight_Phase1 = tf.feature_column.categorical_column_with_hash_bucket('Flight_Phase1', \n",
    "                                                                      hash_bucket_size = len(set(X['Flight_Phase1'])))\n",
    "Route_In_Use = tf.feature_column.categorical_column_with_hash_bucket('Route_In_Use', \n",
    "                                                                     hash_bucket_size = len(set(X['Route_In_Use'])))\n",
    "Airspace = tf.feature_column.categorical_column_with_hash_bucket('Airspace', \n",
    "                                                                 hash_bucket_size = len(set(X['Airspace'])))\n",
    "\n",
    "## Component\n",
    "Aircraft_Component = tf.feature_column.categorical_column_with_hash_bucket('Aircraft_Component', \n",
    "                                                             hash_bucket_size = len(set(X['Aircraft_Component'])))\n",
    "Manufacturer = tf.feature_column.categorical_column_with_hash_bucket('Manufacturer', \n",
    "                                                        hash_bucket_size = len(set(X['Manufacturer'])))\n",
    "\n",
    "## Person\n",
    "Location_Of_Person = tf.feature_column.categorical_column_with_hash_bucket('Location_Of_Person', \n",
    "                                                                hash_bucket_size = len(set(X['Location_Of_Person'])))\n",
    "Location_In_Aircraft = tf.feature_column.categorical_column_with_hash_bucket('Location_In_Aircraft',\n",
    "                                                            hash_bucket_size = len(set(X['Location_In_Aircraft'])))\n",
    "Reporter_Organization = tf.feature_column.categorical_column_with_hash_bucket('Reporter_Organization',\n",
    "                                                            hash_bucket_size = len(set(X['Reporter_Organization'])))\n",
    "Function = tf.feature_column.categorical_column_with_hash_bucket('Function', hash_bucket_size = len(set(X['Function'])))\n",
    "Qualification = tf.feature_column.categorical_column_with_hash_bucket('Qualification', \n",
    "                                                                      hash_bucket_size = len(set(X['Qualification'])))\n",
    "Human_Factors = tf.feature_column.categorical_column_with_hash_bucket('Human_Factors', \n",
    "                                                                      hash_bucket_size = len(set(X['Human_Factors'])))\n",
    "\n",
    "## Events\n",
    "Anomaly = tf.feature_column.categorical_column_with_hash_bucket('Anomaly', \n",
    "                                                                hash_bucket_size = len(set(X['Anomaly'])))\n",
    "Detector = tf.feature_column.categorical_column_with_hash_bucket('Detector', \n",
    "                                                                 hash_bucket_size = len(set(X['Detector'])))\n",
    "When_Detected = tf.feature_column.categorical_column_with_hash_bucket('When_Detected', \n",
    "                                                                      hash_bucket_size = len(set(X['When_Detected'])))\n",
    "Were_Passengers_Involved_In_Event = tf.feature_column.categorical_column_with_hash_bucket('Were_Passengers_Involved_In_Event',\n",
    "                                                    hash_bucket_size = len(set(X['Were_Passengers_Involved_In_Event'])))\n",
    "\n",
    "## Assessments\n",
    "Contributing_Factors_Situations = tf.feature_column.categorical_column_with_hash_bucket('Contributing_Factors_Situations', \n",
    "                                                   hash_bucket_size = len(set(X['Contributing_Factors_Situations'])))\n",
    "Primary_Problem = tf.feature_column.categorical_column_with_hash_bucket('Primary_Problem', \n",
    "                                                        hash_bucket_size = len(set(X['Primary_Problem'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Place\n",
    "Locale_Reference = tf.feature_column.embedding_column(Locale_Reference, len(set(X['Locale_Reference'])))\n",
    "State_Reference = tf.feature_column.embedding_column(State_Reference, len(set(X['State_Reference'])))\n",
    "\n",
    "\n",
    "## Environment\n",
    "Flight_Conditions = tf.feature_column.embedding_column(Flight_Conditions,  len(set(X['Flight_Conditions'])))\n",
    "Weather_Elements_Visibility = tf.feature_column.embedding_column(Weather_Elements_Visibility,  \n",
    "                                                                 len(set(X['Weather_Elements_Visibility'])))\n",
    "Work_Environment_Factor = tf.feature_column.embedding_column(Work_Environment_Factor,  len(set(X['Work_Environment_Factor'])))\n",
    "Light = tf.feature_column.embedding_column(Light, len(set(X['Light'])))\n",
    "\n",
    "\n",
    "## Aircraft\n",
    "ATC_Advisory = tf.feature_column.embedding_column(ATC_Advisory, len(set(X['ATC_Advisory'])))\n",
    "Aircraft_Operator = tf.feature_column.embedding_column(Aircraft_Operator, len(set(X['Aircraft_Operator'])))\n",
    "Make_Model_Name = tf.feature_column.embedding_column(Make_Model_Name, len(set(X['Make_Model_Name'])))\n",
    "Flight_Plan = tf.feature_column.embedding_column(Flight_Plan, len(set(X['Flight_Plan'])))\n",
    "Mission = tf.feature_column.embedding_column(Mission, len(set(X['Mission'])))\n",
    "Flight_Phase1 = tf.feature_column.embedding_column(Flight_Phase1, len(set(X['Flight_Phase1'])))\n",
    "Route_In_Use = tf.feature_column.embedding_column(Route_In_Use, len(set(X['Route_In_Use'])))\n",
    "Airspace = tf.feature_column.embedding_column(Airspace, len(set(X['Airspace'])))\n",
    "\n",
    "## Component\n",
    "Aircraft_Component = tf.feature_column.embedding_column(Aircraft_Component, len(set(X['Aircraft_Component'])))\n",
    "Manufacturer = tf.feature_column.embedding_column(Manufacturer, len(set(X['Manufacturer'])))\n",
    "\n",
    "## Person\n",
    "Location_Of_Person = tf.feature_column.embedding_column(Location_Of_Person, len(set(X['Location_Of_Person'])))\n",
    "Location_In_Aircraft = tf.feature_column.embedding_column(Location_In_Aircraft, len(set(X['Location_In_Aircraft'])))\n",
    "Reporter_Organization = tf.feature_column.embedding_column(Reporter_Organization, len(set(X['Reporter_Organization'])))\n",
    "Function = tf.feature_column.embedding_column(Function, len(set(X['Function'])))\n",
    "Qualification = tf.feature_column.embedding_column(Qualification, len(set(X['Qualification'])))\n",
    "Human_Factors = tf.feature_column.embedding_column(Human_Factors, len(set(X['Human_Factors'])))\n",
    "\n",
    "## Events\n",
    "Anomaly = tf.feature_column.embedding_column(Anomaly, len(set(X['Anomaly'])))\n",
    "Detector = tf.feature_column.embedding_column(Detector, len(set(X['Detector'])))\n",
    "When_Detected = tf.feature_column.embedding_column(When_Detected, len(set(X['When_Detected'])))\n",
    "Were_Passengers_Involved_In_Event = tf.feature_column.embedding_column(Were_Passengers_Involved_In_Event,\n",
    "                                                                       len(set(X['Were_Passengers_Involved_In_Event'])))\n",
    "\n",
    "## Assessments\n",
    "Contributing_Factors_Situations = tf.feature_column.embedding_column(Contributing_Factors_Situations,\n",
    "                                                                     len(set(X['Contributing_Factors_Situations'])))\n",
    "Primary_Problem = tf.feature_column.embedding_column(Primary_Problem, len(set(X['Primary_Problem'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a neural network-based learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_sub = X[['Locale_Reference', 'State_Reference', 'Flight_Conditions', 'Weather_Elements_Visibility', \n",
    "            'Work_Environment_Factor', 'Light', 'ATC_Advisory', 'Aircraft_Operator', 'Make_Model_Name', \n",
    "            'Crew_Size', 'Flight_Plan', 'Mission', 'Flight_Phase1',\n",
    "            'Route_In_Use','Airspace', 'Aircraft_Component', 'Manufacturer', 'Location_Of_Person', 'Location_In_Aircraft',\n",
    "            'Reporter_Organization', 'Function', 'Qualification', 'Human_Factors', 'Anomaly', 'Detector', 'When_Detected',\n",
    "            'Were_Passengers_Involved_In_Event', 'Contributing_Factors_Situations', 'Primary_Problem' ]]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_sub, Y, test_size = 0.2, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpc2elsyb8\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\ZHANGX~1\\\\AppData\\\\Local\\\\Temp\\\\tmpc2elsyb8', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000204AD840D68>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "assertion failed: [Label IDs must < n_classes] [Condition x < y did not hold element-wise:x (dnn/head/labels:0) = ] [[27][14][2]...] [y (dnn/head/assert_range/Const:0) = ] [32]\n\t [[Node: dnn/head/assert_range/assert_less/Assert/AssertGuard/Assert = Assert[T=[DT_STRING, DT_STRING, DT_INT64, DT_STRING, DT_INT64], summarize=3, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](dnn/head/assert_range/assert_less/Assert/AssertGuard/Assert/Switch, dnn/head/assert_range/assert_less/Assert/AssertGuard/Assert/data_0, dnn/head/assert_range/assert_less/Assert/AssertGuard/Assert/data_1, dnn/head/assert_range/assert_less/Assert/AssertGuard/Assert/Switch_1, dnn/head/assert_range/assert_less/Assert/AssertGuard/Assert/data_3, dnn/head/assert_range/assert_less/Assert/AssertGuard/Assert/Switch_2)]]\n\nCaused by op 'dnn/head/assert_range/assert_less/Assert/AssertGuard/Assert', defined at:\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 281, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 232, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 397, in execute_request\n    user_expressions, allow_stdin)\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2856, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-163-d3fbe37a42dc>\", line 17, in <module>\n    model.train(input_fn = input_func, steps = 3000)\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 302, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 711, in _train_model\n    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 694, in _call_model_fn\n    model_fn_results = self._model_fn(features=features, **kwargs)\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\estimator\\canned\\dnn.py\", line 334, in _model_fn\n    config=config)\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\estimator\\canned\\dnn.py\", line 203, in _dnn_model_fn\n    logits=logits)\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\estimator\\canned\\head.py\", line 493, in create_estimator_spec\n    features=features, mode=mode, logits=logits, labels=labels)\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\estimator\\canned\\head.py\", line 433, in create_loss\n    label_ids = self._label_ids(_check_labels(_maybe_expand_dim(labels), 1))\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\estimator\\canned\\head.py\", line 428, in _label_ids\n    return _assert_range(label_ids, self._n_classes)\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\estimator\\canned\\head.py\", line 893, in _assert_range\n    message='Label IDs must < n_classes')\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\ops\\check_ops.py\", line 403, in assert_less\n    return control_flow_ops.Assert(condition, data, summarize=summarize)\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py\", line 107, in wrapped\n    return _add_should_use_warning(fn(*args, **kwargs))\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 134, in Assert\n    condition, no_op, true_assert, name=\"AssertGuard\")\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 316, in new_func\n    return func(*args, **kwargs)\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 1864, in cond\n    orig_res_f, res_f = context_f.BuildCondBranch(false_fn)\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 1725, in BuildCondBranch\n    original_result = fn()\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 132, in true_assert\n    condition, data, summarize, name=\"Assert\")\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\ops\\gen_logging_ops.py\", line 46, in _assert\n    name=name)\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): assertion failed: [Label IDs must < n_classes] [Condition x < y did not hold element-wise:x (dnn/head/labels:0) = ] [[27][14][2]...] [y (dnn/head/assert_range/Const:0) = ] [32]\n\t [[Node: dnn/head/assert_range/assert_less/Assert/AssertGuard/Assert = Assert[T=[DT_STRING, DT_STRING, DT_INT64, DT_STRING, DT_INT64], summarize=3, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](dnn/head/assert_range/assert_less/Assert/AssertGuard/Assert/Switch, dnn/head/assert_range/assert_less/Assert/AssertGuard/Assert/data_0, dnn/head/assert_range/assert_less/Assert/AssertGuard/Assert/data_1, dnn/head/assert_range/assert_less/Assert/AssertGuard/Assert/Switch_1, dnn/head/assert_range/assert_less/Assert/AssertGuard/Assert/data_3, dnn/head/assert_range/assert_less/Assert/AssertGuard/Assert/Switch_2)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    474\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: assertion failed: [Label IDs must < n_classes] [Condition x < y did not hold element-wise:x (dnn/head/labels:0) = ] [[27][14][2]...] [y (dnn/head/assert_range/Const:0) = ] [32]\n\t [[Node: dnn/head/assert_range/assert_less/Assert/AssertGuard/Assert = Assert[T=[DT_STRING, DT_STRING, DT_INT64, DT_STRING, DT_INT64], summarize=3, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](dnn/head/assert_range/assert_less/Assert/AssertGuard/Assert/Switch, dnn/head/assert_range/assert_less/Assert/AssertGuard/Assert/data_0, dnn/head/assert_range/assert_less/Assert/AssertGuard/Assert/data_1, dnn/head/assert_range/assert_less/Assert/AssertGuard/Assert/Switch_1, dnn/head/assert_range/assert_less/Assert/AssertGuard/Assert/data_3, dnn/head/assert_range/assert_less/Assert/AssertGuard/Assert/Switch_2)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-163-d3fbe37a42dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m## train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[0msaving_listeners\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss for final step: %s.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m    781\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 783\u001b[1;33m           \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    784\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    519\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m                           run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mshould_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    890\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 892\u001b[1;33m                               run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m    893\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[1;32mc:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    965\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0moriginal_exc_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 967\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0moriginal_exc_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    968\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    969\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    691\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 693\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    950\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 952\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    953\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m       \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1022\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1024\u001b[1;33m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m   1025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1026\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    825\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    826\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 827\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    828\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    829\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1334\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1335\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1336\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1338\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: assertion failed: [Label IDs must < n_classes] [Condition x < y did not hold element-wise:x (dnn/head/labels:0) = ] [[27][14][2]...] [y (dnn/head/assert_range/Const:0) = ] [32]\n\t [[Node: dnn/head/assert_range/assert_less/Assert/AssertGuard/Assert = Assert[T=[DT_STRING, DT_STRING, DT_INT64, DT_STRING, DT_INT64], summarize=3, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](dnn/head/assert_range/assert_less/Assert/AssertGuard/Assert/Switch, dnn/head/assert_range/assert_less/Assert/AssertGuard/Assert/data_0, dnn/head/assert_range/assert_less/Assert/AssertGuard/Assert/data_1, dnn/head/assert_range/assert_less/Assert/AssertGuard/Assert/Switch_1, dnn/head/assert_range/assert_less/Assert/AssertGuard/Assert/data_3, dnn/head/assert_range/assert_less/Assert/AssertGuard/Assert/Switch_2)]]\n\nCaused by op 'dnn/head/assert_range/assert_less/Assert/AssertGuard/Assert', defined at:\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 281, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 232, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 397, in execute_request\n    user_expressions, allow_stdin)\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2856, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-163-d3fbe37a42dc>\", line 17, in <module>\n    model.train(input_fn = input_func, steps = 3000)\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 302, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 711, in _train_model\n    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 694, in _call_model_fn\n    model_fn_results = self._model_fn(features=features, **kwargs)\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\estimator\\canned\\dnn.py\", line 334, in _model_fn\n    config=config)\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\estimator\\canned\\dnn.py\", line 203, in _dnn_model_fn\n    logits=logits)\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\estimator\\canned\\head.py\", line 493, in create_estimator_spec\n    features=features, mode=mode, logits=logits, labels=labels)\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\estimator\\canned\\head.py\", line 433, in create_loss\n    label_ids = self._label_ids(_check_labels(_maybe_expand_dim(labels), 1))\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\estimator\\canned\\head.py\", line 428, in _label_ids\n    return _assert_range(label_ids, self._n_classes)\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\estimator\\canned\\head.py\", line 893, in _assert_range\n    message='Label IDs must < n_classes')\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\ops\\check_ops.py\", line 403, in assert_less\n    return control_flow_ops.Assert(condition, data, summarize=summarize)\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py\", line 107, in wrapped\n    return _add_should_use_warning(fn(*args, **kwargs))\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 134, in Assert\n    condition, no_op, true_assert, name=\"AssertGuard\")\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 316, in new_func\n    return func(*args, **kwargs)\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 1864, in cond\n    orig_res_f, res_f = context_f.BuildCondBranch(false_fn)\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 1725, in BuildCondBranch\n    original_result = fn()\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 132, in true_assert\n    condition, data, summarize, name=\"Assert\")\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\ops\\gen_logging_ops.py\", line 46, in _assert\n    name=name)\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): assertion failed: [Label IDs must < n_classes] [Condition x < y did not hold element-wise:x (dnn/head/labels:0) = ] [[27][14][2]...] [y (dnn/head/assert_range/Const:0) = ] [32]\n\t [[Node: dnn/head/assert_range/assert_less/Assert/AssertGuard/Assert = Assert[T=[DT_STRING, DT_STRING, DT_INT64, DT_STRING, DT_INT64], summarize=3, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](dnn/head/assert_range/assert_less/Assert/AssertGuard/Assert/Switch, dnn/head/assert_range/assert_less/Assert/AssertGuard/Assert/data_0, dnn/head/assert_range/assert_less/Assert/AssertGuard/Assert/data_1, dnn/head/assert_range/assert_less/Assert/AssertGuard/Assert/Switch_1, dnn/head/assert_range/assert_less/Assert/AssertGuard/Assert/data_3, dnn/head/assert_range/assert_less/Assert/AssertGuard/Assert/Switch_2)]]\n"
     ]
    }
   ],
   "source": [
    "## define input function\n",
    "input_func = tf.estimator.inputs.pandas_input_fn(x = X_train, y = Y_train, batch_size = 50, \n",
    "                                                num_epochs = 2000, shuffle = True)\n",
    "\n",
    "## define the feature columns\n",
    "feat_cols = [Locale_Reference, State_Reference, Flight_Conditions, Weather_Elements_Visibility, Work_Environment_Factor, \n",
    "             Light, ATC_Advisory, Aircraft_Operator, Make_Model_Name, Crew_Size, Flight_Plan, Mission, Flight_Phase1, \n",
    "             Route_In_Use, Airspace, Aircraft_Component, Manufacturer, Location_Of_Person, Location_In_Aircraft, \n",
    "             Reporter_Organization, Function, Qualification, Human_Factors, Anomaly, Detector, When_Detected, \n",
    "             Were_Passengers_Involved_In_Event, Contributing_Factors_Situations, Primary_Problem]\n",
    "\n",
    "## build the model\n",
    "model = tf.estimator.DNNClassifier(hidden_units = [20, 20, 20, 20], feature_columns = feat_cols,\n",
    "                                   n_classes = n_classes, optimizer = tf.train.AdamOptimizer(learning_rate = 0.001))\n",
    "\n",
    "## train the model\n",
    "model.train(input_fn = input_func, steps = 3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Test the performance of the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_input = tf.estimator.inputs.pandas_input_fn(x = X_test, shuffle = False)\n",
    "prediction = list(model.predict(eval_input))\n",
    "\n",
    "pred_label = [int(pred['class_ids']) for pred in prediction]\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "target_names = range(0, n_classes)\n",
    "print(classification_report(Y_test, pred_label, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
