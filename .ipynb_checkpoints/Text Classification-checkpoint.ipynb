{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda\\pkgs\\python-3.6.3-h9e2ca53_1\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The version of TensorFlow is 1.4.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from os import listdir\n",
    "from sklearn.model_selection import train_test_split\n",
    "print ('The version of TensorFlow is {}'.format(tf.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the 12-year incident/accident data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = './data'\n",
    "\n",
    "appended_data = []\n",
    "for file_name in listdir(root_path):\n",
    "    file_path = root_path + '/' + file_name.encode().decode('utf-8')\n",
    "    data_from_one_csv = pd.read_csv(file_path, skiprows=1)\n",
    "    appended_data.append(data_from_one_csv)\n",
    "    \n",
    "data = pd.concat(appended_data, axis=0)\n",
    "data = data.drop(columns = ['ACN', 'Date', 'Local Time Of Day', 'Ceiling', 'Callback', 'Callback.1', 'Unnamed: 96'])\n",
    "data = data.rename(index=str, columns={\"Flight Phase\": \"Flight Phase1\"})\n",
    "\n",
    "## drop the rows with empty synopsis description\n",
    "data = data[pd.notnull(data['Synopsis'])]\n",
    "\n",
    "X = data.drop(columns = 'Result')\n",
    "Y_raw = pd.DataFrame(data['Result'])\n",
    "\n",
    "processed_Y = []\n",
    "count_multiple_outcome = 0\n",
    "for index, row in Y_raw.iterrows():\n",
    "    #print (index, row['Result'])\n",
    "    outcome = row['Result']\n",
    "    if type(outcome) == np.float:\n",
    "        res = 'unknown'\n",
    "        processed_Y.append([res])\n",
    "    elif ';' in outcome:\n",
    "        count_multiple_outcome += 1\n",
    "        res = str(outcome).split(';')\n",
    "        processed_Y.append(res)\n",
    "    else:\n",
    "        res = outcome\n",
    "        processed_Y.append([res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.502222291050439"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_multiple_outcome/X.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform risk-based event outcome cetegorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5] [16508  8636 18841  8261 12327]\n"
     ]
    }
   ],
   "source": [
    "## compress the number of labels to be predicted --> map result to risk level\n",
    "rate_nine = ['General Declared Emergency', 'General Physical Injury / Incapacitation', 'Flight Crew Inflight Shutdown', \n",
    "             'Air Traffic Control Separated Traffic', 'Aircraft Aircraft Damaged']\n",
    "\n",
    "rate_seven = ['General Evacuated', 'Flight Crew Landed as Precaution', 'Flight Crew Regained Aircraft Control', \n",
    "              'Air Traffic Control Issued Advisory / Alert', 'Flight Crew Landed in Emergency Condition',\n",
    "              'Flight Crew Landed In Emergency Condition']\n",
    "\n",
    "rate_five = ['General Work Refused', 'Flight Crew Became Reoriented', 'Flight Crew Diverted', \n",
    "             'Flight Crew Executed Go Around / Missed Approach', \n",
    "             'Flight Crew Overcame Equipment Problem', 'Flight Crew Rejected Takeoff', 'Flight Crew Took Evasive Action', \n",
    "             'Air Traffic Control Issued New Clearance']\n",
    "\n",
    "rate_three = ['General Maintenance Action', 'General Flight Cancelled / Delayed', \n",
    "              'General Release Refused / Aircraft Not Accepted', \n",
    "              'Flight Crew Overrode Automation', 'Flight Crew FLC Overrode Automation',\n",
    "              'Flight Crew Exited Penetrated Airspace', \n",
    "              'Flight Crew Requested ATC Assistance / Clarification', 'Flight Crew Landed As Precaution',\n",
    "              'Flight Crew Returned To Clearance', 'Flight Crew Returned To Departure Airport',\n",
    "              'Aircraft Automation Overrode Flight Crew']\n",
    "\n",
    "rate_one = ['General Police / Security Involved', 'Flight Crew Returned To Gate', 'Aircraft Equipment Problem Dissipated', \n",
    "            'unknown', 'Air Traffic Control Provided Assistance',\n",
    "            'General None Reported / Taken', 'Flight Crew FLC complied w / Automation / Advisory']\n",
    "\n",
    "def risk_quantification(val):\n",
    "    min_risk = []\n",
    "    for i in range(len(val)):\n",
    "        item = val[i].lstrip() ## remove the space at the start of each item\n",
    "        if item in rate_nine:\n",
    "            min_risk.append(5)\n",
    "        elif item in rate_seven:\n",
    "            min_risk.append(4)\n",
    "        elif item in rate_five:\n",
    "            min_risk.append(3)\n",
    "        elif item in rate_three:\n",
    "            min_risk.append(2)\n",
    "        elif item in rate_one:\n",
    "            min_risk.append(1)\n",
    "    return max(min_risk)\n",
    "\n",
    "\n",
    "Y_ = []\n",
    "for i in range(len(processed_Y)):\n",
    "    if len(processed_Y[i]) > 1:\n",
    "        val = risk_quantification(processed_Y[i])\n",
    "        Y_.append(val)\n",
    "    else:\n",
    "        item_val = \" \".join(processed_Y[i]) ## convert a list to a string\n",
    "        if item_val in rate_nine:\n",
    "            Y_.append(5)\n",
    "        elif item_val in rate_seven:\n",
    "            Y_.append(4)\n",
    "        elif item_val in rate_five:\n",
    "            Y_.append(3)\n",
    "        elif item_val in rate_three:\n",
    "            Y_.append(2)\n",
    "        elif item_val in rate_one:\n",
    "            Y_.append(1)\n",
    "        else:\n",
    "            print (Y['Result'][i])\n",
    "\n",
    "outcomes = np.asarray(Y_)\n",
    "Y_true = pd.DataFrame(Y_, index = X.index, columns = ['Result'])\n",
    "unique, counts = np.unique(outcomes, return_counts=True)\n",
    "print (unique, counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Up-sampling the minority classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After the upsampling, the number of each item is: \n",
      "\n",
      "[1 2 3 4 5]\n",
      "[16508 18841 18841 18841 18841]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "data_rev = X.copy(deep=True)\n",
    "data_rev['Result'] = Y_true\n",
    "\n",
    "df_majority_1 = data_rev[data_rev['Result']==1]\n",
    "df_majority_3 = data_rev[data_rev['Result']==3]\n",
    "df_minority_2 = data_rev[data_rev['Result']==2]\n",
    "df_minority_4 = data_rev[data_rev['Result']==4]\n",
    "df_minority_5 = data_rev[data_rev['Result']==5]\n",
    "\n",
    "# Upsample minority class\n",
    "df_minority_2_upsampled = resample(df_minority_2, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=18841,    # to match majority class\n",
    "                                 random_state=145) # reproducible results\n",
    "df_minority_4_upsampled = resample(df_minority_4, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=18841,    # to match majority class\n",
    "                                 random_state=145) # reproducible results\n",
    "df_minority_5_upsampled = resample(df_minority_5, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=18841,    # to match majority class\n",
    "                                 random_state=145) # reproducible results\n",
    "\n",
    "df_upsampled = pd.concat([df_majority_1, df_majority_3, df_minority_2_upsampled, df_minority_4_upsampled, \n",
    "                          df_minority_5_upsampled])\n",
    "\n",
    "df_upsampled['Result'].value_counts()\n",
    "\n",
    "X = df_upsampled.drop(columns = 'Result')\n",
    "Y_true = df_upsampled['Result']\n",
    "\n",
    "unique, counts = np.unique(Y_true, return_counts=True)\n",
    "print ('After the upsampling, the number of each item is: \\n')\n",
    "print (unique)\n",
    "print (counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91872, 89)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## copy the data\n",
    "X_org = X.copy(deep=True)\n",
    "Y_org = Y_true.copy(deep=True)\n",
    "X_org.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data, the data has three parts: \n",
    "##### X_train, Y_train: train the data\n",
    "##### X_validation, Y_validation: trial data to obtain the performance metrics\n",
    "##### X_test, Y_test: test data used to compare the performance of hybrid model with SVM and DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_random_state = 111\n",
    "X, X_test, Y, Y_test = train_test_split(X_org, Y_org, test_size = 0.1, random_state = test_random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_size_ratio = 0.06\n",
    "random_split_seed = 200\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X['Synopsis'], Y, test_size = test_size_ratio, \n",
    "                                                    random_state = random_split_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline: Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.49      0.55       947\n",
      "          2       0.67      0.65      0.66      1017\n",
      "          3       0.49      0.38      0.43       988\n",
      "          4       0.56      0.61      0.58      1034\n",
      "          5       0.57      0.78      0.66       976\n",
      "\n",
      "avg / total       0.58      0.58      0.58      4962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', MultinomialNB(alpha = 1, fit_prior=True)),\n",
    "                    ])\n",
    "\n",
    "text_clf.fit(X_train, Y_train)\n",
    "pred_label_NB = text_clf.predict(X_validation)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "target_names = [str(i) for i in range(1, 5+1)]\n",
    "print(classification_report(Y_validation, pred_label_NB, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Support Vector Machine with Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.58      0.65       947\n",
      "          2       0.85      0.94      0.89      1017\n",
      "          3       0.66      0.60      0.63       988\n",
      "          4       0.81      0.91      0.86      1034\n",
      "          5       0.87      0.90      0.88       976\n",
      "\n",
      "avg / total       0.78      0.79      0.78      4962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words = 'english')),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', SGDClassifier(loss='epsilon_insensitive', penalty='l2',\n",
    "                                            alpha=1e-5, random_state=40,\n",
    "                                            max_iter=10, tol=None)),\n",
    "                    ])\n",
    "\n",
    "\n",
    "parameters = {'clf__loss': ['epsilon_insensitive', 'hinge', 'log', 'huber', 'modified_huber', 'perceptron', \n",
    "                            'squared_loss', 'squared_epsilon_insensitive', 'squared_hinge'],\n",
    "              'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'clf__alpha': (1e-2, 1e-3, 1e-4, 1e-5),\n",
    "              'clf__penalty': ['l1', 'l2', 'elasticnet'],\n",
    "              'clf__max_iter': (10, 20, 30, 40, 50, 60, 70, 80, 90, 100)\n",
    " }\n",
    "\n",
    "optimal_parameters = {'clf__loss': ['modified_huber'],\n",
    "              'vect__ngram_range':  [(1, 2)],\n",
    "              'tfidf__use_idf': [True],\n",
    "              'clf__alpha': [1e-5],\n",
    "              'clf__penalty': ['elasticnet'],\n",
    "              'clf__max_iter': [80],\n",
    " }\n",
    "\n",
    "gs_clf = GridSearchCV(text_clf, optimal_parameters, n_jobs=-1)\n",
    "\n",
    "gs_clf.fit(X_train, Y_train)\n",
    "pred_label_SVM = gs_clf.predict(X_validation)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "target_names = [str(i) for i in range(1, 6)]\n",
    "print(classification_report(Y_validation, pred_label_SVM, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.19241910934354592\n",
      "The best set of parameters is \n",
      " {'clf__alpha': 1e-05, 'clf__loss': 'modified_huber', 'clf__max_iter': 80, 'clf__penalty': 'elasticnet', 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "print ('Accuracy: ', np.sum(np.equal(Y_validation, pred_label_SVM).astype(int))/20367)\n",
    "print ('The best set of parameters is \\n', gs_clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Processing categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "The unique data types across all the items are: {<class 'numpy.float64'>, <class 'float'>, <class 'str'>}\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8     2.0\n",
       "13    2.0\n",
       "14    2.0\n",
       "17    2.0\n",
       "19    2.0\n",
       "Name: Crew_Size, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## change column names\n",
    "new_col_name = []\n",
    "for col in X_org.columns:\n",
    "    #print(type(col))\n",
    "    new_col_name.append(col.replace('/ ', '').replace(' ', '_'))\n",
    "    \n",
    "X_org.columns = new_col_name\n",
    "\n",
    "\n",
    "data_type = []\n",
    "for item_name in X_org.keys():\n",
    "    data_type.append(type(X_org[item_name][0]))\n",
    "\n",
    "print ('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "print ('The unique data types across all the items are:', set(data_type))\n",
    "print ('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "\n",
    "for item_name in X_org.keys():\n",
    "    ## find the number of NaN in this item\n",
    "    no = np.sum(X_org[item_name].isna().astype(int))\n",
    "    #print ('The number of {} with value equal to NaN is {}'.format(item_name, no))\n",
    "    \n",
    "    ## Replace the missing value with corresponding values\n",
    "    if no > 0:\n",
    "        if type(X_org[item_name][0]) == np.float64:\n",
    "            X_org[item_name].fillna(-1, inplace = True)\n",
    "        else:\n",
    "            X_org[item_name].fillna('unknown', inplace = True)\n",
    "X_org['Crew_Size'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_test, Y, Y_test = train_test_split(X_org, Y_org, test_size = 0.1, random_state = test_random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Location\n",
    "Locale_Reference = tf.feature_column.categorical_column_with_hash_bucket('Locale_Reference', \n",
    "                                                                         hash_bucket_size = len(set(X['Locale_Reference'])))\n",
    "State_Reference = tf.feature_column.categorical_column_with_hash_bucket('State_Reference', \n",
    "                                                                        hash_bucket_size = len(set(X['State_Reference'])))\n",
    "\n",
    "\n",
    "## Environment\n",
    "Flight_Conditions = tf.feature_column.categorical_column_with_hash_bucket('Flight_Conditions', \n",
    "                                                                hash_bucket_size = len(set(X['State_Reference'])))\n",
    "Weather_Elements_Visibility = tf.feature_column.categorical_column_with_hash_bucket('Weather_Elements_Visibility', \n",
    "                                                            hash_bucket_size = len(set(X['Weather_Elements_Visibility'])))\n",
    "Work_Environment_Factor = tf.feature_column.categorical_column_with_hash_bucket('Work_Environment_Factor', \n",
    "                                                            hash_bucket_size = len(set(X['Work_Environment_Factor'])))\n",
    "Light = tf.feature_column.categorical_column_with_hash_bucket('Light', hash_bucket_size = \n",
    "                                                              len(set(X['Work_Environment_Factor'])))\n",
    "\n",
    "\n",
    "## Aircraft\n",
    "ATC_Advisory = tf.feature_column.categorical_column_with_hash_bucket('ATC_Advisory', \n",
    "                                                            hash_bucket_size = len(set(X['ATC_Advisory'])))\n",
    "Aircraft_Operator = tf.feature_column.categorical_column_with_hash_bucket('Aircraft_Operator', \n",
    "                                                                hash_bucket_size = len(set(X['Aircraft_Operator'])))\n",
    "Make_Model_Name = tf.feature_column.categorical_column_with_hash_bucket('Make_Model_Name', \n",
    "                                                            hash_bucket_size = len(set(X['Make_Model_Name'])))\n",
    "Crew_Size = tf.feature_column.numeric_column('Crew_Size', [1])\n",
    "Flight_Plan = tf.feature_column.categorical_column_with_hash_bucket('Flight_Plan', \n",
    "                                                            hash_bucket_size = len(set(X['Flight_Plan'])))\n",
    "Mission = tf.feature_column.categorical_column_with_hash_bucket('Mission', \n",
    "                                                                hash_bucket_size = len(set(X['Mission'])))\n",
    "Flight_Phase1 = tf.feature_column.categorical_column_with_hash_bucket('Flight_Phase1', \n",
    "                                                                      hash_bucket_size = len(set(X['Flight_Phase1'])))\n",
    "Route_In_Use = tf.feature_column.categorical_column_with_hash_bucket('Route_In_Use', \n",
    "                                                                     hash_bucket_size = len(set(X['Route_In_Use'])))\n",
    "Airspace = tf.feature_column.categorical_column_with_hash_bucket('Airspace', \n",
    "                                                                 hash_bucket_size = len(set(X['Airspace'])))\n",
    "\n",
    "## Component\n",
    "Aircraft_Component = tf.feature_column.categorical_column_with_hash_bucket('Aircraft_Component', \n",
    "                                                             hash_bucket_size = len(set(X['Aircraft_Component'])))\n",
    "Manufacturer = tf.feature_column.categorical_column_with_hash_bucket('Manufacturer', \n",
    "                                                        hash_bucket_size = len(set(X['Manufacturer'])))\n",
    "\n",
    "## Person\n",
    "Location_Of_Person = tf.feature_column.categorical_column_with_hash_bucket('Location_Of_Person', \n",
    "                                                                hash_bucket_size = len(set(X['Location_Of_Person'])))\n",
    "Location_In_Aircraft = tf.feature_column.categorical_column_with_hash_bucket('Location_In_Aircraft',\n",
    "                                                            hash_bucket_size = len(set(X['Location_In_Aircraft'])))\n",
    "Reporter_Organization = tf.feature_column.categorical_column_with_hash_bucket('Reporter_Organization',\n",
    "                                                            hash_bucket_size = len(set(X['Reporter_Organization'])))\n",
    "Function = tf.feature_column.categorical_column_with_hash_bucket('Function', hash_bucket_size = len(set(X['Function'])))\n",
    "Qualification = tf.feature_column.categorical_column_with_hash_bucket('Qualification', \n",
    "                                                                      hash_bucket_size = len(set(X['Qualification'])))\n",
    "Human_Factors = tf.feature_column.categorical_column_with_hash_bucket('Human_Factors', \n",
    "                                                                      hash_bucket_size = len(set(X['Human_Factors'])))\n",
    "\n",
    "## Events\n",
    "Anomaly = tf.feature_column.categorical_column_with_hash_bucket('Anomaly', \n",
    "                                                                hash_bucket_size = len(set(X['Anomaly'])))\n",
    "Detector = tf.feature_column.categorical_column_with_hash_bucket('Detector', \n",
    "                                                                 hash_bucket_size = len(set(X['Detector'])))\n",
    "When_Detected = tf.feature_column.categorical_column_with_hash_bucket('When_Detected', \n",
    "                                                                      hash_bucket_size = len(set(X['When_Detected'])))\n",
    "Were_Passengers_Involved_In_Event = tf.feature_column.categorical_column_with_hash_bucket('Were_Passengers_Involved_In_Event',\n",
    "                                                    hash_bucket_size = len(set(X['Were_Passengers_Involved_In_Event'])))\n",
    "\n",
    "## Assessments\n",
    "Contributing_Factors_Situations = tf.feature_column.categorical_column_with_hash_bucket('Contributing_Factors_Situations', \n",
    "                                                   hash_bucket_size = len(set(X['Contributing_Factors_Situations'])))\n",
    "Primary_Problem = tf.feature_column.categorical_column_with_hash_bucket('Primary_Problem', \n",
    "                                                        hash_bucket_size = len(set(X['Primary_Problem'])))\n",
    "\n",
    "## Place\n",
    "Locale_Reference = tf.feature_column.embedding_column(Locale_Reference, len(set(X['Locale_Reference'])))\n",
    "State_Reference = tf.feature_column.embedding_column(State_Reference, len(set(X['State_Reference'])))\n",
    "\n",
    "\n",
    "## Environment\n",
    "Flight_Conditions = tf.feature_column.embedding_column(Flight_Conditions,  len(set(X['Flight_Conditions'])))\n",
    "Weather_Elements_Visibility = tf.feature_column.embedding_column(Weather_Elements_Visibility,  \n",
    "                                                                 len(set(X['Weather_Elements_Visibility'])))\n",
    "Work_Environment_Factor = tf.feature_column.embedding_column(Work_Environment_Factor,  len(set(X['Work_Environment_Factor'])))\n",
    "Light = tf.feature_column.embedding_column(Light, len(set(X['Light'])))\n",
    "\n",
    "\n",
    "## Aircraft\n",
    "ATC_Advisory = tf.feature_column.embedding_column(ATC_Advisory, len(set(X['ATC_Advisory'])))\n",
    "Aircraft_Operator = tf.feature_column.embedding_column(Aircraft_Operator, len(set(X['Aircraft_Operator'])))\n",
    "Make_Model_Name = tf.feature_column.embedding_column(Make_Model_Name, len(set(X['Make_Model_Name'])))\n",
    "Flight_Plan = tf.feature_column.embedding_column(Flight_Plan, len(set(X['Flight_Plan'])))\n",
    "Mission = tf.feature_column.embedding_column(Mission, len(set(X['Mission'])))\n",
    "Flight_Phase1 = tf.feature_column.embedding_column(Flight_Phase1, len(set(X['Flight_Phase1'])))\n",
    "Route_In_Use = tf.feature_column.embedding_column(Route_In_Use, len(set(X['Route_In_Use'])))\n",
    "Airspace = tf.feature_column.embedding_column(Airspace, len(set(X['Airspace'])))\n",
    "\n",
    "## Component\n",
    "Aircraft_Component = tf.feature_column.embedding_column(Aircraft_Component, len(set(X['Aircraft_Component'])))\n",
    "Manufacturer = tf.feature_column.embedding_column(Manufacturer, len(set(X['Manufacturer'])))\n",
    "\n",
    "## Person\n",
    "Location_Of_Person = tf.feature_column.embedding_column(Location_Of_Person, len(set(X['Location_Of_Person'])))\n",
    "Location_In_Aircraft = tf.feature_column.embedding_column(Location_In_Aircraft, len(set(X['Location_In_Aircraft'])))\n",
    "Reporter_Organization = tf.feature_column.embedding_column(Reporter_Organization, len(set(X['Reporter_Organization'])))\n",
    "Function = tf.feature_column.embedding_column(Function, len(set(X['Function'])))\n",
    "Qualification = tf.feature_column.embedding_column(Qualification, len(set(X['Qualification'])))\n",
    "Human_Factors = tf.feature_column.embedding_column(Human_Factors, len(set(X['Human_Factors'])))\n",
    "\n",
    "## Events\n",
    "Anomaly = tf.feature_column.embedding_column(Anomaly, len(set(X['Anomaly'])))\n",
    "Detector = tf.feature_column.embedding_column(Detector, len(set(X['Detector'])))\n",
    "When_Detected = tf.feature_column.embedding_column(When_Detected, len(set(X['When_Detected'])))\n",
    "Were_Passengers_Involved_In_Event = tf.feature_column.embedding_column(Were_Passengers_Involved_In_Event,\n",
    "                                                                       len(set(X['Were_Passengers_Involved_In_Event'])))\n",
    "\n",
    "## Assessments\n",
    "Contributing_Factors_Situations = tf.feature_column.embedding_column(Contributing_Factors_Situations,\n",
    "                                                                     len(set(X['Contributing_Factors_Situations'])))\n",
    "Primary_Problem = tf.feature_column.embedding_column(Primary_Problem, len(set(X['Primary_Problem'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_sub = X[['Locale_Reference', 'State_Reference', 'Flight_Conditions', 'Weather_Elements_Visibility', \n",
    "            'Work_Environment_Factor', 'Light', 'ATC_Advisory', 'Aircraft_Operator', 'Make_Model_Name', \n",
    "            'Crew_Size', 'Flight_Plan', 'Mission', 'Flight_Phase1',\n",
    "            'Route_In_Use','Airspace', 'Aircraft_Component', 'Manufacturer', 'Location_Of_Person', 'Location_In_Aircraft',\n",
    "            'Reporter_Organization', 'Function', 'Qualification', 'Human_Factors', 'Anomaly', 'Detector', 'When_Detected',\n",
    "            'Were_Passengers_Involved_In_Event', 'Contributing_Factors_Situations', 'Primary_Problem']]\n",
    "\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X_sub, Y, test_size = test_size_ratio, \n",
    "                                                    random_state = random_split_seed)\n",
    "\n",
    "## extract the test data\n",
    "X_test_sub = X_test[['Locale_Reference', 'State_Reference', 'Flight_Conditions', 'Weather_Elements_Visibility', \n",
    "            'Work_Environment_Factor', 'Light', 'ATC_Advisory', 'Aircraft_Operator', 'Make_Model_Name', \n",
    "            'Crew_Size', 'Flight_Plan', 'Mission', 'Flight_Phase1',\n",
    "            'Route_In_Use','Airspace', 'Aircraft_Component', 'Manufacturer', 'Location_Of_Person', 'Location_In_Aircraft',\n",
    "            'Reporter_Organization', 'Function', 'Qualification', 'Human_Factors', 'Anomaly', 'Detector', 'When_Detected',\n",
    "            'Were_Passengers_Involved_In_Event', 'Contributing_Factors_Situations', 'Primary_Problem']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train the 1 model, please keep waiting !!!\n",
      "\n",
      "\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpn8ey5eru\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\ZHANGX~1\\\\AppData\\\\Local\\\\Temp\\\\tmpn8ey5eru', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000270912A04A8>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpn8ey5eru\\model.ckpt.\n",
      "INFO:tensorflow:loss = 895.4132, step = 1\n",
      "INFO:tensorflow:global_step/sec: 0.705422\n",
      "INFO:tensorflow:loss = 565.30005, step = 101 (141.810 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.723688\n",
      "INFO:tensorflow:loss = 422.47894, step = 301 (138.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.718141\n",
      "INFO:tensorflow:loss = 337.44458, step = 401 (139.247 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 419 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpn8ey5eru\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.649902\n",
      "INFO:tensorflow:loss = 316.4773, step = 501 (153.870 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.72961\n",
      "INFO:tensorflow:global_step/sec: 0.714148\n",
      "INFO:tensorflow:global_step/sec: 0.725909\n",
      "INFO:tensorflow:loss = 228.72408, step = 801 (137.810 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 842 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpn8ey5eru\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.640673\n",
      "INFO:tensorflow:loss = 182.23259, step = 901 (156.070 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.705985\n",
      "INFO:tensorflow:loss = 163.33035, step = 1001 (141.654 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.723036\n",
      "INFO:tensorflow:loss = 165.99324, step = 1101 (138.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.716673\n",
      "INFO:tensorflow:loss = 154.23198, step = 1201 (139.547 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1260 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpn8ey5eru\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.648706\n",
      "INFO:tensorflow:loss = 153.21123, step = 1301 (154.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.719548\n",
      "INFO:tensorflow:loss = 144.87024, step = 1401 (138.984 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.719164\n",
      "INFO:tensorflow:loss = 115.139534, step = 1501 (139.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.706353\n",
      "INFO:tensorflow:loss = 144.9917, step = 1601 (141.548 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1680 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpn8ey5eru\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.650003\n",
      "INFO:tensorflow:loss = 125.06477, step = 1701 (153.823 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.727108\n",
      "INFO:tensorflow:loss = 116.32017, step = 1801 (137.570 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.677381\n",
      "INFO:tensorflow:loss = 112.04059, step = 1901 (147.631 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.720658\n",
      "INFO:tensorflow:loss = 101.390076, step = 2001 (138.743 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2096 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpn8ey5eru\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.644266\n",
      "INFO:tensorflow:loss = 121.24584, step = 2101 (155.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.716533\n",
      "INFO:tensorflow:loss = 95.67356, step = 2201 (139.589 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.733109\n",
      "INFO:tensorflow:loss = 97.26396, step = 2301 (136.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.733615\n",
      "INFO:tensorflow:loss = 88.04384, step = 2401 (136.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.732389\n",
      "INFO:tensorflow:loss = 96.36, step = 2501 (136.542 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2522 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpn8ey5eru\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.653268\n",
      "INFO:tensorflow:loss = 70.82706, step = 2601 (153.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.734213\n",
      "INFO:tensorflow:loss = 79.94269, step = 2701 (136.064 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.736774\n",
      "INFO:tensorflow:loss = 98.98367, step = 2801 (135.732 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.73219\n",
      "INFO:tensorflow:loss = 71.229065, step = 2901 (136.587 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2951 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpn8ey5eru\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.652331\n",
      "INFO:tensorflow:loss = 89.51941, step = 3001 (153.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.73362\n",
      "INFO:tensorflow:loss = 88.880646, step = 3101 (136.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.733163\n",
      "INFO:tensorflow:loss = 55.348118, step = 3201 (136.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.725698\n",
      "INFO:tensorflow:loss = 96.15839, step = 3301 (137.822 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3377 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpn8ey5eru\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.645374\n",
      "INFO:tensorflow:loss = 63.73912, step = 3401 (154.895 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.723271\n",
      "INFO:tensorflow:loss = 63.811913, step = 3501 (138.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.721064\n",
      "INFO:tensorflow:loss = 44.27933, step = 3601 (138.714 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.722153\n",
      "INFO:tensorflow:loss = 65.98713, step = 3701 (138.511 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3801 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpn8ey5eru\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.658158\n",
      "INFO:tensorflow:loss = 53.230015, step = 3801 (151.860 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.731885\n",
      "INFO:tensorflow:loss = 60.98524, step = 3901 (136.666 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpn8ey5eru\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 53.069183.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpn8ey5eru\\model.ckpt-4000\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpn8ey5eru\\model.ckpt-4000\n",
      "Train the 2 model, please keep waiting !!!\n",
      "\n",
      "\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp06pe00gn\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\ZHANGX~1\\\\AppData\\\\Local\\\\Temp\\\\tmp06pe00gn', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000002714836BC88>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp06pe00gn\\model.ckpt.\n",
      "INFO:tensorflow:loss = 895.93604, step = 1\n",
      "INFO:tensorflow:global_step/sec: 0.720763\n",
      "INFO:tensorflow:loss = 560.3262, step = 101 (138.794 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.730419\n",
      "INFO:tensorflow:loss = 422.29877, step = 201 (137.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.72387\n",
      "INFO:tensorflow:loss = 358.8364, step = 301 (137.931 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.723355\n",
      "INFO:tensorflow:loss = 357.11423, step = 401 (138.238 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 426 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp06pe00gn\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.655017\n",
      "INFO:tensorflow:loss = 276.9511, step = 501 (152.775 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.721749\n",
      "INFO:tensorflow:loss = 235.69637, step = 601 (138.531 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.720067\n",
      "INFO:tensorflow:loss = 206.68597, step = 701 (138.804 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.730275\n",
      "INFO:tensorflow:loss = 201.83362, step = 801 (136.955 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 852 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp06pe00gn\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.666105\n",
      "INFO:tensorflow:loss = 188.68356, step = 901 (150.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.733938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 141.32567, step = 1001 (136.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.734861\n",
      "INFO:tensorflow:loss = 173.1886, step = 1101 (136.087 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.738592\n",
      "INFO:tensorflow:loss = 155.38109, step = 1201 (135.379 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1283 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp06pe00gn\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.661482\n",
      "INFO:tensorflow:loss = 134.61597, step = 1301 (151.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.725956\n",
      "INFO:tensorflow:loss = 95.11038, step = 1401 (137.779 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.722727\n",
      "INFO:tensorflow:loss = 122.39973, step = 1501 (138.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.719843\n",
      "INFO:tensorflow:loss = 150.33209, step = 1601 (138.910 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.721016\n",
      "INFO:tensorflow:global_step/sec: 0.669374\n",
      "INFO:tensorflow:loss = 102.31186, step = 1801 (149.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.732105\n",
      "INFO:tensorflow:loss = 88.87395, step = 1901 (136.587 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.727462\n",
      "INFO:tensorflow:loss = 128.25827, step = 2001 (137.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.716496\n",
      "INFO:tensorflow:loss = 84.96777, step = 2101 (139.592 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2135 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp06pe00gn\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.667307\n",
      "INFO:tensorflow:loss = 95.14107, step = 2201 (149.832 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.734057\n",
      "INFO:tensorflow:loss = 82.624435, step = 2301 (136.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.722978\n",
      "INFO:tensorflow:loss = 62.590233, step = 2401 (138.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.727187\n",
      "INFO:tensorflow:loss = 56.15811, step = 2501 (137.522 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2563 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp06pe00gn\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.651119\n",
      "INFO:tensorflow:loss = 64.00192, step = 2601 (153.583 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.733809\n",
      "INFO:tensorflow:loss = 79.13697, step = 2701 (136.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.712072\n",
      "INFO:tensorflow:loss = 82.62209, step = 2801 (140.431 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.737415\n",
      "INFO:tensorflow:loss = 59.34764, step = 2901 (135.612 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2990 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp06pe00gn\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.667162\n",
      "INFO:tensorflow:loss = 74.43556, step = 3001 (149.862 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.737954\n",
      "INFO:tensorflow:loss = 65.653465, step = 3101 (135.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.737229\n",
      "INFO:tensorflow:loss = 50.76384, step = 3201 (135.646 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.738227\n",
      "INFO:tensorflow:loss = 73.70943, step = 3301 (135.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.739101\n",
      "INFO:tensorflow:loss = 44.19942, step = 3401 (135.322 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3423 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp06pe00gn\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.674588\n",
      "INFO:tensorflow:loss = 69.3266, step = 3501 (148.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.73808\n",
      "INFO:tensorflow:loss = 44.187355, step = 3601 (135.492 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.73492\n",
      "INFO:tensorflow:loss = 90.63683, step = 3701 (136.067 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.719577\n",
      "INFO:tensorflow:loss = 40.45441, step = 3801 (138.960 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3852 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp06pe00gn\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.6301\n",
      "INFO:tensorflow:loss = 38.905937, step = 3901 (158.722 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp06pe00gn\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 44.248383.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp06pe00gn\\model.ckpt-4000\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp06pe00gn\\model.ckpt-4000\n",
      "Train the 3 model, please keep waiting !!!\n",
      "\n",
      "\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp8erg6vna\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\ZHANGX~1\\\\AppData\\\\Local\\\\Temp\\\\tmp8erg6vna', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000270BE35BDA0>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp8erg6vna\\model.ckpt.\n",
      "INFO:tensorflow:loss = 895.74506, step = 1\n",
      "INFO:tensorflow:global_step/sec: 0.72401\n",
      "INFO:tensorflow:loss = 541.16626, step = 101 (138.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.724816\n",
      "INFO:tensorflow:loss = 447.55493, step = 201 (137.962 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.714512\n",
      "INFO:tensorflow:loss = 390.53857, step = 301 (139.958 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.708587\n",
      "INFO:tensorflow:loss = 339.01974, step = 401 (141.123 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 422 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp8erg6vna\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.657364\n",
      "INFO:tensorflow:loss = 299.33374, step = 501 (152.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.728295\n",
      "INFO:tensorflow:loss = 249.71341, step = 601 (137.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.699504\n",
      "INFO:tensorflow:loss = 242.24216, step = 701 (142.888 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.722708\n",
      "INFO:tensorflow:loss = 213.62778, step = 801 (138.488 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 844 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp8erg6vna\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.639595\n",
      "INFO:tensorflow:loss = 197.50797, step = 901 (156.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.718091\n",
      "INFO:tensorflow:loss = 188.88562, step = 1001 (139.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.701771\n",
      "INFO:tensorflow:loss = 153.73117, step = 1101 (142.535 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.721241\n",
      "INFO:tensorflow:loss = 174.5203, step = 1201 (138.621 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1262 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp8erg6vna\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.657378\n",
      "INFO:tensorflow:loss = 118.85399, step = 1301 (152.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.723503\n",
      "INFO:tensorflow:loss = 135.1307, step = 1401 (138.180 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711188\n",
      "INFO:tensorflow:loss = 124.35413, step = 1501 (140.781 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.706584\n",
      "INFO:tensorflow:loss = 121.51192, step = 1601 (141.354 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1681 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp8erg6vna\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.629862\n",
      "INFO:tensorflow:loss = 108.58491, step = 1701 (158.732 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.712843\n",
      "INFO:tensorflow:loss = 97.45865, step = 1801 (140.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.724325\n",
      "INFO:tensorflow:loss = 94.60103, step = 1901 (138.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.722189\n",
      "INFO:tensorflow:loss = 105.342636, step = 2001 (138.405 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2100 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp8erg6vna\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.635994\n",
      "INFO:tensorflow:loss = 122.31633, step = 2101 (157.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.720741\n",
      "INFO:tensorflow:loss = 98.15262, step = 2201 (138.979 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.700535\n",
      "INFO:tensorflow:loss = 86.26375, step = 2301 (142.537 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.699462\n",
      "INFO:tensorflow:loss = 84.76572, step = 2401 (142.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.69689\n",
      "INFO:tensorflow:loss = 79.57319, step = 2501 (143.496 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2511 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp8erg6vna\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.641825\n",
      "INFO:tensorflow:loss = 68.12137, step = 2601 (155.807 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.71426\n",
      "INFO:tensorflow:loss = 46.95309, step = 2701 (140.004 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.718256\n",
      "INFO:tensorflow:loss = 73.36444, step = 2801 (139.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.719408\n",
      "INFO:tensorflow:loss = 86.07361, step = 2901 (139.033 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2931 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp8erg6vna\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.647949\n",
      "INFO:tensorflow:loss = 67.12718, step = 3001 (154.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.704724\n",
      "INFO:tensorflow:loss = 43.28032, step = 3101 (141.879 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.693416\n",
      "INFO:tensorflow:loss = 55.99234, step = 3201 (144.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.705115\n",
      "INFO:tensorflow:loss = 51.332394, step = 3301 (141.816 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3344 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp8erg6vna\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.655925\n",
      "INFO:tensorflow:loss = 52.73416, step = 3401 (152.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.706351\n",
      "INFO:tensorflow:loss = 44.9188, step = 3501 (141.646 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.69618\n",
      "INFO:tensorflow:loss = 69.2342, step = 3601 (143.583 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.701266\n",
      "INFO:tensorflow:loss = 56.603706, step = 3701 (142.612 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3758 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp8erg6vna\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.590951\n",
      "INFO:tensorflow:loss = 43.215546, step = 3801 (169.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.689078\n",
      "INFO:tensorflow:loss = 43.873238, step = 3901 (144.964 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp8erg6vna\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 44.176895.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp8erg6vna\\model.ckpt-4000\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp8erg6vna\\model.ckpt-4000\n",
      "Train the 4 model, please keep waiting !!!\n",
      "\n",
      "\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpna1e1p21\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\ZHANGX~1\\\\AppData\\\\Local\\\\Temp\\\\tmpna1e1p21', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000270BCB4BBA8>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpna1e1p21\\model.ckpt.\n",
      "INFO:tensorflow:loss = 895.9256, step = 1\n",
      "INFO:tensorflow:global_step/sec: 0.698536\n",
      "INFO:tensorflow:loss = 565.7908, step = 101 (143.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.613888\n",
      "INFO:tensorflow:loss = 431.7127, step = 201 (163.006 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.654385\n",
      "INFO:tensorflow:loss = 330.2894, step = 301 (152.677 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 387 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpna1e1p21\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.624927\n",
      "INFO:tensorflow:loss = 311.01007, step = 401 (159.977 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.713271\n",
      "INFO:tensorflow:loss = 289.41315, step = 501 (140.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.721099\n",
      "INFO:tensorflow:loss = 233.88597, step = 601 (138.684 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.724747\n",
      "INFO:tensorflow:loss = 236.15749, step = 701 (137.995 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.702252\n",
      "INFO:tensorflow:loss = 202.71362, step = 801 (142.383 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 805 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpna1e1p21\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.650842\n",
      "INFO:tensorflow:loss = 194.86722, step = 901 (153.637 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.720254\n",
      "INFO:tensorflow:loss = 161.1855, step = 1001 (138.850 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.724108\n",
      "INFO:tensorflow:loss = 167.75626, step = 1101 (138.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.72038\n",
      "INFO:tensorflow:loss = 118.13891, step = 1201 (138.804 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1228 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpna1e1p21\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.665458\n",
      "INFO:tensorflow:loss = 154.38095, step = 1301 (150.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.726133\n",
      "INFO:tensorflow:loss = 153.96576, step = 1401 (137.714 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.713846\n",
      "INFO:tensorflow:loss = 163.3403, step = 1501 (140.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711493\n",
      "INFO:tensorflow:loss = 106.42294, step = 1601 (140.524 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1650 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpna1e1p21\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.651836\n",
      "INFO:tensorflow:loss = 115.5107, step = 1701 (153.531 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.7149\n",
      "INFO:tensorflow:loss = 117.65999, step = 1801 (139.849 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.709392\n",
      "INFO:tensorflow:loss = 98.160416, step = 1901 (140.880 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.703148\n",
      "INFO:tensorflow:loss = 104.57654, step = 2001 (142.244 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2065 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpna1e1p21\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.536223\n",
      "INFO:tensorflow:loss = 138.6947, step = 2101 (186.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.701192\n",
      "INFO:tensorflow:loss = 83.92755, step = 2201 (142.650 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.705954\n",
      "INFO:tensorflow:loss = 87.3749, step = 2301 (141.647 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.713795\n",
      "INFO:tensorflow:loss = 86.04007, step = 2401 (140.087 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2460 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpna1e1p21\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.642345\n",
      "INFO:tensorflow:loss = 66.21489, step = 2501 (155.686 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.699583\n",
      "INFO:tensorflow:loss = 56.263298, step = 2601 (142.999 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.687901\n",
      "INFO:tensorflow:loss = 71.19085, step = 2701 (145.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.701512\n",
      "INFO:tensorflow:loss = 95.28558, step = 2801 (142.618 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2871 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpna1e1p21\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.643784\n",
      "INFO:tensorflow:loss = 67.15688, step = 2901 (155.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.71532\n",
      "INFO:tensorflow:loss = 72.85196, step = 3001 (139.627 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.710528\n",
      "INFO:tensorflow:loss = 62.76168, step = 3101 (140.729 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.697909\n",
      "INFO:tensorflow:loss = 60.036316, step = 3201 (143.287 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3286 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpna1e1p21\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.629659\n",
      "INFO:tensorflow:loss = 88.34746, step = 3301 (158.786 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.71127\n",
      "INFO:tensorflow:loss = 52.10862, step = 3401 (140.613 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.705623\n",
      "INFO:tensorflow:loss = 76.94235, step = 3501 (141.720 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.723292\n",
      "INFO:tensorflow:loss = 74.34913, step = 3601 (138.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.733848\n",
      "INFO:tensorflow:loss = 76.4958, step = 3701 (136.263 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3705 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpna1e1p21\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.663511\n",
      "INFO:tensorflow:loss = 72.04208, step = 3801 (150.718 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.721277\n",
      "INFO:tensorflow:loss = 43.77402, step = 3901 (138.635 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpna1e1p21\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 57.134953.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpna1e1p21\\model.ckpt-4000\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpna1e1p21\\model.ckpt-4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train the 5 model, please keep waiting !!!\n",
      "\n",
      "\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp4ls1_vf7\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\ZHANGX~1\\\\AppData\\\\Local\\\\Temp\\\\tmp4ls1_vf7', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000270ACB88240>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp4ls1_vf7\\model.ckpt.\n",
      "INFO:tensorflow:loss = 895.80054, step = 1\n",
      "INFO:tensorflow:global_step/sec: 0.708345\n",
      "INFO:tensorflow:loss = 567.3656, step = 101 (141.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.739996\n",
      "INFO:tensorflow:loss = 319.38116, step = 301 (135.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.736882\n",
      "INFO:tensorflow:loss = 333.5019, step = 401 (135.703 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 429 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp4ls1_vf7\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.671333\n",
      "INFO:tensorflow:loss = 306.57947, step = 501 (148.957 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.74009\n",
      "INFO:tensorflow:loss = 231.07974, step = 601 (135.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.740321\n",
      "INFO:tensorflow:loss = 231.7562, step = 701 (135.082 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.73898\n",
      "INFO:tensorflow:loss = 236.44505, step = 801 (135.318 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 863 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp4ls1_vf7\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.668956\n",
      "INFO:tensorflow:loss = 177.55984, step = 901 (149.642 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.739294\n",
      "INFO:tensorflow:loss = 214.66585, step = 1001 (135.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.740201\n",
      "INFO:tensorflow:loss = 175.15341, step = 1101 (135.086 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.740052\n",
      "INFO:tensorflow:loss = 175.02768, step = 1201 (135.130 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1297 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp4ls1_vf7\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.671247\n",
      "INFO:tensorflow:loss = 145.58604, step = 1301 (148.940 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.74106\n",
      "INFO:tensorflow:loss = 140.93095, step = 1401 (135.071 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.735881\n",
      "INFO:tensorflow:loss = 160.62415, step = 1501 (135.780 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.740449\n",
      "INFO:tensorflow:loss = 139.92635, step = 1601 (135.063 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.740064\n",
      "INFO:tensorflow:loss = 142.68442, step = 1701 (135.130 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1731 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp4ls1_vf7\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.673386\n",
      "INFO:tensorflow:loss = 127.45044, step = 1801 (148.526 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.740419\n",
      "INFO:tensorflow:loss = 149.82101, step = 1901 (135.039 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.739604\n",
      "INFO:tensorflow:loss = 103.762886, step = 2001 (135.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.739181\n",
      "INFO:tensorflow:loss = 119.254974, step = 2101 (135.288 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2165 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp4ls1_vf7\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.66581\n",
      "INFO:tensorflow:loss = 71.133865, step = 2201 (150.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.736317\n",
      "INFO:tensorflow:loss = 100.7285, step = 2301 (135.814 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.736564\n",
      "INFO:tensorflow:loss = 79.892204, step = 2401 (135.765 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.728124\n",
      "INFO:tensorflow:Saving checkpoints for 2594 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp4ls1_vf7\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.646905\n",
      "INFO:tensorflow:loss = 75.79666, step = 2601 (154.562 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.726478\n",
      "INFO:tensorflow:loss = 95.5307, step = 2701 (137.684 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.732789\n",
      "INFO:tensorflow:loss = 74.30742, step = 2801 (136.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.739817\n",
      "INFO:tensorflow:loss = 77.261475, step = 2901 (135.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.735131\n",
      "INFO:tensorflow:loss = 79.659836, step = 3001 (136.071 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3023 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp4ls1_vf7\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.670676\n",
      "INFO:tensorflow:loss = 62.867626, step = 3101 (149.074 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.736854\n",
      "INFO:tensorflow:loss = 71.73101, step = 3201 (135.710 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.726604\n",
      "INFO:tensorflow:loss = 77.12062, step = 3301 (137.630 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.733539\n",
      "INFO:tensorflow:loss = 63.822838, step = 3401 (136.422 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3453 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp4ls1_vf7\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.655471\n",
      "INFO:tensorflow:loss = 86.974556, step = 3501 (152.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.730896\n",
      "INFO:tensorflow:loss = 50.674934, step = 3601 (136.809 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.734667\n",
      "INFO:tensorflow:loss = 61.593624, step = 3701 (136.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.734957\n",
      "INFO:tensorflow:loss = 51.014168, step = 3801 (136.051 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3882 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp4ls1_vf7\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.666597\n",
      "INFO:tensorflow:loss = 40.584213, step = 3901 (149.993 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp4ls1_vf7\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 52.660435.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp4ls1_vf7\\model.ckpt-4000\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp4ls1_vf7\\model.ckpt-4000\n",
      "Train the 6 model, please keep waiting !!!\n",
      "\n",
      "\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpqgez5g7n\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\ZHANGX~1\\\\AppData\\\\Local\\\\Temp\\\\tmpqgez5g7n', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000270ADCFB588>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpqgez5g7n\\model.ckpt.\n",
      "INFO:tensorflow:loss = 895.854, step = 1\n",
      "INFO:tensorflow:global_step/sec: 0.727172\n",
      "INFO:tensorflow:loss = 501.143, step = 101 (137.538 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.717006\n",
      "INFO:tensorflow:loss = 453.0794, step = 201 (139.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.711282\n",
      "INFO:tensorflow:loss = 393.52435, step = 301 (140.592 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.719428\n",
      "INFO:tensorflow:loss = 355.985, step = 401 (139.011 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 421 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpqgez5g7n\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.6513\n",
      "INFO:tensorflow:loss = 289.54114, step = 501 (153.623 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.731675\n",
      "INFO:tensorflow:loss = 235.20549, step = 601 (136.590 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.696823\n",
      "INFO:tensorflow:loss = 232.00504, step = 701 (143.583 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.691553\n",
      "INFO:tensorflow:loss = 183.6297, step = 801 (144.842 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 836 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpqgez5g7n\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.592361\n",
      "INFO:tensorflow:loss = 194.56972, step = 901 (168.527 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.713985\n",
      "INFO:tensorflow:loss = 209.09729, step = 1001 (140.034 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.713475\n",
      "INFO:tensorflow:loss = 156.89029, step = 1101 (140.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.71287\n",
      "INFO:tensorflow:loss = 187.96182, step = 1201 (140.278 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1245 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpqgez5g7n\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.652842\n",
      "INFO:tensorflow:loss = 134.99724, step = 1301 (153.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.727574\n",
      "INFO:tensorflow:loss = 119.951805, step = 1401 (137.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.724805\n",
      "INFO:tensorflow:loss = 163.3768, step = 1501 (137.928 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.732303\n",
      "INFO:tensorflow:loss = 130.1274, step = 1601 (136.569 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1673 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpqgez5g7n\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.664647\n",
      "INFO:tensorflow:loss = 112.64428, step = 1701 (150.515 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.736046\n",
      "INFO:tensorflow:loss = 131.45891, step = 1801 (135.800 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.735516\n",
      "INFO:tensorflow:loss = 82.762474, step = 1901 (135.959 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.737083\n",
      "INFO:tensorflow:loss = 103.15825, step = 2001 (135.672 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.737453\n",
      "INFO:tensorflow:loss = 92.830635, step = 2101 (135.728 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2105 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpqgez5g7n\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.664301\n",
      "INFO:tensorflow:loss = 96.589066, step = 2201 (150.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.735299\n",
      "INFO:tensorflow:loss = 94.050224, step = 2301 (135.992 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.73383\n",
      "INFO:tensorflow:loss = 93.77669, step = 2401 (136.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.733572\n",
      "INFO:tensorflow:loss = 90.34211, step = 2501 (136.320 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2536 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpqgez5g7n\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.667829\n",
      "INFO:tensorflow:loss = 99.36662, step = 2601 (149.727 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.734645\n",
      "INFO:tensorflow:loss = 85.03182, step = 2701 (136.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.73348\n",
      "INFO:tensorflow:loss = 89.78972, step = 2801 (136.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.735998\n",
      "INFO:tensorflow:loss = 60.879753, step = 2901 (135.870 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2967 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpqgez5g7n\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.661271\n",
      "INFO:tensorflow:loss = 53.338173, step = 3001 (151.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.736801\n",
      "INFO:tensorflow:loss = 46.063637, step = 3101 (135.710 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.737404\n",
      "INFO:tensorflow:loss = 64.780495, step = 3201 (135.608 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.737638\n",
      "INFO:tensorflow:loss = 70.95748, step = 3301 (135.575 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3398 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpqgez5g7n\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.664971\n",
      "INFO:tensorflow:loss = 56.343124, step = 3401 (150.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.735047\n",
      "INFO:tensorflow:loss = 62.828453, step = 3501 (136.068 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.736432\n",
      "INFO:tensorflow:loss = 67.60352, step = 3601 (135.796 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.736253\n",
      "INFO:tensorflow:loss = 83.05049, step = 3701 (135.816 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.736063\n",
      "INFO:tensorflow:loss = 74.87321, step = 3801 (135.861 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3829 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpqgez5g7n\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.67005\n",
      "INFO:tensorflow:loss = 38.832, step = 3901 (149.251 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpqgez5g7n\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 52.8805.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpqgez5g7n\\model.ckpt-4000\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpqgez5g7n\\model.ckpt-4000\n",
      "Train the 7 model, please keep waiting !!!\n",
      "\n",
      "\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpdsira8fm\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\ZHANGX~1\\\\AppData\\\\Local\\\\Temp\\\\tmpdsira8fm', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000270AE1FDC88>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpdsira8fm\\model.ckpt.\n",
      "INFO:tensorflow:loss = 896.07263, step = 1\n",
      "INFO:tensorflow:global_step/sec: 0.724706\n",
      "INFO:tensorflow:loss = 560.9547, step = 101 (138.019 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.733459\n",
      "INFO:tensorflow:loss = 456.81396, step = 201 (136.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.736899\n",
      "INFO:tensorflow:loss = 399.6989, step = 301 (135.677 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.73628\n",
      "INFO:tensorflow:loss = 310.55734, step = 401 (135.817 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 431 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpdsira8fm\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.666775\n",
      "INFO:tensorflow:loss = 316.88632, step = 501 (149.974 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.736274\n",
      "INFO:tensorflow:loss = 283.04926, step = 601 (135.897 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.731837\n",
      "INFO:tensorflow:loss = 222.54062, step = 701 (136.558 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.735716\n",
      "INFO:tensorflow:loss = 220.17935, step = 801 (135.923 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 862 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpdsira8fm\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.670487\n",
      "INFO:tensorflow:loss = 201.78348, step = 901 (149.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.735911\n",
      "INFO:tensorflow:loss = 212.04251, step = 1001 (135.883 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.733841\n",
      "INFO:tensorflow:loss = 155.88216, step = 1101 (136.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.735943\n",
      "INFO:tensorflow:loss = 159.86713, step = 1201 (135.871 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1294 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpdsira8fm\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.668085\n",
      "INFO:tensorflow:loss = 171.65721, step = 1301 (149.670 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.734669\n",
      "INFO:tensorflow:loss = 127.004616, step = 1401 (136.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.735992\n",
      "INFO:tensorflow:loss = 96.092476, step = 1501 (135.915 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.734629\n",
      "INFO:tensorflow:loss = 138.89316, step = 1601 (136.079 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.736437\n",
      "INFO:tensorflow:loss = 117.8391, step = 1701 (135.787 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1725 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpdsira8fm\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.66773\n",
      "INFO:tensorflow:loss = 117.36479, step = 1801 (149.746 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.735494\n",
      "INFO:tensorflow:loss = 111.01723, step = 1901 (135.963 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.732631\n",
      "INFO:tensorflow:loss = 94.44884, step = 2001 (136.509 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.735922\n",
      "INFO:tensorflow:loss = 101.16508, step = 2101 (135.897 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2156 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpdsira8fm\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.667657\n",
      "INFO:tensorflow:loss = 118.34072, step = 2201 (149.759 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.735126\n",
      "INFO:tensorflow:loss = 90.387726, step = 2301 (136.040 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.732733\n",
      "INFO:tensorflow:loss = 105.978935, step = 2401 (136.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.734397\n",
      "INFO:tensorflow:loss = 123.21679, step = 2501 (136.152 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 2587 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpdsira8fm\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.666478\n",
      "INFO:tensorflow:loss = 78.49396, step = 2601 (150.027 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.735534\n",
      "INFO:tensorflow:loss = 79.70103, step = 2701 (135.989 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.736893\n",
      "INFO:tensorflow:loss = 78.08174, step = 2801 (135.703 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.734586\n",
      "INFO:tensorflow:loss = 76.797745, step = 2901 (136.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.735824\n",
      "INFO:tensorflow:loss = 84.28174, step = 3001 (135.904 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3019 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpdsira8fm\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.671354\n",
      "INFO:tensorflow:loss = 82.77012, step = 3101 (148.949 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.736681\n",
      "INFO:tensorflow:loss = 71.14556, step = 3201 (135.738 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.731882\n",
      "INFO:tensorflow:loss = 36.965065, step = 3301 (136.649 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.73557\n",
      "INFO:tensorflow:loss = 64.09565, step = 3401 (135.944 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3451 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpdsira8fm\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.666871\n",
      "INFO:tensorflow:loss = 56.074707, step = 3501 (149.947 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.734575\n",
      "INFO:tensorflow:loss = 61.671646, step = 3601 (136.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.734256\n",
      "INFO:tensorflow:loss = 54.989407, step = 3701 (136.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.736508\n",
      "INFO:tensorflow:loss = 51.221527, step = 3801 (135.779 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3883 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpdsira8fm\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.664548\n",
      "INFO:tensorflow:loss = 47.348976, step = 3901 (150.448 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpdsira8fm\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 59.908287.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpdsira8fm\\model.ckpt-4000\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpdsira8fm\\model.ckpt-4000\n",
      "Train the 8 model, please keep waiting !!!\n",
      "\n",
      "\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpr7rvrrh8\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\ZHANGX~1\\\\AppData\\\\Local\\\\Temp\\\\tmpr7rvrrh8', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000270B076AA90>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpr7rvrrh8\\model.ckpt.\n",
      "INFO:tensorflow:loss = 896.28564, step = 1\n",
      "INFO:tensorflow:global_step/sec: 0.73546\n",
      "INFO:tensorflow:loss = 546.14685, step = 101 (136.001 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.737568\n",
      "INFO:tensorflow:loss = 444.30057, step = 201 (135.583 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.742009\n",
      "INFO:tensorflow:loss = 374.73218, step = 301 (134.767 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.741376\n",
      "INFO:tensorflow:loss = 339.47235, step = 401 (134.888 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 431 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpr7rvrrh8\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.67316\n",
      "INFO:tensorflow:loss = 258.4108, step = 501 (148.788 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.737153\n",
      "INFO:tensorflow:loss = 253.91559, step = 601 (135.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.738445\n",
      "INFO:tensorflow:loss = 217.90074, step = 701 (135.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.741453\n",
      "INFO:tensorflow:loss = 218.39612, step = 801 (134.941 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 865 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpr7rvrrh8\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.675845\n",
      "INFO:tensorflow:loss = 169.90024, step = 901 (147.898 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.738598\n",
      "INFO:tensorflow:loss = 181.57791, step = 1001 (135.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.739894\n",
      "INFO:tensorflow:loss = 148.38458, step = 1101 (135.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.737755\n",
      "INFO:tensorflow:loss = 121.03153, step = 1201 (135.537 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1299 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpr7rvrrh8\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.672685\n",
      "INFO:tensorflow:loss = 152.27823, step = 1301 (148.635 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.739598\n",
      "INFO:tensorflow:loss = 138.57822, step = 1401 (135.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.73991\n",
      "INFO:tensorflow:loss = 93.06104, step = 1501 (135.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.742175\n",
      "INFO:tensorflow:loss = 112.97143, step = 1601 (134.737 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.738953\n",
      "INFO:tensorflow:loss = 125.451164, step = 1701 (135.333 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1734 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpr7rvrrh8\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.674819\n",
      "INFO:tensorflow:loss = 128.83286, step = 1801 (148.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.73635\n",
      "INFO:tensorflow:loss = 109.53167, step = 1901 (135.818 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.738211\n",
      "INFO:tensorflow:loss = 90.0305, step = 2001 (135.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.739828\n",
      "INFO:tensorflow:loss = 98.04967, step = 2101 (135.163 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2168 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpr7rvrrh8\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.668215\n",
      "INFO:tensorflow:loss = 106.54683, step = 2201 (149.659 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.737421\n",
      "INFO:tensorflow:loss = 95.65807, step = 2301 (135.655 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.737361\n",
      "INFO:tensorflow:loss = 90.73929, step = 2401 (135.703 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.739005\n",
      "INFO:tensorflow:loss = 87.03518, step = 2501 (135.192 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2601 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpr7rvrrh8\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.671012\n",
      "INFO:tensorflow:loss = 76.65527, step = 2601 (148.994 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.73985\n",
      "INFO:tensorflow:loss = 95.28859, step = 2701 (135.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.73444\n",
      "INFO:tensorflow:loss = 70.75534, step = 2801 (136.026 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.731622\n",
      "INFO:tensorflow:loss = 96.26706, step = 2901 (136.669 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.730542\n",
      "INFO:tensorflow:loss = 88.65001, step = 3001 (136.890 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3032 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpr7rvrrh8\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.653933\n",
      "INFO:tensorflow:loss = 77.8013, step = 3101 (152.925 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.738505\n",
      "INFO:tensorflow:loss = 45.874847, step = 3201 (135.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.738489\n",
      "INFO:tensorflow:loss = 57.302917, step = 3301 (135.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.740163\n",
      "INFO:tensorflow:loss = 74.53907, step = 3401 (135.104 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3463 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpr7rvrrh8\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.665085\n",
      "INFO:tensorflow:loss = 65.2989, step = 3501 (150.431 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.739396\n",
      "INFO:tensorflow:loss = 57.818665, step = 3601 (135.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.738565\n",
      "INFO:tensorflow:loss = 78.18228, step = 3701 (135.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.738726\n",
      "INFO:tensorflow:loss = 60.068287, step = 3801 (135.362 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3896 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpr7rvrrh8\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.664265\n",
      "INFO:tensorflow:loss = 61.347366, step = 3901 (150.517 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpr7rvrrh8\\model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 57.316887.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpr7rvrrh8\\model.ckpt-4000\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpr7rvrrh8\\model.ckpt-4000\n",
      "Train the 9 model, please keep waiting !!!\n",
      "\n",
      "\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp49xt3n6p\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\ZHANGX~1\\\\AppData\\\\Local\\\\Temp\\\\tmp49xt3n6p', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000270B8F7FC50>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp49xt3n6p\\model.ckpt.\n",
      "INFO:tensorflow:loss = 895.9745, step = 1\n",
      "INFO:tensorflow:global_step/sec: 0.731409\n",
      "INFO:tensorflow:loss = 535.31476, step = 101 (136.756 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.73544\n",
      "INFO:tensorflow:loss = 423.28683, step = 201 (135.972 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.736377\n",
      "INFO:tensorflow:loss = 385.09778, step = 301 (135.803 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.736738\n",
      "INFO:tensorflow:loss = 324.06268, step = 401 (135.731 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 432 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp49xt3n6p\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.667091\n",
      "INFO:tensorflow:loss = 290.11826, step = 501 (150.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.734564\n",
      "INFO:tensorflow:loss = 284.27405, step = 601 (135.937 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.737546\n",
      "INFO:tensorflow:loss = 232.18018, step = 701 (135.585 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.737453\n",
      "INFO:tensorflow:loss = 220.3543, step = 801 (135.594 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 865 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp49xt3n6p\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.66743\n",
      "INFO:tensorflow:loss = 211.23871, step = 901 (149.824 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.736274\n",
      "INFO:tensorflow:loss = 193.06427, step = 1001 (135.830 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.735868\n",
      "INFO:tensorflow:loss = 155.38805, step = 1101 (135.879 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.737818\n",
      "INFO:tensorflow:loss = 210.97331, step = 1201 (135.550 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1297 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp49xt3n6p\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.66929\n",
      "INFO:tensorflow:loss = 198.46901, step = 1301 (149.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.738314\n",
      "INFO:tensorflow:loss = 178.09073, step = 1401 (135.665 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.735464\n",
      "INFO:tensorflow:loss = 161.58069, step = 1501 (135.771 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.738112\n",
      "INFO:tensorflow:loss = 161.62325, step = 1601 (135.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.738262\n",
      "INFO:tensorflow:loss = 121.587616, step = 1701 (135.555 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1729 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp49xt3n6p\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.668746\n",
      "INFO:tensorflow:loss = 124.16051, step = 1801 (149.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.73692\n",
      "INFO:tensorflow:loss = 118.57543, step = 1901 (135.692 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.738603\n",
      "INFO:tensorflow:loss = 96.489136, step = 2001 (135.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.735738\n",
      "INFO:tensorflow:loss = 129.87238, step = 2101 (135.905 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2162 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp49xt3n6p\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.670352\n",
      "INFO:tensorflow:loss = 115.17953, step = 2201 (149.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.736774\n",
      "INFO:tensorflow:loss = 115.62432, step = 2301 (135.735 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.735597\n",
      "INFO:tensorflow:loss = 125.64282, step = 2401 (135.936 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.737519\n",
      "INFO:tensorflow:loss = 75.67962, step = 2501 (135.573 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2595 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp49xt3n6p\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.670675\n",
      "INFO:tensorflow:loss = 93.5358, step = 2601 (149.087 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.736019\n",
      "INFO:tensorflow:loss = 72.36838, step = 2701 (135.888 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.735927\n",
      "INFO:tensorflow:loss = 66.58264, step = 2801 (135.894 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.736774\n",
      "INFO:tensorflow:loss = 73.765724, step = 2901 (135.722 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.737508\n",
      "INFO:tensorflow:loss = 77.404945, step = 3001 (135.593 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3028 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp49xt3n6p\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.668894\n",
      "INFO:tensorflow:loss = 58.535362, step = 3101 (149.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.735916\n",
      "INFO:tensorflow:loss = 64.42732, step = 3201 (135.886 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.737002\n",
      "INFO:tensorflow:loss = 67.92841, step = 3301 (135.685 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.736899\n",
      "INFO:tensorflow:loss = 53.554092, step = 3401 (135.692 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3461 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp49xt3n6p\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.668651\n",
      "INFO:tensorflow:loss = 111.168205, step = 3501 (149.566 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.736771\n",
      "INFO:tensorflow:loss = 69.0242, step = 3601 (135.772 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.734569\n",
      "INFO:tensorflow:loss = 55.157097, step = 3701 (136.091 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.736823\n",
      "INFO:tensorflow:loss = 57.430508, step = 3801 (135.728 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3893 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp49xt3n6p\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.668807\n",
      "INFO:tensorflow:loss = 54.990673, step = 3901 (149.475 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp49xt3n6p\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 78.24639.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp49xt3n6p\\model.ckpt-4000\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp49xt3n6p\\model.ckpt-4000\n",
      "Train the 10 model, please keep waiting !!!\n",
      "\n",
      "\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp15zxbq4j\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\ZHANGX~1\\\\AppData\\\\Local\\\\Temp\\\\tmp15zxbq4j', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000270B89A2E48>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp15zxbq4j\\model.ckpt.\n",
      "INFO:tensorflow:loss = 895.4738, step = 1\n",
      "INFO:tensorflow:global_step/sec: 0.731703\n",
      "INFO:tensorflow:loss = 535.17145, step = 101 (136.698 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.73895\n",
      "INFO:tensorflow:loss = 430.92743, step = 201 (135.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.736725\n",
      "INFO:tensorflow:loss = 388.72266, step = 301 (135.730 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.739051\n",
      "INFO:tensorflow:loss = 337.38464, step = 401 (135.318 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 429 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp15zxbq4j\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.671392\n",
      "INFO:tensorflow:loss = 318.24902, step = 501 (148.947 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.74013\n",
      "INFO:tensorflow:loss = 254.48746, step = 601 (135.284 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.740117\n",
      "INFO:tensorflow:loss = 266.38763, step = 701 (134.938 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.741673\n",
      "INFO:tensorflow:loss = 178.80304, step = 801 (134.830 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 864 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp15zxbq4j\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.658467\n",
      "INFO:tensorflow:loss = 202.2975, step = 901 (151.857 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.738461\n",
      "INFO:tensorflow:loss = 166.57344, step = 1001 (135.422 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.741882\n",
      "INFO:tensorflow:loss = 203.11118, step = 1101 (134.851 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.739691\n",
      "INFO:tensorflow:loss = 168.06772, step = 1201 (135.136 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1296 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp15zxbq4j\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.674842\n",
      "INFO:tensorflow:loss = 127.986206, step = 1301 (148.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.739812\n",
      "INFO:tensorflow:loss = 134.35446, step = 1401 (135.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.739221\n",
      "INFO:tensorflow:loss = 169.36627, step = 1501 (135.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.738543\n",
      "INFO:tensorflow:loss = 135.82278, step = 1601 (135.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.740036\n",
      "INFO:tensorflow:loss = 116.895004, step = 1701 (135.187 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1730 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp15zxbq4j\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.672656\n",
      "INFO:tensorflow:loss = 127.311386, step = 1801 (148.669 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.740064\n",
      "INFO:tensorflow:loss = 69.65668, step = 1901 (135.062 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.738827\n",
      "INFO:tensorflow:loss = 102.71724, step = 2001 (135.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.738456\n",
      "INFO:tensorflow:loss = 98.53577, step = 2101 (135.283 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2164 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp15zxbq4j\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.668531\n",
      "INFO:tensorflow:loss = 92.416336, step = 2201 (149.571 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.735954\n",
      "INFO:tensorflow:loss = 79.7906, step = 2301 (135.882 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.739379\n",
      "INFO:tensorflow:loss = 102.567215, step = 2401 (135.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.740717\n",
      "INFO:tensorflow:loss = 102.2294, step = 2501 (135.004 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2597 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp15zxbq4j\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.675139\n",
      "INFO:tensorflow:loss = 77.32538, step = 2601 (148.085 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.740711\n",
      "INFO:tensorflow:loss = 90.57817, step = 2701 (135.043 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.736266\n",
      "INFO:tensorflow:loss = 74.35573, step = 2801 (135.812 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.739511\n",
      "INFO:tensorflow:loss = 78.15328, step = 2901 (135.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.738385\n",
      "INFO:tensorflow:loss = 41.16825, step = 3001 (135.433 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3031 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp15zxbq4j\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.669418\n",
      "INFO:tensorflow:loss = 88.31377, step = 3101 (149.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.737546\n",
      "INFO:tensorflow:loss = 57.756435, step = 3201 (135.645 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.739068\n",
      "INFO:tensorflow:loss = 51.42881, step = 3301 (135.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.73956\n",
      "INFO:tensorflow:loss = 52.930374, step = 3401 (135.215 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3464 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp15zxbq4j\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.667685\n",
      "INFO:tensorflow:loss = 68.84624, step = 3501 (149.768 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.737323\n",
      "INFO:tensorflow:loss = 47.722794, step = 3601 (135.627 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.739172\n",
      "INFO:tensorflow:loss = 56.831055, step = 3701 (135.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.740739\n",
      "INFO:tensorflow:loss = 59.226814, step = 3801 (134.958 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3897 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp15zxbq4j\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.672705\n",
      "INFO:tensorflow:loss = 47.35874, step = 3901 (148.620 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp15zxbq4j\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 54.417442.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp15zxbq4j\\model.ckpt-4000\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp15zxbq4j\\model.ckpt-4000\n"
     ]
    }
   ],
   "source": [
    "label_trial = []\n",
    "label_test = []\n",
    "number_models = 10\n",
    "for i in range(number_models):\n",
    "    print ('Train the {} model, please keep waiting !!!'.format(i+1))\n",
    "    print ('\\n')\n",
    "    \n",
    "    X_train_set, X_test_tmp, Y_train_set, Y_test_tmp = train_test_split(X_train, Y_train, test_size = 0.15, random_state = 20 + i)\n",
    "\n",
    "    ## define input function\n",
    "    input_func = tf.estimator.inputs.pandas_input_fn(x = X_train_set, y = Y_train_set, batch_size = 500, \n",
    "                                                        num_epochs = 600, shuffle = True)\n",
    "\n",
    "    ## define the feature columns\n",
    "    feat_cols = [Locale_Reference, State_Reference, Flight_Conditions, Weather_Elements_Visibility, Work_Environment_Factor, \n",
    "                     Light, ATC_Advisory, Aircraft_Operator, Make_Model_Name, Crew_Size, Flight_Plan, Mission, Flight_Phase1, \n",
    "                     Route_In_Use, Airspace, Aircraft_Component, Manufacturer, Location_Of_Person, Location_In_Aircraft, \n",
    "                     Reporter_Organization, Function, Qualification, Human_Factors, Anomaly, Detector, When_Detected, \n",
    "                     Were_Passengers_Involved_In_Event, Contributing_Factors_Situations, Primary_Problem]\n",
    "\n",
    "    ## build the model\n",
    "    model = tf.estimator.DNNClassifier(hidden_units = [40, 40, 40, 40, 40, 40, 40, 40], feature_columns = feat_cols,\n",
    "                                       n_classes = 6, optimizer = tf.train.AdamOptimizer(learning_rate = 0.001))\n",
    "        \n",
    "    ## train the model\n",
    "    model.train(input_fn = input_func, steps = 4000)\n",
    "    \n",
    "    \n",
    "    ## make predictions on the trial test data\n",
    "    eval_input = tf.estimator.inputs.pandas_input_fn(x = X_validation, shuffle = False)\n",
    "    prediction = list(model.predict(eval_input))\n",
    "    pred_label = [int(pred['class_ids']) for pred in prediction]\n",
    "    label_trial.append(pred_label)\n",
    "    \n",
    "    \n",
    "    ## make predictions on the test data\n",
    "    eval_input = tf.estimator.inputs.pandas_input_fn(x = X_test_sub, shuffle = False)\n",
    "    prediction = list(model.predict(eval_input))\n",
    "    pred_label = [int(pred['class_ids']) for pred in prediction]\n",
    "    label_test.append(pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.66      0.60      0.63       947\n",
      "          2       0.83      0.92      0.87      1017\n",
      "          3       0.60      0.50      0.55       988\n",
      "          4       0.84      0.90      0.87      1034\n",
      "          5       0.79      0.86      0.82       976\n",
      "\n",
      "avg / total       0.75      0.76      0.75      4962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ensembel_trial_pred = []\n",
    "for j in range(len(label_trial[0])):\n",
    "    x = np.zeros(shape = (len(label_trial), 1)) - 1\n",
    "    for i in range(len(label_trial)):\n",
    "        x[i] =  label_trial[i][j]\n",
    "    (values, counts) = np.unique(x, return_counts=True)\n",
    "    ind = np.argmax(counts)\n",
    "    ensembel_trial_pred.append((values[ind]))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "target_names = [str(i) for i in range(1, 5+1)]\n",
    "print(classification_report(Y_validation, ensembel_trial_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the performance metrics of two individual models on the trial test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_list = list(Y_validation)\n",
    "dict_count = {1: 0, 2: 0, 3: 0, 4: 0, 5: 0}\n",
    "common_count = {1: 0, 2: 0, 3: 0, 4: 0, 5: 0}\n",
    "for i in range(len(ensembel_trial_pred)):\n",
    "    if ensembel_trial_pred[i] == pred_label_SVM[i]:\n",
    "        dict_count[ensembel_trial_pred[i]] += 1\n",
    "        if ensembel_trial_pred[i] == validation_list[i]:\n",
    "            common_count[ensembel_trial_pred[i]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 491, 2: 988, 3: 448, 4: 936, 5: 861}\n",
      "{1: 401, 2: 922, 3: 339, 4: 897, 5: 804}\n",
      "1 491\n",
      "2 988\n",
      "3 448\n",
      "4 936\n",
      "5 861\n",
      "[0.81670061 0.93319838 0.75669643 0.95833333 0.93379791]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[389, 811, 359, 772, 791]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## compute the accuracy for the commonly records identified by the two classifiers\n",
    "print (dict_count)\n",
    "print (common_count)\n",
    "accuracy = []\n",
    "for (key, val) in dict_count.items():\n",
    "    common_acuracy = common_count[key]/dict_count[key]\n",
    "    print (key, val)\n",
    "    accuracy.append(common_acuracy)\n",
    "accuracy = np.array(accuracy)\n",
    "print (accuracy)\n",
    "count_consis = [389, 811, 359, 772, 791]\n",
    "count_consis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct hybrid model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "## the predictions from the SVM on the test data\n",
    "pred_label_test_SVM = gs_clf.predict(X_test['Synopsis']) \n",
    "SVM_prob = gs_clf.predict_proba(X_test['Synopsis'])\n",
    "\n",
    "## the predictions from deep learning on the test data\n",
    "ensembel_test_pred = []\n",
    "ensembel_prob = []\n",
    "ensembel_prob_full = []\n",
    "for j in range(len(label_test[0])):\n",
    "    x = np.zeros(shape = (len(label_test), 1)) - 1\n",
    "    for i in range(len(label_test)):\n",
    "        x[i] =  label_test[i][j]\n",
    "    (values, counts) = np.unique(x, return_counts=True)\n",
    "    #print (values, counts)\n",
    "    prob_tmp = np.zeros(shape = 5)\n",
    "    \n",
    "    for j in range(len(values)):\n",
    "        prob_tmp[int(values[j]-1)] = counts[j]/10\n",
    "    ensembel_prob_full.append(prob_tmp)    \n",
    "    #print (prob_tmp)\n",
    "    \n",
    "    ind = np.argmax(counts)\n",
    "    ensembel_test_pred.append((values[ind]))\n",
    "    ensembel_prob.append(counts[ind]/10)\n",
    "    \n",
    "ensembel_prob_full = np.array(ensembel_prob_full)\n",
    "print (SVM_prob[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.65      0.66      1632\n",
      "          2       0.92      0.91      0.91      1877\n",
      "          3       0.63      0.69      0.66      1856\n",
      "          4       0.91      0.88      0.90      1950\n",
      "          5       0.90      0.87      0.88      1873\n",
      "\n",
      "avg / total       0.81      0.81      0.81      9188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, final_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05288516 0.01948626 0.14262979 0.0246257  0.00873522]\n",
      "[0.05509934 0.03739729 0.06409754 0.00479629 0.00487358]\n",
      "[0.08251796 0.00364732 0.05205436 0.00531115 0.05548782]\n",
      "[0.15702881 0.00697135 0.12401866 0.00961794 0.00966683]\n",
      "[0.09940396 0.00879224 0.03028857 0.03426887 0.0042937 ]\n",
      "[0.02037627 0.00290279 0.05087384 0.0397096  0.03871732]\n",
      "[0.0229003  0.00307086 0.05784778 0.06563579 0.00442279]\n",
      "[0.18043716 0.00510358 0.068387   0.00931857 0.00743711]\n",
      "[0.10028429 0.01787847 0.08118533 0.00657384 0.01902769]\n",
      "[0.1669755  0.00414528 0.04536056 0.00484957 0.02161389]\n",
      "[0.0852521  0.01018428 0.02696519 0.03725887 0.00389405]\n",
      "[0.00595168 0.01552599 0.00862087 0.05754021 0.00169375]\n",
      "[0.13055342 0.00463889 0.06976745 0.02648579 0.00670348]\n",
      "[0.08073279 0.00993001 0.22285778 0.02222958 0.01307292]\n",
      "[0.16077963 0.00416798 0.04852293 0.01404579 0.01232545]\n",
      "[0.00624268 0.0010952  0.01031958 0.07813817 0.00193128]\n",
      "[0.1017647  0.00927077 0.16902609 0.02082105 0.01087711]\n",
      "[0.14640498 0.01246097 0.09577032 0.0076655  0.00810386]\n",
      "[0.04587528 0.01808671 0.0452079  0.03738747 0.00403735]\n",
      "[0.08273899 0.01806401 0.06464286 0.01252671 0.01928069]\n",
      "[0.15102387 0.01331739 0.07727278 0.00648615 0.00729587]\n",
      "[0.00558224 0.00116769 0.0086968  0.04667519 0.04166171]\n",
      "[0.02468207 0.00343601 0.06319842 0.03170138 0.04531416]\n",
      "[0.10377292 0.00886736 0.0881433  0.02771342 0.00709488]\n",
      "[0.03339836 0.02678898 0.08645212 0.02541656 0.00569161]\n",
      "[0.00890968 0.04106649 0.01562182 0.01047221 0.01258828]\n",
      "[0.04657889 0.00440359 0.08643245 0.05269906 0.00696687]\n",
      "[0.18058789 0.00436781 0.0489504  0.012008   0.00652963]\n",
      "[0.03009079 0.04795767 0.02001953 0.00167753 0.00227782]\n",
      "[0.07300122 0.00901302 0.20079774 0.02803252 0.01191649]\n",
      "[0.05009171 0.01072944 0.13516523 0.0388471  0.0084304 ]\n",
      "[0.15529102 0.00626402 0.10584767 0.01278613 0.00878838]\n",
      "[0.04153442 0.02816791 0.03577335 0.02508772 0.00341533]\n",
      "[0.11568578 0.00422712 0.05079878 0.00520047 0.04131175]\n",
      "[0.07459777 0.01173416 0.20520109 0.02319084 0.01212133]\n",
      "[0.05454731 0.00573566 0.08053961 0.04928838 0.00597589]\n",
      "[0.01581112 0.0024625  0.03802383 0.02169967 0.06474998]\n",
      "[0.0267862  0.00966627 0.0685669  0.05389129 0.00492174]\n",
      "[0.07764382 0.00960811 0.21412132 0.01512547 0.02435395]\n",
      "[0.11518399 0.00646561 0.12212044 0.02444975 0.00890836]\n",
      "[0.0667249  0.01713256 0.18241832 0.01288261 0.0197745 ]\n",
      "[0.1274603  0.01103429 0.08916015 0.01660636 0.00750162]\n",
      "[0.06855463 0.00452923 0.08381695 0.04608244 0.00636907]\n",
      "[0.00465708 0.00126923 0.00642355 0.00260076 0.09731748]\n",
      "[0.03950029 0.00503968 0.10521152 0.05317666 0.00690569]\n",
      "[0.04008076 0.03452667 0.10512687 0.00745032 0.01030773]\n",
      "[0.02846086 0.01033075 0.07334157 0.04909614 0.00876471]\n",
      "[0.0878618  0.01077554 0.24319856 0.0168789  0.01413922]\n",
      "[0.05942738 0.00751854 0.16226854 0.01376116 0.04036906]\n",
      "[0.05544078 0.00700757 0.15082764 0.02483566 0.02969996]\n",
      "[0.08672549 0.00579224 0.11214587 0.03576178 0.00798602]\n",
      "[0.10905091 0.00840747 0.17422357 0.01268922 0.01941316]\n",
      "[0.0916662  0.00276345 0.02812084 0.02153765 0.0345138 ]\n",
      "[0.09160631 0.00695044 0.14134311 0.02994421 0.00943094]\n",
      "[0.16145707 0.00435765 0.05369594 0.01616049 0.00873639]\n",
      "[0.09311903 0.02848921 0.06328371 0.00506833 0.00554195]\n",
      "[0.15314728 0.00718484 0.13070683 0.01002541 0.00991781]\n",
      "[0.03856574 0.00492884 0.10254505 0.05387808 0.0067659 ]\n",
      "[0.11774425 0.01761807 0.07806036 0.01129175 0.00675137]\n",
      "[0.09832995 0.008326   0.17576682 0.02274796 0.01115002]\n",
      "[0.15672736 0.00537205 0.08093865 0.00717349 0.0184055 ]\n",
      "[0.14568537 0.00677405 0.12191702 0.01386248 0.00938693]\n",
      "[0.08818597 0.01131333 0.12044098 0.02658587 0.0083428 ]\n",
      "[0.1246795  0.00534905 0.09009277 0.02566294 0.00756099]\n",
      "[0.00632906 0.03451953 0.00880299 0.00149647 0.03724965]\n",
      "[0.15406911 0.0050467  0.07409227 0.01769109 0.00728225]\n",
      "[0.03187268 0.00783891 0.08357169 0.01300189 0.05662417]\n",
      "[0.0962943  0.00422618 0.06824887 0.03862385 0.00608417]\n",
      "[0.04593339 0.00598513 0.12388322 0.00968388 0.05605429]\n",
      "[0.03582742 0.00495577 0.01670964 0.06019979 0.00512614]\n",
      "[0.03729418 0.00550305 0.09887343 0.05378911 0.00656599]\n",
      "[0.10304015 0.00420007 0.06361832 0.01888757 0.0284792 ]\n",
      "[0.03332441 0.00343324 0.06455225 0.0610619  0.00490346]\n",
      "[0.06049689 0.00420748 0.07753722 0.0497728  0.00594615]\n",
      "[0.01566326 0.01376063 0.03685539 0.01341331 0.05467962]\n",
      "[0.02055637 0.00155094 0.01023748 0.00282103 0.08990223]\n",
      "[0.1289617  0.01377474 0.12246304 0.00927501 0.00906921]\n",
      "[0.12712051 0.0034391  0.03580013 0.00429741 0.04020184]\n",
      "[0.09390851 0.00571701 0.0787485  0.03635948 0.0065257 ]\n",
      "[0.09715076 0.01026465 0.227193   0.01590377 0.01353859]\n",
      "[0.07531885 0.00325137 0.0449559  0.02060952 0.04033261]\n",
      "[0.09928721 0.00479587 0.07906015 0.00693481 0.0429632 ]\n",
      "[0.08006525 0.00432864 0.07103056 0.00646155 0.05262775]\n",
      "[0.04287973 0.01450482 0.0164066  0.0332696  0.01870298]\n",
      "[0.02707109 0.00366742 0.06992476 0.04091533 0.03195375]\n",
      "[0.13215847 0.00833922 0.16687211 0.01222876 0.01127496]\n",
      "[0.06579413 0.00815823 0.18023417 0.03344181 0.01083851]\n",
      "[0.06773691 0.0084188  0.1858297  0.02559501 0.01909108]\n",
      "[0.00491507 0.03000601 0.00509232 0.00143696 0.04635058]\n",
      "[0.06931976 0.03264245 0.07729791 0.00578795 0.00577624]\n",
      "[0.05303451 0.00664489 0.1438279  0.04301855 0.00893003]\n",
      "[0.00683398 0.00116533 0.01200671 0.07769437 0.00201972]\n",
      "[0.04718369 0.01497203 0.12679821 0.01030951 0.03819926]\n",
      "[0.05090102 0.02118933 0.13685221 0.02332543 0.00841246]\n",
      "[0.06949097 0.01151753 0.19060681 0.02646389 0.01135228]\n",
      "[0.12437361 0.00876739 0.18028601 0.01304599 0.01177834]\n",
      "[0.07479011 0.01742996 0.15762885 0.01900528 0.00981808]\n",
      "[0.13352731 0.00442705 0.06094121 0.0058151  0.03238305]\n",
      "[0.04320789 0.0056244  0.1160417  0.01967201 0.0457481 ]\n",
      "[0.01598249 0.02804306 0.03681899 0.00347198 0.04098765]\n",
      "[0.19051126 0.00512982 0.06632591 0.00610304 0.00750184]\n",
      "[0.10455043 0.00543269 0.06148885 0.03471468 0.00588526]\n",
      "[0.04527156 0.00588704 0.12196087 0.01433339 0.05077981]\n",
      "[0.05614567 0.0279458  0.15144816 0.01056128 0.00911463]\n",
      "[0.0643622  0.00807095 0.17629174 0.01702361 0.03242529]\n",
      "[0.07563885 0.00587972 0.0658285  0.04332447 0.00561961]\n",
      "[0.14426586 0.00712807 0.13163721 0.01298533 0.00981925]\n",
      "[0.15547434 0.00952483 0.10327468 0.00823769 0.00863536]\n",
      "[0.10327018 0.01925696 0.12811273 0.00942724 0.00886403]\n",
      "[0.08957896 0.00578265 0.10908669 0.01778069 0.02961632]\n",
      "[0.12861145 0.00853431 0.17298389 0.01260112 0.01150432]\n",
      "[0.08005646 0.0098498  0.22092804 0.02273721 0.01297176]\n",
      "[0.07890726 0.00940521 0.05636137 0.03796102 0.00518799]\n",
      "[0.10781215 0.0087023  0.18296855 0.01734249 0.01299758]\n",
      "[0.07008702 0.00383004 0.06496711 0.04820821 0.00551117]\n",
      "[0.1455618  0.00709462 0.13040133 0.01270862 0.00978213]\n",
      "[0.14109296 0.00784783 0.15147732 0.01129084 0.01069725]\n",
      "[0.00519664 0.0379037  0.00524251 0.01114229 0.0196418 ]\n",
      "[0.01737882 0.00448898 0.04204618 0.05777081 0.01489545]\n",
      "[0.04887558 0.00738572 0.04251392 0.05207532 0.00407168]\n",
      "[0.10798722 0.00306533 0.03181503 0.01701892 0.03284875]\n",
      "[0.09757206 0.01601491 0.06574236 0.00568847 0.0255716 ]\n",
      "[0.17538874 0.00596156 0.09238314 0.00769057 0.00847967]\n",
      "[0.04532774 0.01627533 0.12120562 0.03362876 0.00763589]\n",
      "[0.17964614 0.0057274  0.08504731 0.00724363 0.00820438]\n",
      "[0.16915058 0.00966136 0.0457926  0.00844484 0.00614027]\n",
      "[0.01311986 0.00950782 0.01010646 0.03862733 0.03343898]\n",
      "[0.061644   0.00303552 0.04632991 0.05377591 0.00450359]\n",
      "[0.03587923 0.03340415 0.05735881 0.00453564 0.02062161]\n",
      "[0.04315089 0.02041558 0.01609201 0.03102452 0.01065252]\n",
      "[0.10633244 0.00876749 0.18520544 0.01852219 0.01185593]\n",
      "[0.02996938 0.00171773 0.01249547 0.00295144 0.0855121 ]\n",
      "[0.00638391 0.00142285 0.01126183 0.01215122 0.08405803]\n",
      "[0.05107981 0.01022338 0.06489432 0.04531189 0.00513386]\n",
      "[0.09942952 0.00964418 0.20990085 0.01485543 0.01612659]\n",
      "[0.03166655 0.03754442 0.08089633 0.00583897 0.01169053]\n",
      "[0.08836461 0.00686925 0.07806192 0.03660116 0.00639177]\n",
      "[0.03545774 0.00793748 0.09359652 0.03703088 0.02422512]\n",
      "[0.14957754 0.00602034 0.10012358 0.00817637 0.01766647]\n",
      "[0.06828097 0.01120942 0.18363864 0.02791312 0.01100704]\n",
      "[0.09101418 0.02175296 0.0606371  0.00515859 0.01872105]\n",
      "[0.07810085 0.00961785 0.2153482  0.02420499 0.01267925]\n",
      "[0.09004408 0.00270454 0.02825632 0.03278336 0.02114744]\n",
      "[0.06719147 0.00669511 0.13798017 0.01052308 0.04429836]\n",
      "[0.07750375 0.01620964 0.141487   0.02125659 0.00911258]\n",
      "[0.02229101 0.04340692 0.01435002 0.00150025 0.01428143]\n",
      "[0.04505784 0.00186144 0.01826531 0.04935036 0.02058328]\n",
      "[0.0555056  0.00428318 0.0801422  0.04466018 0.01407385]\n",
      "[0.03388309 0.00533898 0.01369273 0.0121365  0.06573094]\n",
      "[0.17049617 0.00623065 0.1008134  0.00820417 0.00879602]\n",
      "[0.05789851 0.02402284 0.15669744 0.01519021 0.00943221]\n",
      "[0.06391923 0.02986277 0.11580297 0.008279   0.00753663]\n",
      "[0.12480085 0.00874389 0.17954984 0.01300114 0.01175071]\n",
      "[0.04638985 0.00585681 0.12486911 0.0480057  0.00793617]\n",
      "[0.07708404 0.03661704 0.0221457  0.00222017 0.00325531]\n",
      "[0.10271855 0.00841522 0.17691948 0.02105791 0.01127421]\n",
      "[0.06984847 0.01513647 0.11209021 0.00860118 0.03183079]\n",
      "[0.01232269 0.02245622 0.02648938 0.03669634 0.01156936]\n",
      "[0.03564795 0.00458278 0.09421987 0.05606804 0.00632948]\n",
      "[0.09129709 0.00886032 0.1917735  0.0229377  0.01178681]\n",
      "[0.11824925 0.00893384 0.18634719 0.01432253 0.01196408]\n",
      "[0.14635992 0.00545156 0.08687103 0.01857159 0.0077571 ]\n",
      "[0.050568   0.00635235 0.13679038 0.04486978 0.00856111]\n",
      "[0.13801566 0.00788766 0.08930101 0.01638092 0.00927081]\n",
      "[0.11172724 0.00996638 0.07110136 0.02494715 0.00640679]\n",
      "[0.00516365 0.00121363 0.00766827 0.02673367 0.06684322]\n",
      "[0.12653305 0.00797639 0.1034411  0.00831595 0.02298593]\n",
      "[0.16120901 0.01446958 0.04347176 0.00434606 0.00585188]\n",
      "[0.03648565 0.00904384 0.09634817 0.04916256 0.00639628]\n",
      "[0.00951555 0.00157319 0.01981365 0.0566489  0.02614089]\n",
      "[0.07992762 0.00445155 0.07866167 0.04285133 0.00630973]\n",
      "[0.06682434 0.00697791 0.1348416  0.02943304 0.02038285]\n",
      "[0.03889618 0.00293471 0.04988801 0.06119132 0.00430614]\n",
      "[0.08686066 0.0068757  0.1406698  0.03169091 0.00932348]\n",
      "[0.06374233 0.01331753 0.03336047 0.03080674 0.01453675]\n",
      "[0.13224264 0.00694589 0.13011996 0.01738403 0.00955582]\n",
      "[0.06138564 0.00213028 0.02253797 0.05722212 0.00338567]\n",
      "[0.05958134 0.01545742 0.09908996 0.0319706  0.00683001]\n",
      "[0.06498365 0.00718576 0.15482061 0.03730894 0.00963585]\n",
      "[0.0406289  0.02512107 0.08197128 0.01797595 0.01544095]\n",
      "[0.07603778 0.00937317 0.20946177 0.02575343 0.01237067]\n",
      "[0.02650547 0.00349845 0.0681342  0.06292992 0.00496203]\n",
      "[0.15018152 0.01236432 0.08820907 0.00719959 0.00780873]\n",
      "[0.04735371 0.02667456 0.12637631 0.01748888 0.00780267]\n",
      "[0.02446338 0.00336974 0.06250448 0.04041197 0.03463025]\n",
      "[0.13480017 0.00819393 0.16232026 0.01195144 0.01110415]\n",
      "[0.09619839 0.00892459 0.19212848 0.02118174 0.01188186]\n",
      "[0.04831797 0.01698823 0.12976453 0.02517302 0.01522586]\n",
      "[0.12950013 0.00551369 0.09267279 0.0198151  0.01250633]\n",
      "[0.09867766 0.01018489 0.08880841 0.02745032 0.00703026]\n",
      "[0.09292342 0.01236893 0.13926775 0.01038071 0.02370646]\n",
      "[0.07185858 0.00894714 0.1976583  0.01413271 0.03013736]\n",
      "[0.00476624 0.01342873 0.00586026 0.00210831 0.07575166]\n",
      "[0.0795576  0.00801342 0.17265628 0.02972045 0.01070401]\n",
      "[0.05370456 0.01308149 0.04931808 0.0416538  0.0044105 ]\n",
      "[0.11778945 0.00698792 0.13517707 0.02170104 0.00956128]\n",
      "[0.02231291 0.00280633 0.05103506 0.06680129 0.00409447]\n",
      "[0.04720381 0.00600247 0.12727673 0.0369854  0.02103083]\n",
      "[0.0128563  0.00216602 0.02968663 0.01248157 0.0785602 ]\n",
      "[0.1189032  0.00428899 0.06179193 0.01503286 0.02689037]\n",
      "[0.1109961  0.01416223 0.11712158 0.01516022 0.00852346]\n",
      "[0.07090577 0.02084955 0.03898867 0.02559676 0.00411777]\n",
      "[0.02562156 0.02096752 0.06463422 0.02926354 0.01593801]\n",
      "[0.0540244  0.00254445 0.03437967 0.04876806 0.01547933]\n",
      "[0.0700673  0.00684046 0.14432925 0.03701958 0.00922606]\n",
      "[0.06523447 0.01043317 0.17849678 0.03049257 0.0107234 ]\n",
      "[0.04903685 0.00633971 0.1327147  0.01021644 0.05295182]\n",
      "[0.04916722 0.01472374 0.13228106 0.03363517 0.00823709]\n",
      "[0.14792771 0.00747191 0.13970053 0.01057335 0.01025532]\n",
      "[0.04517312 0.0051816  0.10641328 0.0425296  0.0176589 ]\n",
      "[0.09255382 0.00570082 0.10702163 0.02481357 0.01986682]\n",
      "[0.00465708 0.00126923 0.00642355 0.00260076 0.09731748]\n",
      "[0.07382147 0.00689166 0.13202276 0.03675701 0.00870496]\n",
      "[0.09507522 0.00592939 0.11066243 0.00885074 0.03825328]\n",
      "[0.00954544 0.02070297 0.01897632 0.0026453  0.05908918]\n",
      "[0.08317498 0.01507478 0.21291863 0.01484344 0.01258857]\n",
      "[0.02555546 0.0264718  0.06420022 0.01135174 0.02843937]\n",
      "[0.05137201 0.02945245 0.0867287  0.00649805 0.01734148]\n",
      "[0.01469336 0.03783304 0.03231019 0.01753869 0.00626897]\n",
      "[0.01846452 0.02486675 0.04408028 0.00999409 0.03715086]\n",
      "[0.12817281 0.00523296 0.086078   0.02501346 0.00742894]\n",
      "[0.05101083 0.02204333 0.13714152 0.01892456 0.01231802]\n",
      "[0.07350383 0.00913511 0.20234018 0.01441503 0.02849263]\n",
      "[0.0120854  0.02347862 0.02591523 0.01590145 0.03594081]\n",
      "[0.07967703 0.019674   0.14121457 0.01555287 0.00909809]\n",
      "[0.19831561 0.00470058 0.05287844 0.00528377 0.0069972 ]\n",
      "[0.05284567 0.01138764 0.14300304 0.03630297 0.00883787]\n",
      "[0.01107032 0.01944907 0.00711144 0.00250362 0.06166561]\n",
      "[0.0395127  0.00518929 0.1055039  0.02177639 0.04602922]\n",
      "[0.10020542 0.00311316 0.03539939 0.02091772 0.03077656]\n",
      "[0.07889568 0.0053002  0.09753571 0.00806688 0.04769139]\n",
      "[0.00598329 0.00112367 0.00968222 0.06578085 0.01753571]\n",
      "[0.0339055  0.00248639 0.03943385 0.06440307 0.00373688]\n",
      "[0.00505672 0.04578453 0.00436138 0.00079796 0.01836615]\n",
      "[0.12094634 0.00999406 0.0406987  0.02445965 0.00511958]\n",
      "[0.10616255 0.0086931  0.18266493 0.01355835 0.0184466 ]\n",
      "[0.08297683 0.01183122 0.12311738 0.02734204 0.00837976]\n",
      "[0.02789132 0.00388176 0.03192597 0.04993093 0.02223685]\n",
      "[0.10072913 0.00637335 0.12363805 0.02926665 0.00874809]\n",
      "[0.08471129 0.01518516 0.17942119 0.01276424 0.01642654]\n",
      "[0.10135401 0.01068246 0.10967704 0.02403972 0.00805342]\n",
      "[0.06744041 0.01028159 0.18481567 0.02943153 0.01105889]\n",
      "[0.05647636 0.02776677 0.15240481 0.01062715 0.00916702]\n",
      "[0.10921727 0.01792515 0.10710196 0.01118266 0.00798192]\n",
      "[0.06922972 0.02940627 0.07999356 0.01025916 0.00593629]\n",
      "[0.07278385 0.0078505  0.16835159 0.0166932  0.03034152]\n",
      "[0.00736325 0.04795694 0.01078772 0.00111343 0.01268848]\n",
      "[0.02735905 0.0343562  0.06883248 0.00521325 0.02075906]\n",
      "[0.00561659 0.01140497 0.00808156 0.04352149 0.02697548]\n",
      "[0.04669447 0.00745659 0.12579934 0.0273542  0.03076489]\n",
      "[0.09148283 0.01629483 0.1826882  0.01292255 0.01128221]\n",
      "[0.09525133 0.01094426 0.07264763 0.0076109  0.03291634]\n",
      "[0.06208388 0.00781755 0.1698203  0.01516928 0.03652664]\n",
      "[0.14762511 0.00379896 0.04077883 0.00587122 0.02902223]\n",
      "[0.1054432  0.00955954 0.09899854 0.02522081 0.007627  ]\n",
      "[0.042794   0.00543033 0.11460927 0.05070457 0.00739833]\n",
      "[0.03753224 0.00613368 0.01705219 0.05985865 0.0027    ]\n",
      "[0.11124569 0.00918873 0.19497997 0.01554229 0.01225614]\n",
      "[0.11495942 0.00475179 0.07700437 0.03089236 0.00679273]\n",
      "[0.05669554 0.01632669 0.11115842 0.02160488 0.01868046]\n",
      "[0.04877023 0.0043361  0.07869305 0.0069463  0.06411889]\n",
      "[0.14238733 0.00777663 0.14924702 0.01115496 0.01061356]\n",
      "[0.0878618  0.01077554 0.24319856 0.0168789  0.01413922]\n",
      "[0.01119355 0.01622918 0.02357228 0.05348867 0.00247669]\n",
      "[0.00492614 0.03123875 0.00503521 0.00138704 0.04416422]\n",
      "[0.05468218 0.02572822 0.07477836 0.02086658 0.00549458]\n",
      "[0.05041841 0.01866008 0.13577115 0.00994169 0.03008665]\n",
      "[0.09303174 0.01841923 0.04982476 0.00461374 0.0253341 ]\n",
      "[0.07503686 0.0193635  0.10345791 0.01987338 0.00841288]\n",
      "[0.02464807 0.01678947 0.06202342 0.04488047 0.004503  ]\n",
      "[0.05263702 0.00207302 0.01873904 0.02057895 0.05324046]\n",
      "[0.13081272 0.00690601 0.12850508 0.00990703 0.01968855]\n",
      "[0.1119395  0.02293138 0.07377748 0.00592104 0.00639943]\n",
      "[0.00503251 0.00122803 0.00734602 0.02048589 0.07473272]\n",
      "[0.12672458 0.02020571 0.04810921 0.00442898 0.00886749]\n",
      "[0.00470452 0.00655277 0.00617879 0.00238678 0.08794671]\n",
      "[0.04370485 0.01862877 0.11661349 0.00875867 0.03549848]\n",
      "[0.11153773 0.00823581 0.16978044 0.0189955  0.01108114]\n",
      "[0.07393746 0.01562788 0.05839354 0.03045402 0.00513805]\n",
      "[0.02704734 0.00148572 0.01492941 0.07024684 0.00248   ]\n",
      "[0.11181887 0.00494473 0.08209222 0.02390847 0.01616002]\n",
      "[0.00924137 0.01813347 0.01829339 0.00269979 0.06387059]\n",
      "[0.00546768 0.00165956 0.00838254 0.040993   0.04796329]\n",
      "[0.05128718 0.00651138 0.13897025 0.02870583 0.02814066]\n",
      "[0.03106812 0.00639996 0.08110387 0.04519502 0.01930798]\n",
      "[0.12648303 0.00584785 0.10274862 0.02324988 0.00818231]\n",
      "[0.06200692 0.00778657 0.16956283 0.01985764 0.03074414]\n",
      "[0.12237821 0.00809601 0.1631331  0.01616022 0.01094342]\n",
      "[0.05250766 0.02213002 0.14140052 0.01995747 0.01000123]\n",
      "[0.06350035 0.00794707 0.17379511 0.0222596  0.02657707]\n",
      "[0.05328975 0.00398589 0.03974728 0.02722266 0.03986567]\n",
      "[0.10719287 0.0084118  0.05771755 0.0298574  0.00571826]\n",
      "[0.1039501  0.00983577 0.097238   0.00786939 0.0296137 ]\n",
      "[0.12309791 0.00883755 0.18248413 0.01317991 0.01186083]\n",
      "[0.11391144 0.00934281 0.19831311 0.01414428 0.01245483]\n",
      "[0.10324631 0.00992939 0.2166899  0.01526388 0.01314444]\n",
      "[0.16388224 0.00659441 0.11220969 0.00889849 0.00922368]\n",
      "[0.05261731 0.04271651 0.01918763 0.00181567 0.00265692]\n",
      "[0.09178126 0.00984952 0.21771713 0.01910936 0.01300906]\n",
      "[0.01046533 0.00190484 0.02234928 0.07452446 0.00255873]\n",
      "[0.05106442 0.0228288  0.13722115 0.0208714  0.00841517]\n",
      "[0.07750641 0.00757501 0.1616598  0.03198562 0.0101564 ]\n",
      "[0.17006679 0.00447734 0.04621726 0.00765088 0.01619649]\n",
      "[0.00465708 0.00126923 0.00642355 0.00260076 0.09731748]\n",
      "[0.04877023 0.0043361  0.07869305 0.0069463  0.06411889]\n",
      "[0.03071681 0.00399793 0.08015015 0.05976911 0.00559192]\n",
      "[0.13078606 0.0072619  0.13884814 0.01665972 0.00994111]\n",
      "[0.0941708  0.0056941  0.10452959 0.00850458 0.03985524]\n",
      "[0.03448549 0.00448083 0.09096543 0.04932732 0.01564373]\n",
      "[0.06732968 0.00566236 0.11402173 0.04224784 0.00776345]\n",
      "[0.02099784 0.00297311 0.05264144 0.03996252 0.03791368]\n",
      "[0.12510407 0.00872721 0.17902737 0.01296931 0.01173111]\n",
      "[0.13397416 0.00706762 0.13285573 0.01639545 0.0097116 ]\n",
      "[0.04859443 0.00621738 0.13133119 0.02535137 0.03443724]\n",
      "[0.12544013 0.00779061 0.15366469 0.0114337  0.01678147]\n",
      "[0.0501714  0.02416399 0.05722402 0.00487018 0.03131474]\n",
      "[0.19831561 0.00470058 0.05287844 0.00528377 0.0069972 ]\n",
      "[0.09819118 0.00721754 0.14658495 0.0269129  0.0097817 ]\n",
      "[0.04079424 0.00524254 0.10898917 0.0417396  0.02014256]\n",
      "[0.05256026 0.01823915 0.14191407 0.01033725 0.02912127]\n",
      "[0.17719461 0.00586223 0.08927149 0.00750099 0.0083629 ]\n",
      "[0.01782242 0.00782043 0.04303808 0.06174542 0.00359151]\n",
      "[0.10718103 0.00644155 0.1236728  0.02701618 0.00885296]\n",
      "[0.03234048 0.00173251 0.01353792 0.01315855 0.07165441]\n",
      "[0.13314253 0.0218586  0.03635678 0.0036368  0.00498559]\n",
      "[0.03953408 0.00749287 0.10516091 0.04962679 0.00687789]\n",
      "[0.06819222 0.00823978 0.18172864 0.03239633 0.01094684]\n",
      "[0.12639812 0.00645043 0.11725963 0.00922921 0.02383219]\n",
      "[0.11153977 0.00499111 0.07665113 0.03171622 0.00671842]\n",
      "[0.11153745 0.00947338 0.20240366 0.0143935  0.01260833]\n",
      "[0.04659385 0.00598113 0.12562484 0.02663556 0.03440888]\n",
      "[0.19831561 0.00470058 0.05287844 0.00528377 0.0069972 ]\n",
      "[0.06535169 0.00841425 0.17898007 0.03018774 0.01471121]\n",
      "[0.14741013 0.00757582 0.07253745 0.01639056 0.0070748 ]\n",
      "[0.14404978 0.0076852  0.14638249 0.01098044 0.01050606]\n",
      "[0.0985303  0.00893568 0.19178367 0.02041876 0.01190303]\n",
      "[0.04459566 0.00583229 0.12007644 0.00945432 0.0573916 ]\n",
      "[0.01612638 0.00131962 0.01183317 0.05986012 0.0204019 ]\n",
      "[0.0878618  0.01077554 0.24319856 0.0168789  0.01413922]\n",
      "[0.13168665 0.00778137 0.1521549  0.01325959 0.01208712]\n",
      "[0.04173    0.03122639 0.05599797 0.0188604  0.00434103]\n",
      "[0.1237448  0.00880197 0.18136948 0.013112   0.011819  ]\n",
      "[0.03844505 0.00505257 0.10244013 0.02471653 0.04320399]\n",
      "[0.00465708 0.00126923 0.00642355 0.00260076 0.09731748]\n",
      "[0.06637407 0.02579821 0.05770505 0.01834428 0.0048761 ]\n",
      "[0.053214   0.01144337 0.14405326 0.03600919 0.0088928 ]\n",
      "[0.05692981 0.0141515  0.08123945 0.00673195 0.04305227]\n",
      "[0.12789423 0.01072955 0.1326258  0.01285211 0.00994014]\n",
      "[0.08472361 0.0088248  0.02592086 0.01613489 0.03316812]\n",
      "[0.10974044 0.0049688  0.08381439 0.02885565 0.0106359 ]\n",
      "[0.01663254 0.03824901 0.03793989 0.00315716 0.02244106]\n",
      "[0.08044967 0.00338464 0.04545669 0.00491313 0.05770116]\n",
      "[0.00465708 0.00126923 0.00642355 0.00260076 0.09731748]\n",
      "[0.02541324 0.00350682 0.06525702 0.0345251  0.04122048]\n",
      "[0.08703112 0.01067702 0.24082843 0.01750237 0.01401497]\n",
      "[0.03550532 0.00724281 0.09371524 0.04493243 0.01554613]\n",
      "[0.03072698 0.01735398 0.07937742 0.0405431  0.00541433]\n",
      "[0.11720464 0.00570107 0.09922328 0.00814348 0.03135983]\n",
      "[0.04459822 0.0090769  0.1196699  0.03047715 0.02510681]\n",
      "[0.07774728 0.00243741 0.02616333 0.05101605 0.00381721]\n",
      "[0.06512244 0.01399919 0.17796224 0.02542584 0.01065864]\n",
      "[0.09551489 0.02105286 0.11060161 0.01092754 0.0078933 ]\n",
      "[0.00495104 0.03401329 0.00490668 0.00127467 0.03924336]\n",
      "[0.00492116 0.03068447 0.00506089 0.00140949 0.04514728]\n",
      "[0.04445362 0.00570067 0.11947206 0.03388281 0.02705867]\n",
      "[0.07412297 0.02657296 0.09683781 0.01126795 0.0068404 ]\n",
      "[0.10561466 0.0068021  0.13341828 0.0245795  0.01128866]\n",
      "[0.12651239 0.00864976 0.17660073 0.01282147 0.01164004]\n",
      "[0.12958541 0.01337718 0.1248359  0.00943672 0.0091955 ]\n",
      "[0.11898056 0.0050149  0.08269565 0.02743724 0.00868605]\n",
      "[0.11672074 0.00887229 0.18514237 0.01502448 0.01188322]\n",
      "[0.10907694 0.01283875 0.07651361 0.0064712  0.02509773]\n",
      "[0.04042725 0.00534074 0.10818787 0.01198294 0.05751587]\n",
      "[0.00471626 0.00786141 0.00611817 0.00233378 0.08562574]\n",
      "[0.11613959 0.00693829 0.13431943 0.02239626 0.00949473]\n",
      "[0.0679949  0.00392759 0.02241513 0.02220844 0.04141386]\n",
      "[0.0773048  0.00405022 0.06879911 0.0451555  0.00580606]\n",
      "[0.16187072 0.00456861 0.04474061 0.01831552 0.00602718]\n",
      "[0.0482975  0.00622396 0.13055648 0.01671755 0.04543066]\n",
      "[0.09088431 0.01965322 0.05951341 0.01889923 0.00542139]\n",
      "[0.0702798  0.01403136 0.19278682 0.01364024 0.02241617]\n",
      "[0.00521992 0.00353874 0.00781894 0.00818971 0.08585092]\n",
      "[0.02394509 0.01656842 0.06027405 0.01650869 0.04091295]\n",
      "[0.10377817 0.00966629 0.17743302 0.01284238 0.01884894]\n",
      "[0.01877968 0.05145855 0.01218841 0.0010646  0.0016888 ]\n",
      "[0.08522253 0.02837435 0.08210186 0.00624073 0.00630443]\n",
      "[0.09129248 0.00478315 0.08306377 0.02766964 0.01992581]\n",
      "[0.03359329 0.02667943 0.08709886 0.01577243 0.01788052]\n",
      "[0.11631183 0.00921079 0.19417705 0.0138923  0.01229962]\n",
      "[0.0498477  0.01505756 0.0604162  0.01200194 0.03890362]\n",
      "[0.00494536 0.03338035 0.004936   0.00130031 0.04036592]\n",
      "[0.05296083 0.00665338 0.14364757 0.03942261 0.01346945]\n",
      "[0.10728652 0.00970718 0.20972832 0.01483975 0.0128832 ]\n",
      "[0.15484359 0.01546941 0.04827357 0.00460795 0.00596546]\n",
      "[0.04229113 0.00537069 0.11317446 0.05108199 0.00732312]\n",
      "[0.01220682 0.00188826 0.02748532 0.05550495 0.02545172]\n",
      "[0.08825651 0.01702933 0.18296066 0.01291287 0.01123532]\n",
      "[0.00465721 0.00128306 0.00642291 0.0026002  0.09729296]\n",
      "[0.17058424 0.00592886 0.05178722 0.01284072 0.00648588]\n",
      "[0.09071321 0.00568679 0.106985   0.02400062 0.02165518]\n",
      "[0.08853323 0.00839407 0.02790184 0.03867066 0.00401007]\n",
      "[0.13755309 0.00752669 0.14397927 0.01358063 0.0102896 ]\n",
      "[0.08760734 0.02406279 0.11011068 0.00925668 0.00771088]\n",
      "[0.04391153 0.00556287 0.11779786 0.0498658  0.00756548]\n",
      "[0.05390203 0.00674778 0.14630315 0.04236743 0.00905978]\n",
      "[0.05516187 0.01307071 0.14969612 0.01272431 0.03402857]\n",
      "[0.07688994 0.00562941 0.10690044 0.00863513 0.04661185]\n",
      "[0.04850915 0.00250839 0.03602355 0.05980137 0.00381093]\n",
      "[0.07831715 0.00398948 0.06416307 0.02175011 0.03517572]\n",
      "[0.06968523 0.0334752  0.06857416 0.00521622 0.00536143]\n",
      "[0.0878618  0.01077554 0.24319856 0.0168789  0.01413922]\n",
      "[0.05508916 0.00438735 0.03377251 0.05509028 0.00379079]\n",
      "[0.00465708 0.00126923 0.00642355 0.00260076 0.09731748]\n",
      "[0.14488334 0.00375384 0.04006109 0.0045435  0.03191744]\n",
      "[0.01958619 0.02659505 0.04720781 0.00416864 0.04067016]\n",
      "[0.0121249  0.0103277  0.02694477 0.01990175 0.05482267]\n",
      "[0.10258323 0.01301954 0.07455444 0.01779525 0.01328244]\n",
      "[0.05111255 0.01983854 0.08997357 0.02925057 0.0062168 ]\n",
      "[0.02676788 0.00352957 0.0688829  0.06273298 0.00500127]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06722876 0.00832838 0.18432751 0.03236504 0.01105309]\n",
      "[0.05193878 0.01534543 0.01892869 0.0415943  0.00292328]\n",
      "[0.06144457 0.00775732 0.16802323 0.01234563 0.04054806]\n",
      "[0.08239195 0.00506972 0.09428377 0.03978984 0.00708048]\n",
      "[0.00465708 0.00126923 0.00642355 0.00260076 0.09731748]\n",
      "[0.19831561 0.00470058 0.05287844 0.00528377 0.0069972 ]\n",
      "[0.00467036 0.00126777 0.00645618 0.00323344 0.09651854]\n",
      "[0.08216358 0.00449903 0.07930235 0.04198273 0.0063755 ]\n",
      "[0.04172123 0.01222325 0.0957561  0.04287798 0.00641905]\n",
      "[0.05651947 0.01495924 0.1534247  0.01405871 0.02813578]\n",
      "[0.04965425 0.00577178 0.12173572 0.04731155 0.00784173]\n",
      "[0.05481328 0.00685586 0.14890316 0.04168349 0.00919608]\n",
      "[0.16357864 0.01108181 0.0703035  0.00613445 0.00719274]\n",
      "[0.11463556 0.00930298 0.19706539 0.01406827 0.01240801]\n",
      "[0.00498447 0.03773703 0.00473418 0.00112387 0.03263902]\n",
      "[0.0971067  0.00485976 0.08472855 0.03601633 0.00686864]\n",
      "[0.11988538 0.01246483 0.15527164 0.01135921 0.01048587]\n",
      "[0.02969779 0.02718516 0.07584336 0.0269923  0.0051269 ]\n",
      "[0.07103796 0.025745   0.09675579 0.00725195 0.01463718]\n",
      "[0.04193731 0.00532872 0.11216495 0.05134755 0.0072702 ]\n",
      "[0.06881011 0.01198379 0.18873978 0.01346714 0.02720563]\n",
      "[0.11185519 0.00642753 0.12202608 0.02562164 0.00885067]\n",
      "[0.07576119 0.00306649 0.04077441 0.02803295 0.03142821]\n",
      "[0.17428509 0.01102706 0.0467866  0.0046765  0.00625548]\n",
      "[0.12806651 0.00598426 0.10543112 0.01818899 0.01348638]\n",
      "[0.04355482 0.00389315 0.0180229  0.05393972 0.01173586]\n",
      "[0.02727744 0.0209195  0.06956629 0.0057643  0.04455897]\n",
      "[0.02270468 0.01315594 0.05694409 0.02059125 0.04271305]\n",
      "[0.04135844 0.02532383 0.01543226 0.0310089  0.00248218]\n",
      "[0.14898526 0.00741375 0.1378783  0.01046233 0.01018693]\n",
      "[0.0224629  0.02381383 0.05535136 0.03603914 0.00407847]\n",
      "[0.00471646 0.00788297 0.00611717 0.00233291 0.0855875 ]\n",
      "[0.07868519 0.00365774 0.05807595 0.04618775 0.00532616]\n",
      "[0.10584949 0.00714995 0.14104138 0.0106826  0.02754   ]\n",
      "[0.16852085 0.0041413  0.04627662 0.01658509 0.00621136]\n",
      "[0.03487096 0.00656839 0.09214941 0.02185556 0.04609694]\n",
      "[0.03138091 0.024361   0.08094039 0.01680899 0.02207295]\n",
      "[0.13234968 0.00832871 0.16654264 0.01220869 0.0112626 ]\n",
      "[0.12846486 0.00590414 0.10315796 0.017922   0.01394641]\n",
      "[0.00545879 0.00118124 0.00839346 0.04079405 0.04908823]\n",
      "[0.05376739 0.00684625 0.1461175  0.0182195  0.03926049]\n",
      "[0.018515   0.00257271 0.04537354 0.06427321 0.00956699]\n",
      "[0.06773664 0.00835984 0.18501808 0.03209086 0.01109354]\n",
      "[0.10171423 0.00991089 0.2166207  0.01580688 0.01311669]\n",
      "[0.0168789  0.00182797 0.02647886 0.07000061 0.0055473 ]\n",
      "[0.10853567 0.0176741  0.03132589 0.01831029 0.00439586]\n",
      "[0.17520585 0.00939018 0.04712604 0.0055837  0.00771076]\n",
      "[0.00506212 0.04638526 0.00433355 0.00077363 0.01730071]\n",
      "[0.06341695 0.00953781 0.12182057 0.03728113 0.00802764]\n",
      "[0.10919497 0.0089309  0.18874369 0.01713578 0.01193138]\n",
      "[0.07399404 0.02355997 0.15300141 0.01081652 0.00952193]\n",
      "[0.03900685 0.00374194 0.07113705 0.05815523 0.00530265]\n",
      "[0.11352633 0.01261236 0.16814789 0.01215323 0.0109898 ]\n",
      "[0.00465708 0.00126923 0.00642355 0.00260076 0.09731748]\n",
      "[0.05351449 0.03464882 0.09374011 0.00673603 0.00627668]\n",
      "[0.05998918 0.00746974 0.16367125 0.03779872 0.00997025]\n",
      "[0.07104632 0.01987899 0.19455368 0.01352938 0.01147525]\n",
      "[0.13264571 0.00637999 0.11509219 0.01936368 0.00885877]\n",
      "[0.02061663 0.01600964 0.00955094 0.00223446 0.06428886]\n",
      "[0.07646484 0.00486034 0.09038395 0.04240291 0.00680307]\n",
      "[0.12228436 0.01974269 0.03416732 0.01049822 0.00472965]\n",
      "[0.04253128 0.00539917 0.11385967 0.05090175 0.00735904]\n",
      "[0.08054806 0.00993993 0.22238589 0.01562384 0.02145064]\n",
      "[0.18104697 0.00565035 0.08263359 0.00709658 0.0081138 ]\n",
      "[0.08422356 0.00858856 0.18585768 0.02035026 0.01873585]\n",
      "[0.0436037  0.0055494  0.11695952 0.04521405 0.01360473]\n",
      "[0.04021629 0.00518032 0.1073511  0.04083245 0.02172729]\n",
      "[0.05052124 0.02444995 0.09345486 0.02248719 0.00632286]\n",
      "[0.03644153 0.00957095 0.09619034 0.0484296  0.00638254]\n",
      "[0.0878618  0.01077554 0.24319856 0.0168789  0.01413922]\n",
      "[0.1914112  0.00508032 0.06477524 0.00600857 0.00744364]\n",
      "[0.02730356 0.02350448 0.06945485 0.00566013 0.03997197]\n",
      "[0.01882923 0.03258103 0.00904768 0.01726866 0.01594433]\n",
      "[0.13260678 0.00663128 0.12172717 0.01844125 0.00916875]\n",
      "[0.0878618  0.01077554 0.24319856 0.0168789  0.01413922]\n",
      "[0.04761171 0.04275726 0.03003873 0.00248783 0.00308817]\n",
      "[0.10438311 0.00496729 0.08433649 0.02289502 0.02024341]\n",
      "[0.06172027 0.0361371  0.06119307 0.00466162 0.00485645]\n",
      "[0.0645012  0.00817546 0.17654432 0.03306193 0.01202922]\n",
      "[0.01141061 0.04519647 0.00591952 0.00091445 0.01664267]\n",
      "[0.03312792 0.00452208 0.08744277 0.00748642 0.0688557 ]\n",
      "[0.03448549 0.00448083 0.09096543 0.04932732 0.01564373]\n",
      "[0.05492812 0.02239335 0.14837285 0.01058015 0.019894  ]\n",
      "[0.0296239  0.00449167 0.07611671 0.05976806 0.00537865]\n",
      "[0.03325153 0.03379481 0.0856895  0.00627637 0.0170493 ]\n",
      "[0.06490017 0.0080522  0.17768351 0.03411276 0.0107048 ]\n",
      "[0.03550305 0.00479345 0.09420168 0.007894   0.06648132]\n",
      "[0.05061893 0.00431708 0.08005519 0.02646762 0.03882046]\n",
      "[0.10000057 0.02816042 0.02822948 0.0062756  0.00400123]\n",
      "[0.0050989  0.05048294 0.00414372 0.00060768 0.01003316]\n",
      "[0.08540347 0.00498064 0.08798915 0.01278198 0.04032191]\n",
      "[0.00554561 0.00117171 0.00860679 0.04493007 0.04386539]\n",
      "[0.0761267  0.00923916 0.20554206 0.02315713 0.01607815]\n",
      "[0.0564708  0.00707067 0.15366408 0.03657839 0.01425591]\n",
      "[0.06091257 0.00843944 0.08634585 0.02524342 0.02831691]\n",
      "[0.0434965  0.00320765 0.04971252 0.00706931 0.06991327]\n",
      "[0.12511864 0.02291129 0.03437407 0.00347709 0.00661334]\n",
      "[0.04223002 0.00943605 0.10602012 0.04584829 0.00694134]\n",
      "[0.00506566 0.04678053 0.00431524 0.00075762 0.01659967]\n",
      "[0.02921608 0.00384709 0.0759153  0.05514064 0.01253956]\n",
      "[0.10834168 0.01111367 0.03090721 0.00371191 0.03478979]\n",
      "[0.05917221 0.0231334  0.01848738 0.00250695 0.03490918]\n",
      "[0.15254157 0.00721815 0.13175051 0.010089   0.00995698]\n",
      "[0.02018453 0.0515969  0.00772142 0.00078228 0.00149906]\n",
      "[0.03181898 0.01087673 0.08288979 0.049231   0.00566627]\n",
      "[0.04442786 0.00562411 0.11927107 0.04947827 0.00764271]\n",
      "[0.03158418 0.0390959  0.08054962 0.00575915 0.0090157 ]\n",
      "[0.00554805 0.03554209 0.00626468 0.02896999 0.00136428]\n",
      "[0.06363604 0.0080077  0.1742595  0.0127217  0.03835728]\n",
      "[0.04834825 0.00274544 0.04231618 0.05896969 0.00410293]\n",
      "[0.18413243 0.00548065 0.0773171  0.00677268 0.00791429]\n",
      "[0.00734276 0.01120823 0.01300232 0.04614867 0.02304152]\n",
      "[0.03563756 0.02390522 0.09321054 0.00711347 0.03261468]\n",
      "[0.07464456 0.00731514 0.15297967 0.01175769 0.03770492]\n",
      "[0.0313791  0.00407648 0.08203983 0.05927202 0.00569098]\n",
      "[0.1557525  0.00704155 0.12621783 0.00975192 0.00974936]\n",
      "[0.15310369 0.01461703 0.06026921 0.00538351 0.00651281]\n",
      "[0.17319208 0.00608237 0.09616815 0.00792116 0.0086217 ]\n",
      "[0.0553898  0.00692424 0.15054813 0.04125078 0.00928231]\n",
      "[0.06809495 0.00686117 0.14249725 0.01289367 0.04038033]\n",
      "[0.12345571 0.0177953  0.0417089  0.0041244  0.01535082]\n",
      "[0.09026456 0.02659182 0.08769936 0.00665277 0.0066688 ]\n",
      "[0.07284571 0.01464626 0.02368475 0.03523005 0.00349208]\n",
      "[0.01800448 0.0027472  0.04432461 0.01485095 0.07156177]\n",
      "[0.03375847 0.00986278 0.0884983  0.04956548 0.00597305]\n",
      "[0.13901627 0.00796204 0.15505561 0.01150885 0.01083153]\n",
      "[0.04079833 0.00828671 0.01579981 0.02472181 0.04164714]\n",
      "[0.09392817 0.00483564 0.08329152 0.02297512 0.02464996]\n",
      "[0.04274722 0.00234389 0.02993642 0.03408689 0.03908072]\n",
      "[0.08846753 0.0093913  0.20568821 0.01460773 0.02156314]\n",
      "[0.04148439 0.02121035 0.01593313 0.03261171 0.00789031]\n",
      "[0.00495698 0.03467461 0.00487605 0.00124789 0.03807046]\n",
      "[0.05489381 0.00689057 0.14917659 0.03629172 0.01585241]\n",
      "[0.13315863 0.00350879 0.03789731 0.01831596 0.01992053]\n",
      "[0.10013403 0.0097819  0.11616726 0.0251867  0.00834972]\n",
      "[0.16572092 0.0051633  0.07314017 0.0065321  0.01645219]\n",
      "[0.05106382 0.01261093 0.1380483  0.01031011 0.040257  ]\n",
      "[0.03231606 0.03437551 0.01238479 0.0212109  0.00209686]\n",
      "[0.00488756 0.02694138 0.00523429 0.00156107 0.05178593]\n",
      "[0.0483264  0.00188515 0.01964435 0.06217557 0.00304124]\n",
      "[0.13526828 0.00816818 0.16151367 0.0119023  0.01107388]\n",
      "[0.03434265 0.00450378 0.09062704 0.04098194 0.0261566 ]\n",
      "[0.08663855 0.01143778 0.23965986 0.01663524 0.01394542]\n",
      "[0.00524829 0.00258249 0.00778207 0.03012105 0.06005349]\n",
      "[0.03353354 0.00570861 0.0881043  0.05567399 0.00599476]\n",
      "[0.04390572 0.00556218 0.11778129 0.04987016 0.00756462]\n",
      "[0.19831561 0.00470058 0.05287844 0.00528377 0.0069972 ]\n",
      "[0.15615094 0.01526846 0.04724562 0.00455141 0.00594012]\n",
      "[0.00505049 0.0450903  0.00439354 0.00082607 0.01959743]\n",
      "[0.11464339 0.00801406 0.16227044 0.01196188 0.0195257 ]\n",
      "[0.02448944 0.04508363 0.05987106 0.00425559 0.00409954]\n",
      "[0.02860872 0.02607886 0.07284367 0.02346585 0.01219253]\n",
      "[0.02815069 0.01598885 0.03058887 0.0475823  0.00308373]\n",
      "[0.08582723 0.01026333 0.22985713 0.01607261 0.01771863]\n",
      "[0.112877   0.0093997  0.20009551 0.01425287 0.01252172]\n",
      "[0.07905194 0.01829576 0.13496222 0.01533032 0.01252422]\n",
      "[0.02219221 0.02499904 0.05475999 0.00469554 0.04141013]\n",
      "[0.11480707 0.0174508  0.11935327 0.00894885 0.00865544]\n",
      "[0.02505149 0.00343259 0.06417052 0.0414335  0.032895  ]\n",
      "[0.06123804 0.01222746 0.06720342 0.02228666 0.02615955]\n",
      "[0.14916196 0.00606242 0.10178093 0.01182139 0.01307967]\n",
      "[0.01360386 0.05332938 0.00605319 0.00061598 0.00129595]\n",
      "[0.01954967 0.02532653 0.01475151 0.03832777 0.00209863]\n",
      "[0.06460648 0.02403301 0.16958758 0.01182906 0.01014879]\n",
      "[0.09670211 0.01775751 0.14431506 0.01048928 0.01191579]\n",
      "[0.00532653 0.03152047 0.00599678 0.02030917 0.01967631]\n",
      "[0.02994815 0.04453282 0.0528434  0.00383926 0.00386151]\n",
      "[0.08385101 0.00608979 0.1207749  0.03554496 0.00834397]\n",
      "[0.10698442 0.0097238  0.21024887 0.01487146 0.01290274]\n",
      "[0.08631875 0.01453044 0.07285948 0.00618887 0.03173983]\n",
      "[0.02165066 0.00321078 0.05478204 0.0055169  0.08032931]\n",
      "[0.03520569 0.00667116 0.0929005  0.04498935 0.01668738]\n",
      "[0.05757696 0.0137163  0.10456655 0.00869465 0.0396965 ]\n",
      "[0.04368086 0.03556055 0.01415546 0.00177627 0.01965646]\n",
      "[0.06410734 0.00797456 0.17544978 0.03123531 0.01491391]\n",
      "[0.10883642 0.00832665 0.03245133 0.03161294 0.00455271]\n",
      "[0.05069466 0.00559772 0.03108123 0.00394954 0.06771565]\n",
      "[0.01816282 0.0049817  0.01223927 0.06175303 0.01050375]\n",
      "[0.14114067 0.0078452  0.15139512 0.01128583 0.01069417]\n",
      "[0.15866369 0.00572786 0.09079252 0.01373608 0.00813757]\n",
      "[0.01370935 0.01582886 0.03121042 0.00358497 0.06437664]\n",
      "[0.09196838 0.00401345 0.06378173 0.04040224 0.00625163]\n",
      "[0.0775396  0.00382774 0.06287021 0.04591015 0.00553226]\n",
      "[0.11516838 0.00683345 0.13182116 0.02308671 0.00936223]\n",
      "[0.13740407 0.00805071 0.15783355 0.01167809 0.01093578]\n",
      "[0.02453572 0.00336936 0.06269534 0.04225806 0.03227267]\n",
      "[0.12114344 0.00505427 0.06463053 0.00602413 0.03573006]\n",
      "[0.15387364 0.0063905  0.10956909 0.01275447 0.00893991]\n",
      "[0.04444168 0.03428202 0.11759015 0.00822993 0.00726045]\n",
      "[0.04261867 0.00560642 0.11445054 0.00911506 0.05936796]\n",
      "[0.0901426  0.00459343 0.07961063 0.03916215 0.00651761]\n",
      "[0.05824121 0.00739133 0.15890748 0.01179593 0.04375039]\n",
      "[0.10082724 0.0079029  0.1625639  0.01198886 0.02523108]\n",
      "[0.0141088  0.02493039 0.03148067 0.02847587 0.01635413]\n",
      "[0.13033913 0.01776922 0.08146092 0.00658495 0.00711325]\n",
      "[0.1092323  0.01571187 0.14837225 0.01081332 0.00995413]\n",
      "[0.06477444 0.00483398 0.09288335 0.04611914 0.00673301]\n",
      "[0.09378042 0.03055072 0.042234   0.00368692 0.00453694]\n",
      "[0.14557361 0.01106107 0.1109226  0.00865684 0.00882068]\n",
      "[0.07086373 0.00682006 0.1422482  0.02564062 0.02335513]\n",
      "[0.14555702 0.0076023  0.14378542 0.01082222 0.01040861]\n",
      "[0.05136994 0.01172284 0.13876179 0.03667633 0.0086103 ]\n",
      "[0.13687393 0.00828147 0.09639906 0.01682202 0.00802419]\n",
      "[0.01531741 0.00231975 0.03646913 0.03991131 0.04244128]\n",
      "[0.06673925 0.00604659 0.09779326 0.00805882 0.05121185]\n",
      "[0.08502034 0.00425687 0.07213833 0.04199906 0.00608584]\n",
      "[0.0885655  0.00779139 0.16434198 0.02775815 0.01045894]\n",
      "[0.05573858 0.00926581 0.04564913 0.01261331 0.04723215]\n",
      "[0.02007015 0.02699361 0.04856032 0.00423725 0.03958   ]\n",
      "[0.00820201 0.00421726 0.0158209  0.06261615 0.01459995]\n",
      "[0.11300381 0.00330506 0.03554738 0.00429153 0.04614442]\n",
      "[0.05944846 0.02087444 0.16131986 0.01882215 0.00970873]\n",
      "[0.02080192 0.01260447 0.05136463 0.04242232 0.01741836]\n",
      "[0.03023748 0.02041944 0.07779324 0.03641559 0.00529922]\n",
      "[0.04896042 0.00616169 0.13220356 0.04607635 0.00832066]\n",
      "[0.10556094 0.00753888 0.15160889 0.01132252 0.02549772]\n",
      "[0.13394185 0.00824114 0.16379922 0.01204155 0.01115965]\n",
      "[0.03984347 0.00224182 0.01654711 0.03968666 0.03422252]\n",
      "[0.0552305  0.00327355 0.05435707 0.05487574 0.00477674]\n",
      "[0.06400479 0.00379925 0.0605695  0.00583899 0.06147064]\n",
      "[0.0453645  0.01004252 0.12168496 0.04257679 0.00772504]\n",
      "[0.0814792  0.01004631 0.22503563 0.01578363 0.02051979]\n",
      "[0.0178148  0.00767724 0.0431799  0.04377341 0.0264087 ]\n",
      "[0.00508566 0.00122219 0.00747663 0.02301828 0.07153489]\n",
      "[0.00543587 0.0411051  0.00560983 0.02102956 0.00127271]\n",
      "[0.12246881 0.01171183 0.09975683 0.01230228 0.01302853]\n",
      "[0.11278424 0.01136818 0.11908586 0.01843041 0.00867456]\n",
      "[0.02457257 0.003281   0.06263963 0.06187927 0.00779034]\n",
      "[0.13605912 0.00560561 0.09374645 0.02118686 0.00791413]\n",
      "[0.0475148  0.01327433 0.12787199 0.00965611 0.0419168 ]\n",
      "[0.06145186 0.0119944  0.16758343 0.0304393  0.01013067]\n",
      "[0.12709062 0.00949204 0.16730887 0.01221413 0.01120174]\n",
      "[0.07315133 0.00421253 0.05778548 0.04725478 0.00521741]\n",
      "[0.11377763 0.01684484 0.12741531 0.00947128 0.00902591]\n",
      "[0.17333869 0.01127622 0.04654668 0.00465258 0.00622627]\n",
      "[0.0878618  0.01077554 0.24319856 0.0168789  0.01413922]\n",
      "[0.11031394 0.02048089 0.10068343 0.0076801  0.00766951]\n",
      "[0.06716697 0.02451151 0.02071926 0.0106232  0.01885655]\n",
      "[0.0636651  0.00675077 0.14062867 0.01324905 0.04203061]\n",
      "[0.16696653 0.0121528  0.04502199 0.00564057 0.00604234]\n",
      "[0.07324965 0.00236893 0.02488937 0.04676394 0.01116611]\n",
      "[0.08533745 0.00695    0.14304444 0.03188608 0.00941027]\n",
      "[0.04516373 0.02229807 0.09080351 0.02744119 0.00634383]\n",
      "[0.13499689 0.00357866 0.03768952 0.00440653 0.03652838]\n",
      "[0.0440696  0.02386063 0.11726065 0.01064079 0.02340848]\n",
      "[0.09765137 0.0176145  0.13999227 0.01022663 0.01238882]\n",
      "[0.03126195 0.04570979 0.0387238  0.00292009 0.00320358]\n",
      "[0.11617241 0.00457244 0.07194526 0.03118386 0.00657531]\n",
      "[0.03695083 0.03722068 0.02540773 0.01443444 0.00275632]\n",
      "[0.03242194 0.00270565 0.04561902 0.06404689 0.00400269]\n",
      "[0.04067909 0.00517949 0.10857494 0.05229191 0.007082  ]\n",
      "[0.16447849 0.0053171  0.07837602 0.01346383 0.00764936]\n",
      "[0.06354704 0.00657512 0.13646002 0.01756932 0.03722954]\n",
      "[0.00522083 0.01855985 0.0066233  0.02134148 0.04202008]\n",
      "[0.05245788 0.00673057 0.14244989 0.0108035  0.04953189]\n",
      "[0.00481241 0.01857128 0.00562203 0.00190005 0.06663095]\n",
      "[0.12454054 0.01638774 0.09345395 0.00947676 0.00760068]\n",
      "[0.06980831 0.00740789 0.11183352 0.0350356  0.01277155]\n",
      "[0.12761861 0.01187217 0.03625157 0.01990853 0.00499725]\n",
      "[0.11912071 0.009001   0.03360459 0.00395484 0.03383928]\n",
      "[0.0556606  0.0025385  0.03254339 0.03786449 0.02863268]\n",
      "[0.14921037 0.00740137 0.13749041 0.0104387  0.01017238]\n",
      "[0.14649655 0.00755063 0.14216652 0.01072359 0.01034785]\n",
      "[0.05453787 0.01375468 0.04464557 0.04080713 0.00419619]\n",
      "[0.07614587 0.00942935 0.2098454  0.01648419 0.02383773]\n",
      "[0.07453396 0.00751084 0.15929094 0.02055101 0.02596792]\n",
      "[0.0479682  0.00441481 0.08546949 0.04479516 0.01636909]\n",
      "[0.00734451 0.05436543 0.01027315 0.00084044 0.00138338]\n",
      "[0.10264779 0.00770801 0.15829618 0.0237097  0.01040126]\n",
      "[0.1706688  0.00622115 0.10051594 0.00818605 0.00878486]\n",
      "[0.12092732 0.00602839 0.10902584 0.02429802 0.00838726]\n",
      "[0.10020542 0.00311316 0.03539939 0.02091772 0.03077656]\n",
      "[0.06685152 0.03889449 0.01959885 0.00255897 0.0029461 ]\n",
      "[0.04253367 0.01242849 0.02913729 0.03340248 0.02168393]\n",
      "[0.02241412 0.00928118 0.03949373 0.05841217 0.00348269]\n",
      "[0.10079956 0.00443787 0.07169192 0.02878084 0.01603322]\n",
      "[0.08732459 0.0140841  0.08335076 0.00685506 0.03067207]\n",
      "[0.0425724  0.03193705 0.01464514 0.01441702 0.01081118]\n",
      "[0.09341279 0.00830822 0.17563398 0.01581873 0.02186623]\n",
      "[0.02581003 0.00869457 0.05173006 0.0570725  0.00412134]\n",
      "[0.05475662 0.02553191 0.14761991 0.01484046 0.00893704]\n",
      "[0.00473829 0.00151329 0.0066058  0.00635096 0.0921207 ]\n",
      "[0.08476097 0.0144002  0.21576017 0.01504427 0.01275542]\n",
      "[0.08849912 0.00682316 0.13853318 0.03140541 0.00924955]\n",
      "[0.0244966  0.03941268 0.03660057 0.00884027 0.01010475]\n",
      "[0.13810179 0.01591651 0.03813884 0.010413   0.00521248]\n",
      "[0.1216774  0.02158613 0.03360988 0.00348078 0.0104555 ]\n",
      "[0.03526763 0.02558235 0.07483042 0.02753933 0.00518577]\n",
      "[0.02840989 0.0429612  0.0712124  0.00503652 0.00472064]\n",
      "[0.01058947 0.00194702 0.02330531 0.00361877 0.09138698]\n",
      "[0.0056675  0.02694056 0.00714492 0.03867762 0.00476182]\n",
      "[0.04155824 0.01825206 0.11030483 0.03296996 0.00703957]\n",
      "[0.13538488 0.01036747 0.07206278 0.00627973 0.01954026]\n",
      "[0.14079748 0.00786408 0.15198644 0.01132186 0.01071636]\n",
      "[0.00478142 0.00125558 0.00672906 0.00852417 0.08983759]\n",
      "[0.05382984 0.01980934 0.14531251 0.02361298 0.00887369]\n",
      "[0.02213588 0.00901898 0.04101253 0.05875248 0.00355269]\n",
      "[0.05834718 0.01379834 0.12384658 0.03264175 0.00799655]\n",
      "[0.00516296 0.02461386 0.00606793 0.01575556 0.03804939]\n",
      "[0.04766106 0.01153593 0.12824012 0.03020148 0.0192135 ]\n",
      "[0.04566441 0.00577077 0.12279925 0.04855018 0.00782767]\n",
      "[0.17194949 0.00616297 0.09819292 0.00804394 0.00869643]\n",
      "[0.1312127  0.00839124 0.16850174 0.01232804 0.01133612]\n",
      "[0.03571014 0.01835258 0.0935711  0.03621647 0.00615421]\n",
      "[0.14006    0.00597529 0.10117669 0.00824648 0.02142259]\n",
      "[0.14130528 0.00924275 0.03893357 0.00426834 0.02376043]\n",
      "[0.12404579 0.00918795 0.06786949 0.02224718 0.00646091]\n",
      "[0.08936462 0.00642225 0.12803236 0.03260216 0.00877195]\n",
      "[0.14516766 0.00553746 0.08814023 0.00745388 0.02195915]\n",
      "[0.01499573 0.01152909 0.03473005 0.05804757 0.00311448]\n",
      "[0.17916836 0.00436132 0.04828539 0.00501849 0.01592728]\n",
      "[0.04585863 0.0057938  0.1233534  0.04840441 0.00785672]\n",
      "[0.04508097 0.01378062 0.12064954 0.03736188 0.00763205]\n",
      "[0.0360878  0.01151956 0.09506156 0.04583056 0.00630294]\n",
      "[0.06955631 0.02212938 0.16134639 0.01364074 0.00985957]\n",
      "[0.08937211 0.00392474 0.05790895 0.005661   0.05142944]\n",
      "[0.03778489 0.0086136  0.100439   0.00813578 0.05791274]\n",
      "[0.04784509 0.03067104 0.12756298 0.00898229 0.01092347]\n",
      "[0.05917003 0.02894302 0.01822935 0.00279148 0.02397397]\n",
      "[0.03567066 0.0060292  0.09419801 0.05397338 0.00631352]\n",
      "[0.00507964 0.04007677 0.00480747 0.00455845 0.02401773]\n",
      "[0.00471456 0.00126292 0.00656479 0.00533915 0.09385952]\n",
      "[0.0404156  0.00351938 0.06432332 0.05379509 0.01103211]\n",
      "[0.07928459 0.00669674 0.07372616 0.04024876 0.00604259]\n",
      "[0.14209495 0.00779272 0.14975081 0.01118565 0.01063247]\n",
      "[0.0048007  0.01726615 0.00568249 0.00195291 0.0689457 ]\n",
      "[0.02545095 0.03309384 0.05554448 0.00443845 0.02561284]\n",
      "[0.06755918 0.03697043 0.01997497 0.00506962 0.00299562]\n",
      "[0.02265669 0.00327715 0.05756065 0.01598118 0.0664974 ]\n",
      "[0.06455157 0.00801086 0.17668887 0.0343744  0.01065266]\n",
      "[0.05987792 0.01338757 0.16308532 0.01907702 0.0227616 ]\n",
      "[0.06988667 0.00475102 0.08806233 0.03438661 0.01985239]\n",
      "[0.14540215 0.00569493 0.09233495 0.00770766 0.02100283]\n",
      "[0.04612223 0.0145401  0.12365192 0.02750142 0.01802358]\n",
      "[0.01561268 0.04629227 0.03445063 0.00263877 0.00904702]\n",
      "[0.05656979 0.00578647 0.12023343 0.04511653 0.00788206]\n",
      "[0.05869752 0.00896025 0.02116346 0.048372   0.00320522]\n",
      "[0.19281514 0.00459733 0.05165967 0.00737013 0.00685213]\n",
      "[0.06543705 0.0118552  0.07669068 0.03715527 0.00590489]\n",
      "[0.02295603 0.02283401 0.05682072 0.03716319 0.00416616]\n",
      "[0.0981168  0.01037934 0.20149047 0.01763399 0.0123394 ]\n",
      "[0.11493726 0.00996203 0.12063873 0.01961011 0.00879744]\n",
      "[0.01408491 0.026026   0.03138606 0.02228288 0.02214607]\n",
      "[0.01842307 0.00964791 0.04491563 0.02719578 0.04327552]\n",
      "[0.05297449 0.01151046 0.12076435 0.03800145 0.00778866]\n",
      "[0.00617139 0.00463055 0.00990342 0.07309196 0.00187309]\n",
      "[0.08187062 0.01610888 0.13588781 0.02043071 0.00891964]\n",
      "[0.02913468 0.00488803 0.07557126 0.05940563 0.00534083]\n",
      "[0.0370257  0.04429213 0.03923823 0.00300336 0.00333573]\n",
      "[0.10887672 0.01040679 0.19951857 0.01418059 0.01241937]\n",
      "[0.13388476 0.02077036 0.04501842 0.00421392 0.00541802]\n",
      "[0.14211341 0.0077917  0.149719   0.01118372 0.01063127]\n",
      "[0.0958805  0.01826519 0.15411543 0.0110774  0.00998317]\n",
      "[0.08922479 0.00745635 0.15533013 0.02879997 0.01004761]\n",
      "[0.03423784 0.03714942 0.04783664 0.00380556 0.01594982]\n",
      "[0.05640628 0.0070448  0.15344839 0.04048786 0.00943435]\n",
      "[0.11958245 0.00845442 0.17298011 0.01260691 0.01527286]\n",
      "[0.03268741 0.00537635 0.04797304 0.01623627 0.05890217]\n",
      "[0.03928931 0.02353734 0.10349755 0.02667985 0.00662571]\n",
      "[0.05144398 0.00471979 0.02002086 0.0570108  0.00307926]\n",
      "[0.0878618  0.01077554 0.24319856 0.0168789  0.01413922]\n",
      "[0.09591558 0.00525244 0.09540526 0.03492476 0.00734939]\n",
      "[0.04106644 0.00542907 0.11003336 0.00884869 0.0609197 ]\n",
      "[0.09921147 0.01789125 0.02838059 0.00330347 0.02676764]\n",
      "[0.04699167 0.02259635 0.11897232 0.01690463 0.01657125]\n",
      "[0.09895482 0.00799412 0.16684741 0.02378872 0.01074248]\n",
      "[0.14435607 0.00739511 0.04050258 0.0204328  0.00551499]\n",
      "[0.10983412 0.00890758 0.18753662 0.01349463 0.01636174]\n",
      "[0.07895406 0.01102048 0.21775903 0.01529717 0.02081373]\n",
      "[0.12756053 0.01274326 0.03545494 0.0039258  0.02354511]\n",
      "[0.11988381 0.00721652 0.14063073 0.02020277 0.0098501 ]\n",
      "[0.0525871  0.0102417  0.018168   0.0167367  0.04322217]\n",
      "[0.05131921 0.00816786 0.13909681 0.01054214 0.04790153]\n",
      "[0.10598593 0.02900808 0.02947246 0.00295054 0.00414738]\n",
      "[0.08411377 0.0050731  0.09390236 0.03924437 0.00709018]\n",
      "[0.04440859 0.00384522 0.0723808  0.05607633 0.00547648]\n",
      "[0.0109509  0.01285588 0.02347366 0.01240359 0.06030928]\n",
      "[0.05712837 0.02736293 0.15429403 0.01083022 0.009271  ]\n",
      "[0.09918254 0.01912618 0.10469021 0.01299854 0.00769367]\n",
      "[0.0708863  0.00876218 0.19476336 0.02961987 0.01160016]\n",
      "[0.15368552 0.00635566 0.10870208 0.01294225 0.00889631]\n",
      "[0.02838277 0.00380996 0.07364471 0.04269162 0.02870926]\n",
      "[0.07091708 0.00558011 0.10699379 0.00864477 0.0490852 ]\n",
      "[0.09564341 0.01999428 0.06040691 0.01674441 0.00553665]\n",
      "[0.00529664 0.03607483 0.00561242 0.01675657 0.01586616]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12062993 0.00794622 0.1096058  0.01305469 0.01908861]\n",
      "[0.1625458  0.01174883 0.06629191 0.00586126 0.00697964]\n",
      "[0.01455117 0.00229224 0.03439275 0.0270598  0.05905989]\n",
      "[0.08365235 0.00300627 0.03447952 0.00424647 0.05861123]\n",
      "[0.01376917 0.0023103  0.03235375 0.00416441 0.08820829]\n",
      "[0.1440478  0.00768531 0.14638591 0.01098065 0.01050619]\n",
      "[0.13493138 0.00818671 0.16209417 0.01193767 0.01109567]\n",
      "[0.14329699 0.0077266  0.14767962 0.01105947 0.01055474]\n",
      "[0.008243   0.01195284 0.01587025 0.00495826 0.07285603]\n",
      "[0.16320969 0.00620454 0.10211616 0.01055644 0.00874041]\n",
      "[0.09109895 0.00614938 0.12036539 0.03308009 0.00844078]\n",
      "[0.08239386 0.00324177 0.04481553 0.03575177 0.01850509]\n",
      "[0.11077203 0.01490197 0.03213998 0.02149879 0.00449965]\n",
      "[0.03981266 0.03678805 0.10419902 0.00730786 0.0065271 ]\n",
      "[0.11895233 0.00486325 0.07619082 0.00674799 0.03534423]\n",
      "[0.07063195 0.01867296 0.06379659 0.00547698 0.03193935]\n",
      "[0.1314843  0.00506644 0.0807835  0.02460778 0.00723408]\n",
      "[0.10227888 0.02208389 0.10350921 0.00779748 0.00765651]\n",
      "[0.05420568 0.00533731 0.10903925 0.0475185  0.00732019]\n",
      "[0.07577566 0.00470164 0.08638879 0.04320636 0.00660502]\n",
      "[0.0581108  0.00354369 0.05695532 0.02139733 0.04499546]\n",
      "[0.0817444  0.00263511 0.02491529 0.00366875 0.06136478]\n",
      "[0.10016205 0.00428455 0.06873068 0.03720972 0.00616862]\n",
      "[0.11438326 0.00472059 0.07342902 0.00658385 0.0378161 ]\n",
      "[0.08395526 0.03448056 0.02699583 0.00259863 0.00361761]\n",
      "[0.07905628 0.00255425 0.02484844 0.01604632 0.04705848]\n",
      "[0.07665476 0.01552991 0.09984819 0.00782594 0.03009818]\n",
      "[0.05050336 0.01476285 0.0954395  0.03631236 0.00651874]\n",
      "[0.03040812 0.01840843 0.07841629 0.03754091 0.00744722]\n",
      "[0.14513313 0.00373576 0.0419766  0.02533175 0.00563581]\n",
      "[0.059818   0.00757148 0.16339453 0.01206651 0.0421741 ]\n",
      "[0.04898988 0.02184256 0.13146526 0.00955576 0.02560485]\n",
      "[0.08063378 0.00957505 0.21352778 0.02358021 0.01263456]\n",
      "[0.07981127 0.02222446 0.15261613 0.01084096 0.00961159]\n",
      "[0.0878618  0.01077554 0.24319856 0.0168789  0.01413922]\n",
      "[0.03858287 0.00493087 0.10259393 0.05386523 0.00676847]\n",
      "[0.03801264 0.00989256 0.10066496 0.04705575 0.00661572]\n",
      "[0.08089237 0.00898657 0.19794433 0.02568854 0.01190919]\n",
      "[0.16475314 0.00407489 0.04536682 0.01640398 0.00813016]\n",
      "[0.09378042 0.03055072 0.042234   0.00368692 0.00453694]\n",
      "[0.13633202 0.00810968 0.15968077 0.01179063 0.0110051 ]\n",
      "[0.0145961  0.00870928 0.03401305 0.03222076 0.04088369]\n",
      "[0.04354467 0.00551936 0.11675113 0.05014115 0.00751061]\n",
      "[0.06682901 0.00234739 0.02174496 0.01221682 0.05734851]\n",
      "[0.16790044 0.00637341 0.10528603 0.00847667 0.00896387]\n",
      "[0.07196963 0.00517954 0.10002664 0.04260718 0.00718255]\n",
      "[0.11634143 0.00676594 0.12972103 0.0229747  0.00928269]\n",
      "[0.03597813 0.00656505 0.09504532 0.05302398 0.00635281]\n",
      "[0.00489273 0.00124337 0.00700256 0.01382678 0.08314162]\n",
      "[0.12245091 0.01371448 0.13765201 0.01022013 0.00968209]\n",
      "[0.00954544 0.02070297 0.01897632 0.0026453  0.05908918]\n",
      "[0.15161192 0.00645279 0.11182905 0.01322285 0.00900951]\n",
      "[0.00491763 0.001299   0.00716498 0.00264547 0.09705702]\n",
      "[0.0740137  0.0091331  0.20368658 0.0272726  0.01206793]\n",
      "[0.14412775 0.00768091 0.14624814 0.01097226 0.01050102]\n",
      "[0.00465708 0.00126923 0.00642355 0.00260076 0.09731748]\n",
      "[0.08972008 0.00572787 0.06682806 0.03876737 0.00589528]\n",
      "[0.02018958 0.01013071 0.04975431 0.04719533 0.01628223]\n",
      "[0.00547458 0.00764396 0.00801052 0.03618774 0.04310227]\n",
      "[0.01685392 0.00824652 0.04073026 0.00445879 0.07526126]\n",
      "[0.05825476 0.00626184 0.12926994 0.01717606 0.04086149]\n",
      "[0.07016763 0.00949702 0.19266359 0.02897914 0.01148166]\n",
      "[0.12586157 0.00777929 0.15325851 0.01140883 0.01668873]\n",
      "[0.085156   0.00864675 0.18782157 0.02563259 0.01150353]\n",
      "[0.00624268 0.0010952  0.01031958 0.07813817 0.00193128]\n",
      "[0.13315863 0.00350879 0.03789731 0.01831596 0.01992053]\n",
      "[0.06621966 0.00830288 0.18161167 0.01316505 0.03577448]\n",
      "[0.00465708 0.00126923 0.00642355 0.00260076 0.09731748]\n",
      "[0.13070032 0.00350253 0.03665886 0.004347   0.03853225]\n",
      "[0.12102308 0.0102298  0.1739291  0.0125984  0.01140875]\n",
      "[0.0048651  0.0244401  0.00535016 0.00166237 0.05622216]\n",
      "[0.06810374 0.00225639 0.02402654 0.0546739  0.00356286]\n",
      "[0.01938431 0.00688907 0.04756154 0.06218001 0.0038401 ]\n",
      "[0.15003152 0.0073562  0.13607551 0.0103525  0.01011928]\n",
      "[0.00507588 0.03421618 0.00519862 0.00712053 0.03146656]\n",
      "[0.11818077 0.01559721 0.12937062 0.00963785 0.00920237]\n",
      "[0.01010954 0.00162972 0.02148431 0.05915431 0.02255169]\n",
      "[0.06155023 0.00887209 0.1682446  0.01231736 0.03849459]\n",
      "[0.09976373 0.02647541 0.03189085 0.00847213 0.0041881 ]\n",
      "[0.08125429 0.03551915 0.02320288 0.00232555 0.00338402]\n",
      "[0.04728833 0.00706497 0.12736655 0.04574609 0.00805579]\n",
      "[0.08096059 0.02492742 0.09978305 0.00746687 0.01168422]\n",
      "[0.08366372 0.0102959  0.23125209 0.0161585  0.01833597]\n",
      "[0.11480031 0.01665342 0.12693603 0.00944846 0.00902178]\n",
      "[0.18634874 0.00535876 0.07349824 0.00654002 0.00777099]\n",
      "[0.0141088  0.02493039 0.03148067 0.02847587 0.01635413]\n",
      "[0.02713556 0.00363477 0.07003881 0.04940602 0.02132136]\n",
      "[0.02468207 0.00343601 0.06319842 0.03170138 0.04531416]\n",
      "[0.04176241 0.00530798 0.11166592 0.05147882 0.00724404]\n",
      "[0.1213214  0.00820507 0.16583447 0.01217318 0.0160096 ]\n",
      "[0.06015784 0.01408534 0.05958382 0.03716882 0.00498854]\n",
      "[0.00828202 0.01996076 0.00660795 0.00658964 0.05675471]\n",
      "[0.02020326 0.00397105 0.02620027 0.0679646  0.00287559]\n",
      "[0.07547603 0.00387813 0.06476231 0.04636146 0.00558782]\n",
      "[0.02165066 0.00321078 0.05478204 0.0055169  0.08032931]\n",
      "[0.07632798 0.00613337 0.12120006 0.01421739 0.03803717]\n",
      "[0.01467899 0.05304633 0.00632574 0.00064315 0.00132913]\n",
      "[0.04455132 0.00582723 0.11995026 0.00944671 0.05743593]\n",
      "[0.00491721 0.01013754 0.00645492 0.0108319  0.07070518]\n",
      "[0.04116951 0.00537283 0.1102087  0.02328033 0.04285295]\n",
      "[0.07131234 0.01071876 0.19586452 0.02655719 0.01163832]\n",
      "[0.029664   0.01173595 0.07667419 0.04924415 0.005329  ]\n",
      "[0.0944609  0.00595154 0.11423148 0.03277527 0.00820743]\n",
      "[0.12298809 0.00667148 0.12541487 0.0212688  0.00918747]\n",
      "[0.11538402 0.01036248 0.18532985 0.01330136 0.01185477]\n",
      "[0.11312085 0.01247801 0.08252061 0.00685544 0.02328044]\n",
      "[0.0310105  0.02212007 0.07990225 0.03352003 0.00539327]\n",
      "[0.17927188 0.00965456 0.04861677 0.00483982 0.00643676]\n",
      "[0.10526916 0.00781576 0.0524761  0.0318112  0.0054461 ]\n",
      "[0.0951697  0.0049415  0.08741244 0.03631189 0.00696329]\n",
      "[0.0518171  0.00697457 0.1403259  0.04325006 0.00874158]\n",
      "[0.06643059 0.00452989 0.07971381 0.00699631 0.05654038]\n",
      "[0.0048164  0.0190152  0.00560147 0.00188207 0.06584363]\n",
      "[0.05957048 0.00576298 0.11645282 0.02448162 0.03285418]\n",
      "[0.01859639 0.00286101 0.04608912 0.00516629 0.08316636]\n",
      "[0.07182471 0.00887348 0.19744088 0.02891555 0.01174052]\n",
      "[0.04238729 0.01916442 0.09655707 0.0159788  0.02721279]\n",
      "[0.0653607  0.00810682 0.1789975  0.03376712 0.01077368]\n",
      "[0.0444317  0.0110418  0.1189568  0.04167969 0.00757063]\n",
      "[0.04165914 0.00370689 0.06947575 0.05735808 0.00540252]\n",
      "[0.13791588 0.01314104 0.10837466 0.00842335 0.008555  ]\n",
      "[0.02435982 0.01168404 0.06150543 0.05239461 0.0045279 ]\n",
      "[0.07028237 0.01451548 0.11660184 0.02691703 0.00951981]\n",
      "[0.05857773 0.01092847 0.15942636 0.03363988 0.0097105 ]\n",
      "[0.0224772  0.00306809 0.0567228  0.05590644 0.0168807 ]\n",
      "[0.06159499 0.00606031 0.04115676 0.04987006 0.00422656]\n",
      "[0.02284225 0.02079899 0.05661741 0.04015769 0.00417625]\n",
      "[0.053214   0.01144337 0.14405326 0.03600919 0.0088928 ]\n",
      "[0.0804072  0.0098914  0.22192878 0.02247396 0.01302422]\n",
      "[0.01952707 0.01206994 0.0478646  0.03051449 0.03406835]\n",
      "[0.11590795 0.009233   0.19487297 0.01393469 0.01232573]\n",
      "[0.02824389 0.00303926 0.05555485 0.06409942 0.00440096]\n",
      "[0.12905491 0.00513303 0.08320264 0.02511206 0.00730845]\n",
      "[0.05141907 0.04337382 0.01563952 0.0015716  0.00246314]\n",
      "[0.03943553 0.00509667 0.10513893 0.03952236 0.02397356]\n",
      "[0.02710498 0.02236551 0.0687322  0.03356964 0.00713601]\n",
      "[0.17246099 0.00913285 0.06885882 0.00611534 0.00728826]\n",
      "[0.04838218 0.01541911 0.03527399 0.03251589 0.01461691]\n",
      "[0.05023453 0.0063128  0.13583891 0.04512007 0.00851123]\n",
      "[0.07828704 0.00744015 0.15769382 0.03057403 0.01210291]\n",
      "[0.14693638 0.00375019 0.04124968 0.01952399 0.01221989]\n",
      "[0.01388708 0.00217396 0.03242941 0.03593201 0.04852455]\n",
      "[0.10582394 0.01039993 0.09535584 0.01980401 0.01296407]\n",
      "[0.05282692 0.01360646 0.04020473 0.04197424 0.00396052]\n",
      "[0.04886205 0.01507781 0.13150019 0.0200169  0.02485787]\n",
      "[0.05530208 0.0036162  0.05889169 0.01572003 0.05300126]\n",
      "[0.14254717 0.00776784 0.14897161 0.01113818 0.01060322]\n",
      "[0.11813132 0.02127164 0.03277145 0.00344187 0.0125547 ]\n",
      "[0.14547925 0.01727464 0.03963544 0.00586514 0.00538764]\n",
      "[0.12777233 0.00670683 0.12503956 0.0196566  0.00924645]\n",
      "[0.10193551 0.01407714 0.18026844 0.01285263 0.01135983]\n",
      "[0.01840669 0.0025379  0.04502641 0.06900847 0.00375067]\n",
      "[0.02893635 0.03123991 0.0734392  0.01957506 0.00749695]\n",
      "[0.0967042  0.0033723  0.04449874 0.0321247  0.01708659]\n",
      "[0.15142742 0.00584417 0.09583598 0.01554318 0.00825787]\n",
      "[0.05912072 0.00453155 0.0815015  0.00710941 0.0592249 ]\n",
      "[0.03933862 0.00513096 0.10494184 0.02989291 0.03605063]\n",
      "[0.06487352 0.00670527 0.14218465 0.03912981 0.00904255]\n",
      "[0.03216785 0.00441239 0.08471073 0.00732167 0.06981546]\n",
      "[0.12630489 0.02135131 0.04705292 0.00572406 0.0053858 ]\n",
      "[0.08898215 0.00468519 0.0823466  0.03918009 0.00662712]\n",
      "[0.0865952  0.01608271 0.16534445 0.0163533  0.01038682]\n",
      "[0.05106631 0.00699411 0.13817718 0.04365731 0.00862782]\n",
      "[0.0371485  0.00476075 0.09850132 0.05494179 0.00655393]\n",
      "[0.12515411 0.00333416 0.03654781 0.03046191 0.00829173]\n",
      "[0.13934589 0.01779925 0.0609553  0.00531087 0.00628988]\n",
      "[0.10075415 0.01006646 0.22098408 0.0155255  0.01330559]\n",
      "[0.01436484 0.00800613 0.03364395 0.0040298  0.07767185]\n",
      "[0.0440761  0.01300152 0.02609423 0.04698009 0.0031597 ]\n",
      "[0.07483087 0.00928673 0.20611654 0.01464276 0.027166  ]\n",
      "[0.06342596 0.00792726 0.17356379 0.02464379 0.02366418]\n",
      "[0.16790757 0.00515334 0.07312209 0.0130115  0.00745828]\n",
      "[0.05653394 0.01472781 0.04578874 0.03863822 0.00427203]\n",
      "[0.06797441 0.0155361  0.07006961 0.03156532 0.00559422]\n",
      "[0.04128309 0.0048975  0.1009765  0.05315359 0.00673596]\n",
      "[0.0618886  0.01882557 0.10010916 0.02624975 0.00687968]\n",
      "[0.07354267 0.00426425 0.07471874 0.0391808  0.01406703]\n",
      "[0.11369492 0.00634539 0.11935822 0.02535768 0.00875522]\n",
      "[0.05708923 0.01715587 0.15479485 0.02554144 0.00940198]\n",
      "[0.00524829 0.00258249 0.00778207 0.03012105 0.06005349]\n",
      "[0.08781438 0.01077012 0.2430636  0.01687076 0.01418662]\n",
      "[0.05080588 0.00756367 0.13739806 0.0429887  0.00858082]\n",
      "[0.08696114 0.00767637 0.08969789 0.00748937 0.04131948]\n",
      "[0.01818196 0.0239125  0.04337742 0.00589    0.04419978]\n",
      "[0.15863801 0.00688285 0.1212459  0.00944901 0.00956278]\n",
      "[0.02922616 0.00719543 0.07598227 0.02226995 0.04769041]\n",
      "[0.0929634  0.00544142 0.08538965 0.03649929 0.00682695]\n",
      "[0.07849978 0.0254125  0.02339161 0.01048866 0.01266297]\n",
      "[0.07338979 0.01257226 0.13751231 0.02822304 0.0088971 ]\n",
      "[0.11840975 0.01734457 0.11227321 0.00851316 0.00838033]\n",
      "[0.03372364 0.01767663 0.0881965  0.00703795 0.04514401]\n",
      "[0.05474259 0.0069916  0.14895149 0.01119556 0.0472479 ]\n",
      "[0.08329094 0.01058391 0.02490219 0.00336834 0.04662521]\n",
      "[0.01114995 0.00910979 0.0238993  0.06090772 0.00614372]\n",
      "[0.02669267 0.00363334 0.06886378 0.03890965 0.03475074]\n",
      "[0.00482943 0.01244152 0.00608249 0.00557714 0.07315831]\n",
      "[0.0685755  0.01996693 0.18749586 0.0130898  0.01329128]\n",
      "[0.1407562  0.00786635 0.15205757 0.01132619 0.01071903]\n",
      "[0.00478151 0.00485537 0.00648335 0.00684464 0.0853963 ]\n",
      "[0.00465708 0.00126923 0.00642355 0.00260076 0.09731748]\n",
      "[0.0351742  0.00684906 0.09302301 0.01856889 0.04953582]\n",
      "[0.16808031 0.01120978 0.05898258 0.00542701 0.00672941]\n",
      "[0.09018111 0.02018576 0.11484799 0.00857517 0.01431256]\n",
      "[0.07955502 0.02591631 0.06751495 0.01293701 0.0055504 ]\n",
      "[0.08935924 0.02269863 0.12668032 0.00921369 0.00853586]\n",
      "[0.12836511 0.00509294 0.08014679 0.00698119 0.0306067 ]\n",
      "[0.09083213 0.01970003 0.15183192 0.01088368 0.00977884]\n",
      "[0.1678242  0.00940504 0.04552491 0.00927992 0.00610897]\n",
      "[0.08533852 0.0059149  0.1128293  0.01097372 0.03939657]\n",
      "[0.08028772 0.01722876 0.02467411 0.02065264 0.01403035]\n",
      "[0.04799093 0.03842974 0.02979747 0.00863229 0.00312866]\n",
      "[0.04473983 0.03765839 0.01430868 0.00170647 0.01548327]\n",
      "[0.07838198 0.00921227 0.13558889 0.03157882 0.00892226]\n",
      "[0.14161568 0.00781908 0.15057663 0.01123597 0.01066346]\n",
      "[0.1555353  0.0070535  0.12659209 0.00977472 0.0097634 ]\n",
      "[0.12279807 0.0067106  0.12514088 0.00970872 0.02372154]\n",
      "[0.05027581 0.02058724 0.13510003 0.02455442 0.00832602]\n",
      "[0.02194817 0.01935724 0.00970918 0.00211786 0.05778544]\n",
      "[0.02645841 0.02510751 0.0667023  0.03186057 0.0046651 ]\n",
      "[0.0131139  0.01385007 0.02943537 0.02913404 0.03625933]\n",
      "[0.01700372 0.04913619 0.03821593 0.00276449 0.00291363]\n",
      "[0.0274476  0.01866813 0.06992815 0.03939919 0.00634961]\n",
      "[0.13806274 0.00720859 0.12437109 0.01086589 0.01527091]\n",
      "[0.13712354 0.00806614 0.15831693 0.01170754 0.01095392]\n",
      "[0.0211677  0.01739125 0.05218818 0.02773989 0.02692362]\n",
      "[0.05689723 0.01315085 0.13034712 0.03349895 0.00828696]\n",
      "[0.0509997  0.02063403 0.13716779 0.02406733 0.00843482]\n",
      "[0.09429475 0.00358021 0.04750001 0.00557124 0.05082736]\n",
      "[0.03084956 0.02931354 0.07902722 0.02125043 0.00779614]\n",
      "[0.16114345 0.00467924 0.06189805 0.01200919 0.0129863 ]\n",
      "[0.00483243 0.01332807 0.00602927 0.00530501 0.07188524]\n",
      "[0.01169471 0.00195295 0.02320186 0.00361177 0.09094694]\n",
      "[0.17805688 0.00581481 0.08778573 0.00741047 0.00830714]\n",
      "[0.02207974 0.00485802 0.05539339 0.06353979 0.00427479]\n",
      "[0.01417243 0.01814    0.03236574 0.00356941 0.05992474]\n",
      "[0.07759033 0.0095573  0.21389156 0.02458816 0.01260289]\n",
      "[0.16571291 0.0040886  0.04565445 0.01765016 0.00613731]\n",
      "[0.09994837 0.0113357  0.08514742 0.02568092 0.0068657 ]\n",
      "[0.10292191 0.00994723 0.21724887 0.01529793 0.01316542]\n",
      "[0.06966145 0.00481432 0.09102961 0.04467973 0.00672443]\n",
      "[0.14786247 0.00502974 0.07534093 0.01967516 0.00724138]\n",
      "[0.07129055 0.00854974 0.18905281 0.03028475 0.01133929]\n",
      "[0.0184628  0.00709248 0.03258759 0.03062243 0.04437123]\n",
      "[0.09654885 0.00879135 0.18756665 0.01350531 0.0218995 ]\n",
      "[0.08085895 0.0145667  0.22294027 0.01548398 0.0130298 ]\n",
      "[0.10370073 0.00458638 0.07569276 0.0347583  0.0068476 ]\n",
      "[0.09550432 0.01079232 0.22588146 0.01580324 0.01344455]\n",
      "[0.11596095 0.00577867 0.10379991 0.02676377 0.00806315]\n",
      "[0.00472156 0.00126215 0.00658198 0.00567247 0.09343862]\n",
      "[0.10272442 0.00454617 0.07150047 0.00647488 0.04307599]\n",
      "[0.14848196 0.0145856  0.07094358 0.00604731 0.00694267]\n",
      "[0.11703691 0.0065943  0.05668333 0.0253311  0.01082056]\n",
      "[0.05160003 0.00653326 0.13983646 0.03169849 0.02416514]\n",
      "[0.1779365  0.00582143 0.08799315 0.00742311 0.00831493]\n",
      "[0.07342027 0.00861393 0.19004163 0.02836149 0.01272004]\n",
      "[0.11994742 0.00550612 0.09330702 0.00778349 0.03142607]\n",
      "[0.03921289 0.02426686 0.01407507 0.01181103 0.0294558 ]\n",
      "[0.11773896 0.00998134 0.11144123 0.01944261 0.00840812]\n",
      "[0.03598833 0.0178372  0.09443736 0.03215355 0.0120298 ]\n",
      "[0.09932104 0.01014528 0.22345343 0.01567594 0.01339825]\n",
      "[0.13819993 0.00800694 0.15646222 0.01159454 0.01088432]\n",
      "[0.1087866  0.00814543 0.16814956 0.0201831  0.01096076]\n",
      "[0.07918967 0.0081151  0.0299992  0.04200473 0.00396151]\n",
      "[0.09487006 0.00717907 0.14444512 0.01089598 0.03142509]\n",
      "[0.0641922  0.01237715 0.17548148 0.01860195 0.02270876]\n",
      "[0.04109288 0.00805189 0.10958607 0.04791842 0.00710603]\n",
      "[0.09129392 0.00662364 0.13116542 0.01732129 0.02662091]\n",
      "[0.08411411 0.01034736 0.23253377 0.01623579 0.01788572]\n",
      "[0.00508286 0.0426443  0.00463994 0.00351059 0.02065989]\n",
      "[0.07818459 0.02550467 0.03519308 0.01677675 0.0040066 ]\n",
      "[0.05300638 0.01738375 0.1038243  0.03097001 0.00692723]\n",
      "[0.0416235  0.0312706  0.02498948 0.00260933 0.02659912]\n",
      "[0.11311964 0.00346368 0.03980152 0.00454898 0.04522545]\n",
      "[0.13036194 0.00569947 0.09777733 0.02260113 0.00801166]\n",
      "[0.07690065 0.00830597 0.18109405 0.0294549  0.01105649]\n",
      "[0.02706318 0.01172332 0.06924841 0.04927455 0.00681319]\n",
      "[0.08538947 0.00269969 0.02578967 0.00371925 0.05966475]\n",
      "[0.10003548 0.01741236 0.02945401 0.02168105 0.00417329]\n",
      "[0.01130285 0.00125468 0.01031903 0.05212372 0.03226414]\n",
      "[0.07872987 0.03618375 0.02256293 0.00226176 0.00330611]\n",
      "[0.14364675 0.00715553 0.1325301  0.01307485 0.00985114]\n",
      "[0.11008657 0.00520115 0.09018125 0.03072951 0.00733161]\n",
      "[0.16411384 0.00695537 0.10445283 0.00896931 0.00885736]\n",
      "[0.10803402 0.02100406 0.10083682 0.00767068 0.00763448]\n",
      "[0.0886716  0.00871882 0.18876074 0.02427651 0.01160376]\n",
      "[0.06821688 0.01918095 0.13025723 0.02102749 0.00840131]\n",
      "[0.00465708 0.00126923 0.00642355 0.00260076 0.09731748]\n",
      "[0.03935307 0.03540105 0.10296769 0.00957034 0.00647623]\n",
      "[0.00514445 0.05555648 0.00390869 0.00040221 0.00103484]\n",
      "[0.07260142 0.00968157 0.02386179 0.03532341 0.01251608]\n",
      "[0.05332289 0.01198682 0.01961853 0.04592439 0.00301367]\n",
      "[0.00557539 0.00295158 0.00855815 0.04551481 0.03987648]\n",
      "[0.02624742 0.00679692 0.05723202 0.05919276 0.00440824]\n",
      "[0.05470877 0.00686499 0.14670807 0.02084777 0.03551227]\n",
      "[0.12341068 0.0226491  0.05070305 0.0044988  0.00549778]\n",
      "[0.08577475 0.01029635 0.23076106 0.01612736 0.01755553]\n",
      "[0.06851389 0.00495897 0.0951565  0.04449697 0.00689926]\n",
      "[0.05904952 0.01268773 0.1607258  0.02431899 0.01793442]\n",
      "[0.09030364 0.00610119 0.11931223 0.03350547 0.00837876]\n",
      "[0.01214867 0.01537066 0.02192596 0.00302774 0.06710649]\n",
      "[0.05359057 0.00685998 0.14567318 0.01099787 0.04839956]\n",
      "[0.03319014 0.02380548 0.06268392 0.03184552 0.0045976 ]\n",
      "[0.04111066 0.00819824 0.09884569 0.01759777 0.04555213]\n",
      "[0.09289928 0.03245339 0.02615494 0.00261983 0.00374345]\n",
      "[0.05261802 0.00535977 0.11006494 0.04792639 0.0073428 ]\n",
      "[0.04216408 0.00535562 0.11281196 0.05117735 0.00730411]\n",
      "[0.08263157 0.00346201 0.05089811 0.0377483  0.01512982]\n",
      "[0.01507371 0.00232752 0.03583739 0.03232335 0.05208945]\n",
      "[0.16156005 0.00633254 0.10594112 0.01059102 0.00889307]\n",
      "[0.08498358 0.00613825 0.12124002 0.03076353 0.01377435]\n",
      "[0.11077203 0.01490197 0.03213998 0.02149879 0.00449965]\n",
      "[0.03643602 0.00469572 0.09650221 0.05134906 0.01159133]\n",
      "[0.16057984 0.00677605 0.11789998 0.00924516 0.00943722]\n",
      "[0.02872536 0.00558193 0.01484108 0.06377966 0.00245954]\n",
      "[0.04921285 0.00190179 0.01984076 0.06183933 0.00306462]\n",
      "[0.02718622 0.01155892 0.06984775 0.02158496 0.04178783]\n",
      "[0.05837859 0.01995563 0.1583956  0.01129143 0.02144702]\n",
      "[0.08702355 0.01200728 0.16912753 0.0217701  0.01061545]\n",
      "[0.04634695 0.02459325 0.12362156 0.0210678  0.0076784 ]\n",
      "[0.13652074 0.00554671 0.09206767 0.02126302 0.00784292]\n",
      "[0.0836131  0.00799449 0.02684644 0.04097759 0.0038852 ]\n",
      "[0.02236824 0.00300776 0.05632968 0.06603513 0.00434321]\n",
      "[0.04264307 0.00191886 0.01594306 0.01187805 0.06863319]\n",
      "[0.00789137 0.041394   0.0127671  0.00148278 0.02385998]\n",
      "[0.12572888 0.01392272 0.0355967  0.01763299 0.0049142 ]\n",
      "[0.09131243 0.01578476 0.05321583 0.00492345 0.03023363]\n",
      "[0.04695338 0.03292225 0.12485615 0.00873024 0.00765836]\n",
      "[0.02764533 0.00669108 0.07120292 0.05767458 0.00509151]\n",
      "[0.08761711 0.00668688 0.13548549 0.03215897 0.00909289]\n",
      "[0.01111478 0.00941494 0.02392243 0.0438317  0.02703682]\n",
      "[0.09466806 0.0080844  0.16893164 0.01237846 0.02649809]\n",
      "[0.0715326  0.0089099  0.19673068 0.01407677 0.03046323]\n",
      "[0.08174739 0.00923574 0.144838   0.01084732 0.03298722]\n",
      "[0.00495401 0.00123664 0.00715314 0.0167462  0.07945507]\n",
      "[0.02210292 0.04637562 0.05296719 0.00378021 0.00372146]\n",
      "[0.0049185  0.00124054 0.00706589 0.01505473 0.08159101]\n",
      "[0.15465131 0.00970759 0.04250327 0.01261353 0.00685277]\n",
      "[0.06957561 0.00504377 0.07324793 0.04591116 0.00588106]\n",
      "[0.0049185  0.00124054 0.00706589 0.01505473 0.08159101]\n",
      "[0.07370622 0.01175169 0.02460715 0.03759283 0.00540225]\n",
      "[0.12232856 0.00605635 0.10771278 0.00966704 0.0262206 ]\n",
      "[0.10921788 0.00387301 0.05540799 0.03593726 0.00568985]\n",
      "[0.12104722 0.00351747 0.03572732 0.03420871 0.00495499]\n",
      "[0.05582363 0.00479237 0.09414992 0.04834924 0.00753036]\n",
      "[0.01556488 0.02155358 0.03594134 0.02158179 0.03030896]\n",
      "[0.00480701 0.00125277 0.00679195 0.00974349 0.08829787]\n",
      "[0.08017977 0.00935124 0.20774617 0.02450279 0.0124203 ]\n",
      "[0.13414269 0.00740947 0.14182117 0.01507205 0.010134  ]\n",
      "[0.08304071 0.00522493 0.09819792 0.03901188 0.0072741 ]\n",
      "[0.02732396 0.01136583 0.0420444  0.04996974 0.00814974]\n",
      "[0.05510775 0.0089701  0.13142417 0.02098677 0.03227229]\n",
      "[0.09009501 0.00734373 0.15022304 0.01288305 0.03019696]\n",
      "[0.07675051 0.00867287 0.09714471 0.03621824 0.00708656]\n",
      "[0.16669346 0.0064398  0.10736575 0.00860337 0.00904191]\n",
      "[0.03953277 0.00625279 0.10548245 0.02199387 0.04381001]\n",
      "[0.05713008 0.00713064 0.15551357 0.03994461 0.00954261]\n",
      "[0.00583716 0.00113971 0.00932317 0.05881936 0.02632645]\n",
      "[0.10368861 0.02558117 0.06715331 0.00541386 0.0059257 ]\n",
      "[0.09364216 0.00670046 0.13419735 0.03024368 0.009129  ]\n",
      "[0.0835676  0.00255889 0.02777538 0.04876289 0.00398582]\n",
      "[0.19461624 0.00567451 0.05194064 0.00519028 0.00688302]\n",
      "[0.07485034 0.02577887 0.06257065 0.01512914 0.0052426 ]\n",
      "[0.08371835 0.01030214 0.23140756 0.01616787 0.01828136]\n",
      "[0.07452705 0.01799461 0.20462296 0.01422272 0.01202668]\n",
      "[0.11489348 0.01259037 0.16528728 0.01197644 0.010877  ]\n",
      "[0.03068879 0.00401988 0.08011406 0.05443387 0.0122631 ]\n",
      "[0.10143024 0.01979008 0.12209348 0.00978948 0.00854455]\n",
      "[0.03124779 0.02410395 0.01171781 0.00206054 0.04533968]\n",
      "[0.00475499 0.0121753  0.00591833 0.00215908 0.07797473]\n",
      "[0.19831561 0.00470058 0.05287844 0.00528377 0.0069972 ]\n",
      "[0.07923487 0.0097899  0.21864896 0.0153985  0.02276341]\n",
      "[0.08674598 0.0106432  0.24001485 0.01771638 0.01397232]\n",
      "[0.03373454 0.00435584 0.08876045 0.05750415 0.00604329]\n",
      "[0.08288947 0.00660358 0.1339972  0.02899239 0.01521163]\n",
      "[0.03459228 0.00917763 0.01574647 0.05655437 0.00255878]\n",
      "[0.08599297 0.00714095 0.14595855 0.03114052 0.0095564 ]\n",
      "[0.08982644 0.0152623  0.1294676  0.01955739 0.00875365]\n",
      "[0.05175478 0.00424135 0.07801184 0.02862447 0.03591912]\n",
      "[0.10937323 0.01644915 0.1410587  0.0103326  0.0096033 ]\n",
      "[0.00540748 0.01666397 0.00721004 0.03111054 0.03310271]\n",
      "[0.03382744 0.02971639 0.06483649 0.02291078 0.00464698]\n",
      "[0.05054445 0.00316989 0.05290499 0.05671156 0.00463377]\n",
      "[0.07918423 0.01767884 0.04539611 0.02686579 0.00458722]\n",
      "[0.1777442  0.01011638 0.0476635  0.00476391 0.00636225]\n",
      "[0.03158418 0.0390959  0.08054962 0.00575915 0.0090157 ]\n",
      "[0.05380328 0.01108525 0.10274858 0.03989393 0.0069559 ]\n",
      "[0.08464972 0.00469976 0.08391461 0.04046679 0.0066312 ]\n",
      "[0.09421045 0.00285599 0.02790565 0.00384146 0.05555074]\n",
      "[0.08966866 0.01727386 0.07611635 0.02130797 0.00621087]\n",
      "[0.05846878 0.00732621 0.15939702 0.03114198 0.01946112]\n",
      "[0.0679252  0.00685852 0.14221628 0.01077903 0.04312523]\n",
      "[0.11264838 0.00845924 0.08762645 0.02539121 0.0072178 ]\n",
      "[0.05249004 0.0115778  0.07000505 0.04244511 0.00538356]\n",
      "[0.03219728 0.00429916 0.08459223 0.03203314 0.03899511]\n",
      "[0.06097114 0.00553272 0.11234171 0.04469792 0.00758306]\n",
      "[0.06888249 0.00826514 0.13219725 0.01556003 0.03478542]\n",
      "[0.13684823 0.00808129 0.15879131 0.01173644 0.01097172]\n",
      "[0.12226484 0.01550438 0.12108271 0.00912669 0.00887784]\n",
      "[0.16723986 0.00822708 0.08917679 0.00740948 0.00817302]\n",
      "[0.11840183 0.00747197 0.14757887 0.01809921 0.01219626]\n",
      "[0.08499509 0.01286795 0.13223282 0.02438604 0.00883169]\n",
      "[0.06502423 0.0103071  0.17790298 0.03079591 0.01069331]\n",
      "[0.00499687 0.00827529 0.00677727 0.01549365 0.06819728]\n",
      "[0.19831561 0.00470058 0.05287844 0.00528377 0.0069972 ]\n",
      "[0.00508188 0.01329179 0.0066428  0.01719286 0.05688987]\n",
      "[0.04590344 0.01337839 0.12307078 0.03224007 0.01431678]\n",
      "[0.06131789 0.0142281  0.02633373 0.00332723 0.04877742]\n",
      "[0.09103928 0.02837602 0.06902706 0.00542898 0.0057808 ]\n",
      "[0.00497061 0.00530332 0.00691598 0.0156342  0.07344272]\n",
      "[0.15683906 0.01235633 0.04273342 0.00891733 0.00576896]\n",
      "[0.08508562 0.01227849 0.23516743 0.0163259  0.0136994 ]\n",
      "[0.08569633 0.01039667 0.23380295 0.01895801 0.01366472]\n",
      "[0.00550208 0.00117649 0.00849982 0.04285602 0.04648444]\n",
      "[0.03117851 0.01902474 0.08056865 0.03787696 0.00546018]\n",
      "[0.01411079 0.00124289 0.01206297 0.07515375 0.0021388 ]\n",
      "[0.09107704 0.00936661 0.2043996  0.01452798 0.02073791]\n",
      "[0.04092533 0.04400273 0.03322986 0.00264084 0.00311794]\n",
      "[0.00465708 0.00126923 0.00642355 0.00260076 0.09731748]\n",
      "[0.04831561 0.00515354 0.10580433 0.05002487 0.0070745 ]\n",
      "[0.11573031 0.00924277 0.19517905 0.01395334 0.01233722]\n",
      "[0.03810418 0.03129884 0.0996417  0.01619784 0.00634246]\n",
      "[0.09325314 0.00727025 0.14821103 0.01883842 0.02170798]\n",
      "[0.07488703 0.0167297  0.09831548 0.00768646 0.02888962]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07418349 0.00915324 0.20417103 0.02714517 0.01209332]\n",
      "[0.1191168  0.00591812 0.10462647 0.00846929 0.0294561 ]\n",
      "[0.03066789 0.02360822 0.07883293 0.03157717 0.00532152]\n",
      "[0.1830366  0.00554092 0.07920531 0.00688771 0.00798515]\n",
      "[0.15244821 0.00385233 0.04249396 0.01792724 0.01174621]\n",
      "[0.03116526 0.00417231 0.08163991 0.03374996 0.03766647]\n",
      "[0.01931989 0.00152903 0.00994087 0.0028039  0.09047891]\n",
      "[0.00465708 0.00126923 0.00642355 0.00260076 0.09731748]\n",
      "[0.00465708 0.00126923 0.00642355 0.00260076 0.09731748]\n",
      "[0.00465708 0.00126923 0.00642355 0.00260076 0.09731748]\n",
      "[0.1509673  0.00565174 0.09062101 0.01413472 0.01088057]\n",
      "[0.03013539 0.04202706 0.07620402 0.00538022 0.00499399]\n",
      "[0.07065357 0.00764625 0.16541028 0.03384167 0.01022231]\n",
      "[0.02161868 0.02233762 0.0396143  0.02962784 0.0161201 ]\n",
      "[0.08851622 0.00810614 0.17183322 0.01967561 0.01959367]\n",
      "[0.18047714 0.00438451 0.04859935 0.00503663 0.01531687]\n",
      "[0.06264041 0.01566158 0.02128687 0.03736975 0.0032037 ]\n",
      "[0.15674468 0.00523772 0.07839655 0.01615267 0.00752656]\n",
      "[0.00902482 0.01849144 0.01745349 0.02564664 0.03454918]\n",
      "[0.0532565  0.00649252 0.13876892 0.0352158  0.01922315]\n",
      "[0.09691384 0.00996498 0.21935826 0.01709147 0.01316802]\n",
      "[0.15585388 0.0060943  0.10111961 0.01239415 0.00965257]\n",
      "[0.04842395 0.01265938 0.07091373 0.01888313 0.03456953]\n",
      "[0.03289075 0.00541967 0.0863601  0.04742616 0.01724083]\n",
      "[0.06076015 0.00498247 0.09787102 0.04661051 0.00715446]\n",
      "[0.11278281 0.01696251 0.12853192 0.00953634 0.00906136]\n",
      "[0.04287199 0.00537505 0.11313078 0.05088599 0.00733037]\n",
      "[0.08878642 0.00671089 0.1357991  0.03170776 0.00912628]\n",
      "[0.01288531 0.0020761  0.02960746 0.03224373 0.05390836]\n",
      "[0.08949935 0.01969006 0.15491862 0.01107567 0.00990321]\n",
      "[0.03914536 0.03281609 0.01397232 0.0185275  0.00546681]\n",
      "[0.07407009 0.02105279 0.17662517 0.01237387 0.01066506]\n",
      "[0.02423107 0.02152137 0.0605466  0.0383128  0.0043765 ]\n",
      "[0.06148543 0.0153336  0.07679214 0.0334391  0.00580922]\n",
      "[0.02046562 0.00154933 0.01021571 0.00281977 0.08994455]\n",
      "[0.00529888 0.00119879 0.00800054 0.03317582 0.05870828]\n",
      "[0.11042906 0.00309495 0.03263818 0.02215199 0.02531881]\n",
      "[0.01814847 0.03113285 0.02714931 0.02064    0.01352066]\n",
      "[0.00590063 0.0180577  0.00832285 0.05392655 0.00165207]\n",
      "[0.11422208 0.00711265 0.13943976 0.02234133 0.00970374]\n",
      "[0.03538655 0.00464219 0.09363088 0.03710481 0.03016824]\n",
      "[0.04298867 0.014642   0.11470688 0.02633512 0.02110823]\n",
      "[0.04976764 0.04204623 0.03194667 0.00263202 0.00322051]\n",
      "[0.09072445 0.00460135 0.0796604  0.03895262 0.00652925]\n",
      "[0.13363054 0.00825826 0.16433563 0.01207423 0.01117978]\n",
      "[0.03494291 0.0250758  0.09109431 0.01274864 0.02381427]\n",
      "[0.12855744 0.00853728 0.17307694 0.01260678 0.01150781]\n",
      "[0.04579107 0.00578579 0.12316063 0.04845511 0.00784661]\n",
      "[0.03089519 0.02122708 0.07215484 0.0184843  0.02641704]\n",
      "[0.10006195 0.01118446 0.09511841 0.0090075  0.02741807]\n",
      "[0.02260781 0.02147204 0.02279093 0.02188028 0.02805499]\n",
      "[0.10394358 0.00659908 0.12871002 0.02743237 0.00903697]\n",
      "[0.14178229 0.00775732 0.14890316 0.01141405 0.01058778]\n",
      "[0.01164638 0.01083931 0.02564314 0.0079703  0.06914009]\n",
      "[0.09646408 0.00574327 0.10530725 0.00852562 0.03876968]\n",
      "[0.01083437 0.001975   0.02400221 0.00366079 0.09114216]\n",
      "[0.03846102 0.00916561 0.09751241 0.04822829 0.00648179]\n",
      "[0.162682   0.01180157 0.06548566 0.0058093  0.00694321]\n",
      "[0.07492185 0.02194205 0.16627335 0.01169903 0.01018062]\n",
      "[0.03763742 0.00426792 0.08440572 0.04841773 0.01630754]\n",
      "[0.07144836 0.00882884 0.19636705 0.02919802 0.01168422]\n",
      "[0.08453791 0.00762529 0.16059607 0.02966274 0.01021894]\n",
      "[0.06044699 0.01547159 0.16450037 0.02601814 0.00993214]\n",
      "[0.04505695 0.00584542 0.12132048 0.01791918 0.04647958]\n",
      "[0.06219857 0.00678418 0.14499577 0.03966426 0.00913134]\n",
      "[0.0864552  0.01343709 0.07222034 0.02698856 0.00760642]\n",
      "[0.04963703 0.00409976 0.07490305 0.03018676 0.0352574 ]\n",
      "[0.07750862 0.00952642 0.21309988 0.02472828 0.01256452]\n",
      "[0.11413971 0.00933025 0.19791977 0.01412032 0.01244007]\n",
      "[0.00465708 0.00126923 0.00642355 0.00260076 0.09731748]\n",
      "[0.05304209 0.00664579 0.14384955 0.04301285 0.00893116]\n",
      "[0.14160113 0.01167052 0.11405703 0.00882936 0.00889822]\n",
      "[0.10332226 0.01117791 0.13940884 0.02010331 0.00948367]\n",
      "[0.06777428 0.03004154 0.10545163 0.00762992 0.00710812]\n",
      "[0.04352205 0.0367244  0.05572851 0.01034635 0.00429902]\n",
      "[0.08639698 0.01442244 0.1671561  0.01866083 0.01048673]\n",
      "[0.18512988 0.00445307 0.0499568  0.01028519 0.00664943]\n",
      "[0.05830082 0.04137451 0.01916416 0.0018628  0.00276158]\n",
      "[0.09793823 0.02913511 0.04633446 0.00399273 0.00481251]\n",
      "[0.06720592 0.00416656 0.07462521 0.04784852 0.00591719]\n",
      "[0.09730246 0.00515228 0.08915419 0.0075472  0.04172563]\n",
      "[0.04988461 0.03046518 0.13339839 0.00935074 0.00965985]\n",
      "[0.02209623 0.02890478 0.05420507 0.00451424 0.03458755]\n",
      "[0.12473882 0.00498146 0.07881222 0.01370195 0.02391231]\n",
      "[0.02854569 0.01058588 0.07356448 0.04920066 0.00812051]\n",
      "[0.08580846 0.01846585 0.04063028 0.00404498 0.02942884]\n",
      "[0.04451582 0.00563454 0.11952206 0.04941225 0.00765587]\n",
      "[0.12983515 0.00528393 0.08696738 0.02430942 0.00749718]\n",
      "[0.07526567 0.02623953 0.05780521 0.00481967 0.01746901]\n",
      "[0.00479797 0.01696237 0.00569656 0.00196521 0.06948448]\n",
      "[0.0878618  0.01077554 0.24319856 0.0168789  0.01413922]\n",
      "[0.03280128 0.01451025 0.08554622 0.03582951 0.01530678]\n",
      "[0.09065328 0.00531121 0.09839242 0.0363349  0.00740502]\n",
      "[0.05904952 0.01268773 0.1607258  0.02431899 0.01793442]\n",
      "[0.0481416  0.01753706 0.1053981  0.03223317 0.00692153]\n",
      "[0.0865817  0.00786758 0.09515212 0.03427864 0.00715939]\n",
      "[0.14861062 0.010121   0.11302613 0.00882147 0.00897888]\n",
      "[0.04520048 0.02020386 0.12076856 0.00895623 0.0315229 ]\n",
      "[0.02700784 0.01992392 0.06858505 0.03900145 0.00481767]\n",
      "[0.08195288 0.01250154 0.13743991 0.0102662  0.02813052]\n",
      "[0.05078585 0.00637819 0.13741194 0.04470628 0.00859369]\n",
      "[0.02628971 0.0417883  0.00966676 0.00126978 0.0162011 ]\n",
      "[0.00738779 0.04720496 0.01089024 0.00368464 0.01081585]\n",
      "[0.06876211 0.00554172 0.10776114 0.01951997 0.03632219]\n",
      "[0.19796879 0.00469443 0.05279525 0.00527896 0.00715895]\n",
      "[0.11667297 0.00479161 0.07758583 0.03021393 0.00684737]\n",
      "[0.15514008 0.00413571 0.0497853  0.02074729 0.00616149]\n",
      "[0.06091837 0.00762973 0.16640881 0.02655197 0.02325658]\n",
      "[0.0267862  0.00966627 0.0685669  0.05389129 0.00492174]\n",
      "[0.00490563 0.0289541  0.00514105 0.00147956 0.04821621]\n",
      "[0.0385335  0.00496347 0.10251975 0.04575293 0.0169174 ]\n",
      "[0.07831893 0.01840106 0.02332621 0.00297827 0.0349544 ]\n",
      "[0.12752626 0.00697808 0.13225706 0.01872408 0.00958039]\n",
      "[0.06279598 0.00791172 0.17186895 0.01257754 0.03919707]\n",
      "[0.03483536 0.04645717 0.02360823 0.00195465 0.00253957]\n",
      "[0.13792183 0.0204176  0.03930287 0.00387187 0.00521693]\n",
      "[0.07818947 0.0090207  0.19958256 0.02639818 0.01194263]\n",
      "[0.04790569 0.02989053 0.1277621  0.01254085 0.00784297]\n",
      "[0.12378157 0.00383628 0.04933127 0.02202173 0.01774239]\n",
      "[0.06982641 0.00863647 0.19173926 0.03041537 0.01144163]\n",
      "[0.04671932 0.01360007 0.12538552 0.03211213 0.01360368]\n",
      "[0.12399184 0.00409772 0.05729451 0.03052908 0.00601458]\n",
      "[0.13405896 0.01113094 0.13611056 0.01021799 0.00982366]\n",
      "[0.12849143 0.00854091 0.17319069 0.01261371 0.01151208]\n",
      "[0.12798231 0.00856891 0.17406794 0.01266716 0.011545  ]\n",
      "[0.05260249 0.00671556 0.14280672 0.01750988 0.04106026]\n",
      "[0.01050232 0.02154184 0.0215865  0.00985291 0.04796694]\n",
      "[0.04402351 0.00564002 0.11822813 0.03624867 0.02444815]\n",
      "[0.0349616  0.02096436 0.09149299 0.00711798 0.03834878]\n",
      "[0.1232592  0.00867716 0.1782119  0.01372645 0.01166341]\n",
      "[0.0946545  0.01280019 0.2087336  0.014666   0.01259999]\n",
      "[0.00520558 0.0013319  0.00798441 0.00269488 0.09676916]\n",
      "[0.06173544 0.00745714 0.15987082 0.01201944 0.04188615]\n",
      "[0.06628681 0.0099683  0.05508487 0.00526644 0.05035697]\n",
      "[0.02329782 0.00988328 0.05877369 0.03239745 0.0335097 ]\n",
      "[0.04115318 0.04032252 0.04835147 0.00371573 0.00746438]\n",
      "[0.19831561 0.00470058 0.05287844 0.00528377 0.0069972 ]\n",
      "[0.14882562 0.01772974 0.04033251 0.00403312 0.00546966]\n",
      "[0.04082203 0.00375073 0.0647867  0.00610976 0.07028165]\n",
      "[0.11458396 0.0079645  0.16138394 0.0155766  0.01515629]\n",
      "[0.07479434 0.02363317 0.03477498 0.02064492 0.00395204]\n",
      "[0.04068236 0.00529479 0.10878358 0.02793824 0.03743075]\n",
      "[0.11449463 0.00391636 0.05510898 0.03414288 0.0057603 ]\n",
      "[0.15973092 0.00682274 0.11936272 0.00933428 0.00949211]\n",
      "[0.07742229 0.01642721 0.2129985  0.01479943 0.01248535]\n",
      "[0.09273441 0.01670639 0.14987821 0.01281484 0.01216842]\n",
      "[0.04275385 0.00559108 0.11478181 0.01566093 0.05110381]\n",
      "[0.11625901 0.00631829 0.11610986 0.00916637 0.02829851]\n",
      "[0.12023991 0.00899474 0.18740868 0.01347994 0.01204563]\n",
      "[0.00465708 0.00126923 0.00642355 0.00260076 0.09731748]\n",
      "[0.13862686 0.00793938 0.09169791 0.01713784 0.00783409]\n",
      "[0.08987733 0.00746703 0.08442826 0.03468468 0.00671041]\n",
      "[0.15984439 0.01015367 0.08749562 0.00723535 0.00795411]\n",
      "[0.03019095 0.00399231 0.07874817 0.04813786 0.02050086]\n",
      "[0.09315119 0.00618484 0.10280108 0.0338608  0.00764418]\n",
      "[0.0795576  0.00801342 0.17265628 0.02972045 0.01070401]\n",
      "[0.00529587 0.04804752 0.00479261 0.01112022 0.00115844]\n",
      "[0.09840222 0.00354152 0.04962487 0.04051745 0.00524605]\n",
      "[0.04077779 0.02061506 0.10229583 0.0077982  0.03513352]\n",
      "[0.03251984 0.00424341 0.08534951 0.05171253 0.01421575]\n",
      "[0.12751566 0.00911679 0.16545205 0.01211311 0.01195544]\n",
      "[0.13123241 0.00839016 0.16846777 0.01232597 0.01133484]\n",
      "[0.05261731 0.04271651 0.01918763 0.00181567 0.00265692]\n",
      "[0.1055972  0.00585618 0.10617765 0.00857222 0.03478032]\n",
      "[0.04164181 0.01389359 0.08713584 0.04123582 0.0059931 ]\n",
      "[0.04307165 0.0018765  0.01691483 0.03054913 0.0450395 ]\n",
      "[0.09698594 0.01027371 0.227477   0.01592107 0.01354924]\n",
      "[0.16861061 0.00845324 0.04554532 0.00469837 0.01327889]\n",
      "[0.07297758 0.03126674 0.08214209 0.00613849 0.00607844]\n",
      "[0.08513407 0.02376601 0.12603602 0.00913504 0.00842608]\n",
      "[0.09187477 0.00761169 0.15683742 0.01164817 0.03013887]\n",
      "[0.0591704  0.0074064  0.16139367 0.03125806 0.01876509]\n",
      "[0.06096629 0.01013097 0.01954973 0.00306137 0.05713873]\n",
      "[0.15660792 0.00556198 0.0860745  0.00732119 0.01760793]\n",
      "[0.08977899 0.00958285 0.21123451 0.02072074 0.01267355]\n",
      "[0.07389841 0.00928053 0.15641148 0.03117702 0.00983243]\n",
      "[0.08222139 0.01846422 0.09581007 0.02008561 0.00736534]\n",
      "[0.07865822 0.00791406 0.05650179 0.00542734 0.04884094]\n",
      "[0.03730281 0.00818246 0.09889851 0.03101842 0.03026055]\n",
      "[0.11156852 0.00762026 0.10377247 0.0151207  0.02108877]\n",
      "[0.16381039 0.00606202 0.09819513 0.0109005  0.00856647]\n",
      "[0.07257117 0.01545387 0.10438063 0.01626322 0.02100964]\n",
      "[0.10567033 0.02835003 0.03642631 0.00340606 0.00447758]\n",
      "[0.00465708 0.00126923 0.00642355 0.00260076 0.09731748]\n",
      "[0.08780118 0.00499256 0.09077192 0.03840258 0.00700264]\n",
      "[0.09803442 0.01209457 0.0284784  0.00567795 0.03482506]\n",
      "[0.0878618  0.01077554 0.24319856 0.0168789  0.01413922]\n",
      "[0.12645487 0.01066755 0.15757989 0.01156759 0.01071971]\n",
      "[0.08398435 0.01499148 0.17571315 0.01790429 0.01084585]\n",
      "[0.00495189 0.03410725 0.00490233 0.00127087 0.03907671]\n",
      "[0.06649793 0.01132481 0.18216722 0.01557458 0.02709288]\n",
      "[0.04065624 0.03633136 0.10663939 0.0074759  0.00666074]\n",
      "[0.06554835 0.0114544  0.12681894 0.03337193 0.00827771]\n",
      "[0.07967703 0.019674   0.14121457 0.01555287 0.00909809]\n",
      "[0.06654709 0.01737263 0.10101423 0.02671842 0.00701284]\n",
      "[0.00598329 0.00112367 0.00968222 0.06578085 0.01753571]\n",
      "[0.13008688 0.00675959 0.12472573 0.00967872 0.0207649 ]\n",
      "[0.1166551  0.00755321 0.15038832 0.01995002 0.01025521]\n",
      "[0.06086143 0.00500187 0.08921233 0.04749675 0.00649486]\n",
      "[0.01975566 0.0359661  0.04701725 0.00380419 0.02398179]\n",
      "[0.09384376 0.00859188 0.18400123 0.02314776 0.01146372]\n",
      "[0.03999996 0.01080932 0.0161844  0.03966441 0.01858566]\n",
      "[0.09782262 0.0155921  0.17512432 0.01247843 0.01103466]\n",
      "[0.05079185 0.01051782 0.13742273 0.01035022 0.04417129]\n",
      "[0.01427231 0.00907264 0.0328083  0.06200203 0.00303807]\n",
      "[0.10723871 0.0120139  0.16640787 0.01207009 0.01481967]\n",
      "[0.12926336 0.00842956 0.1037543  0.00831738 0.02104092]\n",
      "[0.00963589 0.02679106 0.01848276 0.03919277 0.00209958]\n",
      "[0.07565522 0.00935258 0.20841323 0.02078824 0.01885928]\n",
      "[0.07576191 0.00245989 0.02729849 0.05154692 0.00383858]\n",
      "[0.04529104 0.00182817 0.01897178 0.0633269  0.00296118]\n",
      "[0.10079226 0.01072805 0.13718364 0.01031075 0.02375051]\n",
      "[0.03214708 0.00170062 0.0139865  0.02378762 0.05841939]\n",
      "[0.0469487  0.00837841 0.12631623 0.04405292 0.00798683]\n",
      "[0.09309465 0.02262624 0.1085294  0.00809106 0.00968451]\n",
      "[0.00465708 0.00126923 0.00642355 0.00260076 0.09731748]\n",
      "[0.00498278 0.03754858 0.00474291 0.0011315  0.03297325]\n",
      "[0.07271875 0.0031099  0.03991385 0.00483585 0.06174591]\n",
      "[0.05135478 0.00640403 0.13793761 0.04443411 0.0086274 ]\n",
      "[0.01924368 0.00289566 0.04786294 0.01360466 0.07214119]\n",
      "[0.04553727 0.00584899 0.12259834 0.02887445 0.03244888]\n",
      "[0.02222287 0.00145275 0.01514496 0.06988955 0.00491508]\n",
      "[0.03146295 0.00271671 0.0459287  0.06224235 0.00661453]\n",
      "[0.13179301 0.00797889 0.15747346 0.01368181 0.01082913]\n",
      "[0.1349043  0.00351029 0.03882798 0.02933605 0.00532473]\n",
      "[0.00510065 0.05067726 0.00413472 0.00059981 0.00968851]\n",
      "[0.09254266 0.00755788 0.15709995 0.02739553 0.01018356]\n",
      "[0.09764602 0.01262385 0.08130607 0.00677992 0.02940481]\n",
      "[0.06588505 0.00370918 0.0615766  0.03852112 0.01978899]\n",
      "[0.18334118 0.00552417 0.07868049 0.00685574 0.00796546]\n",
      "[0.0785276  0.02360235 0.14242117 0.01015816 0.00909499]\n",
      "[0.02074834 0.04710896 0.04904858 0.00351039 0.00350686]\n",
      "[0.13899073 0.0042291  0.05665963 0.02539829 0.00622488]\n",
      "[0.13933073 0.00513501 0.08044725 0.02192428 0.0073439 ]\n",
      "[0.02192141 0.04102832 0.03675852 0.01296193 0.00300981]\n",
      "[0.02690712 0.00354608 0.0692802  0.06262847 0.0050221 ]\n",
      "[0.08269262 0.01594921 0.0911898  0.008423   0.02668565]\n",
      "[0.04049877 0.01158981 0.10772358 0.03739401 0.01421891]\n",
      "[0.06116892 0.00760966 0.16703733 0.03691326 0.01014671]\n",
      "[0.03161655 0.00845793 0.08245599 0.05282917 0.00566811]\n",
      "[0.1034538  0.01700705 0.13250313 0.00978373 0.01217745]\n",
      "[0.00465708 0.00126923 0.00642355 0.00260076 0.09731748]\n",
      "[0.1054466  0.0057734  0.10653405 0.03003758 0.00802289]\n",
      "[0.16795433 0.00567245 0.08679346 0.01106663 0.00809903]\n",
      "[0.11644852 0.00630572 0.11756006 0.02465295 0.00871511]\n",
      "[0.11840975 0.01734457 0.11227321 0.00851316 0.00838033]\n",
      "[0.04635174 0.00579174 0.12316428 0.04825946 0.00785575]\n",
      "[0.07757052 0.00956022 0.2138442  0.02348718 0.01399058]\n",
      "[0.0789892  0.03252896 0.05666659 0.00451126 0.00495913]\n",
      "[0.10466135 0.00790094 0.16159679 0.01192776 0.02382904]\n",
      "[0.07855897 0.00971267 0.21672555 0.01528251 0.0234391 ]\n",
      "[0.00732451 0.02691594 0.00582219 0.00159762 0.05077079]\n",
      "[0.04763205 0.02127469 0.12749664 0.02509819 0.00791716]\n",
      "[0.07333734 0.00617816 0.10863158 0.03996695 0.0076003 ]\n",
      "[0.03661068 0.03852151 0.09493614 0.00667005 0.00601983]\n",
      "[0.02209292 0.00763106 0.05526461 0.05954158 0.00423959]\n",
      "[0.02086471 0.00282943 0.05203973 0.06716361 0.00411832]\n",
      "[0.14560921 0.00759943 0.14369548 0.01081674 0.01040523]\n",
      "[0.05123288 0.00654816 0.13889029 0.01958947 0.03954479]\n",
      "[0.0048651  0.0244401  0.00535016 0.00166237 0.05622216]\n",
      "[0.05621486 0.01790695 0.07734884 0.02599566 0.01254556]\n",
      "[0.08032102 0.01631122 0.08150502 0.02534681 0.00632487]\n",
      "[0.05263705 0.00735844 0.14264819 0.04222218 0.00886038]\n",
      "[0.03792919 0.00488044 0.10077582 0.04861374 0.01382692]\n",
      "[0.09797516 0.003796   0.05418874 0.02058865 0.029693  ]\n",
      "[0.06553845 0.00329287 0.02333535 0.05409106 0.00347793]\n",
      "[0.00465708 0.00126923 0.00642355 0.00260076 0.09731748]\n",
      "[0.17843314 0.00434829 0.04810903 0.00500831 0.01627017]\n",
      "[0.00465708 0.00126923 0.00642355 0.00260076 0.09731748]\n",
      "[0.03234179 0.00427516 0.08493317 0.04064359 0.02815059]\n",
      "[0.0619724  0.02352954 0.10384517 0.01781854 0.00862375]\n",
      "[0.09827255 0.00953209 0.20757581 0.0182807  0.01263819]\n",
      "[0.0313637  0.02002498 0.08129247 0.0065228  0.04287877]\n",
      "[0.07750064 0.00708382 0.14871323 0.03381398 0.00955024]\n",
      "[0.02044199 0.00307269 0.05134252 0.00530949 0.0815376 ]\n",
      "[0.08239046 0.00747762 0.02875746 0.01479035 0.03807745]\n",
      "[0.1318475  0.00703885 0.13184413 0.01010847 0.01857339]\n",
      "[0.07719817 0.00255455 0.02382474 0.00360576 0.06348509]\n",
      "[0.02862692 0.00386087 0.07437939 0.03785638 0.03454343]\n",
      "[0.0231932  0.02445897 0.05763192 0.00767007 0.03808295]\n",
      "[0.04081033 0.01112048 0.1088674  0.01156538 0.04730436]\n",
      "[0.03300465 0.00426927 0.08667792 0.05805196 0.00593412]\n",
      "[0.03779228 0.0048371  0.10033816 0.05445861 0.00665022]\n",
      "[0.0475148  0.01327433 0.12787199 0.00965611 0.0419168 ]\n",
      "[0.15231302 0.00738192 0.05919936 0.01618838 0.00652609]\n",
      "[0.09770608 0.00903847 0.05756474 0.00732145 0.03668989]\n",
      "[0.03019237 0.03750529 0.0515382  0.00431797 0.01605778]\n",
      "[0.03967556 0.00265795 0.04237964 0.06197925 0.00396712]\n",
      "[0.0878618  0.01077554 0.24319856 0.0168789  0.01413922]\n",
      "[0.12347749 0.01395644 0.11348187 0.01161418 0.00855488]\n",
      "[0.05888949 0.00839515 0.03944132 0.03054445 0.0254221 ]\n",
      "[0.05162741 0.00594672 0.12580813 0.04605031 0.00806394]\n",
      "[0.02329782 0.00988328 0.05877369 0.03239745 0.0335097 ]\n",
      "[0.04858115 0.00611671 0.13112141 0.04636101 0.00826393]\n",
      "[0.01373758 0.00198413 0.03170434 0.07251287 0.00305231]\n",
      "[0.05675277 0.01193765 0.14601797 0.03394712 0.00903735]\n",
      "[0.09582628 0.00728825 0.14909498 0.02738191 0.00986136]\n",
      "[0.16220611 0.00466169 0.06171968 0.0166044  0.00683326]\n",
      "[0.11859933 0.01956574 0.03422744 0.00359607 0.01519495]\n",
      "[0.01271704 0.01451394 0.00772171 0.0021801  0.07037235]\n",
      "[0.04812874 0.00680745 0.07713282 0.05017229 0.00570028]\n",
      "[0.14532326 0.00376163 0.04016662 0.00454959 0.03171227]\n",
      "[0.05587893 0.00202692 0.02131781 0.05931085 0.00324043]\n",
      "[0.02732779 0.02805997 0.06908658 0.01833593 0.01576422]\n",
      "[0.01945804 0.01325016 0.04740592 0.05118034 0.00602837]\n",
      "[0.00479797 0.01696237 0.00569656 0.00196521 0.06948448]\n",
      "[0.08511104 0.0187644  0.11213034 0.00846205 0.01925098]\n",
      "[0.08900534 0.00898789 0.06018801 0.03487011 0.00553578]\n",
      "[0.02165066 0.00321078 0.05478204 0.0055169  0.08032931]\n",
      "[0.05415023 0.02337557 0.14601486 0.0182952  0.00887429]\n",
      "[0.08880222 0.00912411 0.19940869 0.02272896 0.01210431]\n",
      "[0.05568602 0.00231687 0.02635732 0.03583493 0.03195248]\n",
      "[0.09460582 0.0100075  0.20152089 0.01933783 0.0122882 ]\n",
      "[0.12916821 0.00850369 0.17202454 0.01254267 0.01146832]\n",
      "[0.13575917 0.00814118 0.16066783 0.01185077 0.01104214]\n",
      "[0.05115916 0.00652614 0.13865691 0.02245814 0.03602758]\n",
      "[0.06785358 0.00870293 0.02127701 0.00321977 0.05666968]\n",
      "[0.06785779 0.00595573 0.11982436 0.02589026 0.02719655]\n",
      "[0.09932484 0.00959256 0.08925584 0.02805163 0.00706807]\n",
      "[0.01917583 0.00292803 0.04773942 0.00509221 0.08280336]\n",
      "[0.05585877 0.01518657 0.09283291 0.03414154 0.00647747]\n",
      "[0.03321066 0.00429371 0.08726572 0.05789734 0.00596493]\n",
      "[0.14904157 0.00671184 0.07540897 0.0168472  0.0072458 ]\n",
      "[0.00465708 0.00126923 0.00642355 0.00260076 0.09731748]\n",
      "[0.10838878 0.01861522 0.06811343 0.00573385 0.01627911]\n",
      "[0.10522927 0.00859356 0.18093456 0.01961766 0.01150235]\n",
      "[0.05570718 0.02575591 0.15035432 0.01057608 0.01333274]\n",
      "[0.13635838 0.00777314 0.15080228 0.01303393 0.01058989]\n",
      "[0.0878618  0.01077554 0.24319856 0.0168789  0.01413922]\n",
      "[0.0560516  0.02275877 0.046613   0.01683748 0.0171382 ]\n",
      "[0.06951048 0.01054936 0.0930982  0.03626878 0.006759  ]\n",
      "[0.06457253 0.00801334 0.17674865 0.03435868 0.01065579]\n",
      "[0.00493611 0.03234938 0.00498376 0.00134206 0.04219443]\n",
      "[0.08500059 0.0074673  0.1567729  0.03006667 0.01004755]\n",
      "[0.02107553 0.0101696  0.0522021  0.05647845 0.00405175]\n",
      "[0.11404661 0.00672567 0.12788193 0.01196085 0.02421763]\n",
      "[0.13172757 0.01006524 0.1514587  0.01120939 0.01052203]\n",
      "[0.03488198 0.00274672 0.0440458  0.04636468 0.02523279]\n",
      "[0.05414959 0.0119436  0.14669935 0.03474679 0.00902752]\n",
      "[0.09851811 0.01901543 0.10901001 0.00891984 0.01301912]\n",
      "[0.04454136 0.00197592 0.01599101 0.00315333 0.07871588]\n",
      "[0.04635174 0.00579174 0.12316428 0.04825946 0.00785575]\n",
      "[0.044723   0.0100879  0.10803351 0.04390279 0.00706968]\n",
      "[0.0165447  0.00233872 0.03975129 0.06581551 0.00919316]\n",
      "[0.00465708 0.00126923 0.00642355 0.00260076 0.09731748]\n",
      "[0.13570674 0.00456392 0.06638315 0.0251696  0.00662752]\n",
      "[0.08499963 0.00480181 0.086509   0.03997902 0.00675825]\n",
      "[0.0137938  0.01223773 0.0080913  0.00228827 0.07393206]\n",
      "[0.04516562 0.00686541 0.12150126 0.02446069 0.0363527 ]\n",
      "[0.05856036 0.00909044 0.10546085 0.01450019 0.04039426]\n",
      "[0.17771235 0.00433552 0.04793613 0.00499832 0.01660634]\n",
      "[0.10579945 0.00978897 0.21229066 0.01499586 0.01297936]\n",
      "[0.06063328 0.02925691 0.01854222 0.00227945 0.02343696]\n",
      "[0.08920429 0.00500579 0.09073732 0.03791911 0.00702348]\n",
      "[0.00495597 0.01843973 0.00598268 0.00879315 0.05813766]\n",
      "[0.14160162 0.00369569 0.03927387 0.00449803 0.033448  ]\n",
      "[0.18142054 0.00525808 0.07219104 0.00843967 0.00763093]\n",
      "[0.00523486 0.00120582 0.00784323 0.03012592 0.0625596 ]\n",
      "[0.09142865 0.00622291 0.11961975 0.01077661 0.03621902]\n",
      "[0.02517352 0.00286152 0.05170845 0.06571066 0.00417177]\n",
      "[0.0101633  0.00858066 0.02126288 0.04418063 0.02866525]\n",
      "[0.08374267 0.0074656  0.15707188 0.03046231 0.01004142]\n",
      "[0.14480228 0.00764381 0.14508588 0.01090145 0.01045741]\n",
      "[0.16401439 0.00658715 0.11198199 0.00888461 0.00921514]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11952652 0.02544327 0.03290506 0.00329272 0.00456532]\n",
      "[0.08147193 0.01869154 0.12326618 0.00915566 0.01929572]\n",
      "[0.04938886 0.03281644 0.12039259 0.00845698 0.00748797]\n",
      "[0.10835604 0.00622507 0.11764539 0.02745749 0.0085896 ]\n",
      "[0.02624579 0.00360489 0.06763133 0.03404168 0.04116871]\n",
      "[0.06858277 0.00666555 0.06178886 0.04488831 0.00530688]\n",
      "[0.07960049 0.00437863 0.07682901 0.04322372 0.0062187 ]\n",
      "[0.01970619 0.04767315 0.0460338  0.0033028  0.00334176]\n",
      "[0.12259516 0.01312992 0.10411689 0.01390978 0.00810725]\n",
      "[0.06706757 0.00475453 0.09016232 0.04570488 0.00664232]\n",
      "[0.00465708 0.00126923 0.00642355 0.00260076 0.09731748]\n",
      "[0.12489888 0.01538384 0.11631312 0.00883496 0.00869636]\n",
      "[0.00471889 0.00815342 0.00610464 0.00232196 0.08510784]\n",
      "[0.10816756 0.01544005 0.14657546 0.01071263 0.01111409]\n",
      "[0.0877814  0.02402517 0.10813708 0.00942332 0.0076209 ]\n",
      "[0.03575143 0.0211981  0.0477984  0.03604242 0.00396363]\n",
      "[0.07451852 0.00981226 0.13728966 0.01036057 0.03591433]\n",
      "[0.04970223 0.00418279 0.07461722 0.00908864 0.06158336]\n",
      "[0.08308124 0.00881731 0.19254905 0.02280393 0.01528879]\n",
      "[0.06493912 0.00454805 0.08530109 0.04713144 0.00638069]\n",
      "[0.00465708 0.00126923 0.00642355 0.00260076 0.09731748]\n",
      "[0.0273759  0.01968715 0.0697561  0.02692479 0.02019071]\n",
      "[0.06247232 0.03396817 0.08008903 0.00591322 0.00578367]\n",
      "[0.13338722 0.00659382 0.12052637 0.01833901 0.00912503]\n",
      "[0.08617404 0.01057537 0.23838297 0.01814565 0.01388677]\n",
      "[0.04996697 0.03764363 0.0732821  0.00535755 0.00522193]\n",
      "[0.05275497 0.00778069 0.01856948 0.02204572 0.04095331]\n",
      "[0.03882771 0.03572307 0.10145126 0.00875422 0.00721737]\n",
      "[0.01838309 0.03112851 0.00828018 0.00158764 0.03850509]\n",
      "[0.03998529 0.01812036 0.07335904 0.00610025 0.04390119]\n",
      "[0.0053962  0.00118811 0.00823966 0.03781207 0.05285378]\n",
      "[0.06897042 0.00860183 0.18941291 0.0168859  0.02897569]\n",
      "[0.03623335 0.00180675 0.01438023 0.01124665 0.07230268]\n",
      "[0.07708425 0.01340583 0.05436217 0.03296289 0.00502191]\n",
      "[0.08256002 0.01448605 0.15699097 0.02072403 0.00994429]\n",
      "[0.12826642 0.00842322 0.06455307 0.00589018 0.02689556]\n",
      "[0.03497086 0.00450247 0.09228799 0.05657622 0.00622821]\n",
      "[0.11081985 0.02063829 0.09805376 0.00751115 0.00755184]\n",
      "[0.04976458 0.00206847 0.01724396 0.00322569 0.07627983]\n",
      "[0.13817724 0.0039174  0.04866532 0.02680917 0.00583762]\n",
      "[0.00535344 0.0011928  0.00813459 0.03577495 0.05542619]\n",
      "[0.00736966 0.00131729 0.00707424 0.00263834 0.09605237]\n",
      "[0.09446569 0.00856875 0.18249363 0.01688669 0.01920798]\n",
      "[0.04572102 0.01212092 0.12265303 0.03080919 0.0185051 ]\n",
      "[0.13295001 0.00829569 0.16550822 0.01214567 0.01122378]\n",
      "[0.07025604 0.00516527 0.10011846 0.04319064 0.00715942]\n",
      "[0.03389321 0.03060743 0.08767752 0.01503617 0.01148563]\n",
      "[0.06804693 0.0108492  0.09286412 0.03634342 0.0067212 ]\n",
      "[0.09191678 0.02662458 0.08367916 0.00640201 0.00650526]\n",
      "[0.10423199 0.02269735 0.09330231 0.00714162 0.00719958]\n",
      "[0.03629779 0.00848648 0.09584429 0.05007357 0.00637536]\n",
      "[0.07808437 0.01798079 0.03615009 0.00982378 0.02643787]\n",
      "[0.0047426  0.00125984 0.00663368 0.00667491 0.09217278]\n",
      "[0.01015124 0.0082995  0.02113902 0.05705453 0.01302877]\n",
      "[0.04975141 0.02233887 0.07062486 0.00576892 0.03286489]\n",
      "[0.13145922 0.01904013 0.03629928 0.00827297 0.00498557]\n",
      "[0.05460607 0.00211307 0.01912159 0.0186776  0.05473935]\n",
      "[0.04669971 0.02186404 0.07792135 0.00623969 0.03392087]\n",
      "[0.08324854 0.01022839 0.23003579 0.02034139 0.0134492 ]\n",
      "[0.00480149 0.00450526 0.00655622 0.00795933 0.08462293]\n",
      "[0.09616674 0.01685946 0.16681389 0.01191663 0.0106022 ]\n",
      "[0.00533624 0.03309704 0.00591287 0.02003421 0.01714761]\n",
      "[0.1539887  0.00713856 0.129257   0.00993708 0.00986341]\n",
      "[0.17358751 0.00426243 0.04694666 0.00494118 0.01853012]\n",
      "[0.14648816 0.0087849  0.09306877 0.01318    0.00801653]\n",
      "[0.09596225 0.00279417 0.02994102 0.03855842 0.01125191]\n",
      "[0.12766232 0.00391279 0.05141693 0.03008071 0.00579817]\n",
      "[0.08438214 0.02216909 0.14145806 0.01015048 0.00942353]\n",
      "[0.06287224 0.00770192 0.16900383 0.03604301 0.01026602]\n",
      "[0.09698861 0.00927168 0.18078996 0.0130674  0.02181055]\n",
      "[0.00626426 0.04023402 0.00820692 0.00124456 0.02720719]\n",
      "[0.08364126 0.00266871 0.02537031 0.00369503 0.0604801 ]\n",
      "[0.03642897 0.00486383 0.09677515 0.01555568 0.05620518]\n",
      "[0.03567066 0.0060292  0.09419801 0.05397338 0.00631352]\n",
      "[0.09201918 0.00644615 0.12793688 0.03169171 0.00880996]\n",
      "[0.09635989 0.00781386 0.16122541 0.01191081 0.02736922]\n",
      "[0.09892378 0.00680676 0.13555623 0.02821372 0.00927713]\n",
      "[0.11951433 0.00381884 0.05116651 0.03295193 0.00565606]\n",
      "[0.00480438 0.00125306 0.00678548 0.00961792 0.08845644]\n",
      "[0.12048219 0.01670368 0.04875271 0.0046027  0.01750615]\n",
      "[0.02692797 0.03757457 0.06729695 0.01364749 0.00456887]\n",
      "[0.04221349 0.00550033 0.11319378 0.0217172  0.04398066]\n",
      "[0.12381118 0.00640247 0.11809868 0.02201441 0.00885814]\n",
      "[0.05232199 0.00416739 0.07621211 0.03130054 0.03257644]\n",
      "[0.05178405 0.02972653 0.13887237 0.00971691 0.00944912]\n",
      "[0.00503206 0.04303749 0.00448863 0.00090921 0.02323824]\n",
      "[0.18930421 0.00701412 0.05115274 0.00509286 0.00674606]\n",
      "[0.02096624 0.04610429 0.04974272 0.00359111 0.00510767]\n",
      "[0.05605331 0.02804836 0.15068215 0.01051001 0.00907589]\n",
      "[0.04881646 0.01599668 0.05851645 0.02210298 0.02504104]\n",
      "[0.0148313  0.00218358 0.03494594 0.05691435 0.02163285]\n",
      "[0.08901155 0.01363693 0.09589037 0.0250733  0.00717238]\n",
      "[0.00509169 0.04967973 0.00418093 0.00064021 0.01145771]\n",
      "[0.01534456 0.05003441 0.03341621 0.002434   0.00265078]\n",
      "[0.0165447  0.00233872 0.03975129 0.06581551 0.00919316]\n",
      "[0.00467729 0.00126701 0.0064732  0.00356342 0.09610187]\n",
      "[0.06138564 0.00213028 0.02253797 0.05722212 0.00338567]\n",
      "[0.15675103 0.00698663 0.12449731 0.0096471  0.00968479]\n",
      "[0.02256461 0.03316834 0.0550807  0.0225185  0.00396839]\n",
      "[0.05863335 0.01568422 0.02038792 0.03874928 0.00309645]\n",
      "[0.00551316 0.00117527 0.00852704 0.04338383 0.04581794]\n",
      "[0.09940396 0.00879224 0.03028857 0.03426887 0.0042937 ]\n",
      "[0.06370218 0.00797417 0.17437644 0.0214385  0.02744179]\n",
      "[0.05553133 0.00386277 0.06980704 0.05259153 0.00550482]\n",
      "[0.08673964 0.01484698 0.20707772 0.01448908 0.01237264]\n",
      "[0.09384457 0.00278236 0.0289858  0.02892266 0.0242797 ]\n",
      "[0.10492436 0.02422409 0.07725836 0.00609032 0.00643707]\n",
      "[0.12132458 0.00948067 0.18036181 0.01302487 0.01172525]\n",
      "[0.02564817 0.01894313 0.06497394 0.01549969 0.03687715]\n",
      "[0.04102489 0.01024398 0.10935314 0.03387844 0.0207755 ]\n",
      "[0.09020923 0.00273893 0.02774867 0.02103049 0.03580365]\n",
      "[0.09753571 0.00476784 0.08218817 0.03622538 0.00675658]\n",
      "[0.13414982 0.0057202  0.09728873 0.02135169 0.0080494 ]\n",
      "[0.0160585  0.04820878 0.03556793 0.00464719 0.00278319]\n",
      "[0.09797516 0.003796   0.05418874 0.02058865 0.029693  ]\n",
      "[0.1228768  0.00748283 0.14683307 0.01828611 0.01018834]\n",
      "[0.07282751 0.00905784 0.20041558 0.01429898 0.02916873]\n",
      "[0.14008378 0.00361263 0.03988668 0.02546062 0.00785625]\n",
      "[0.10146866 0.00485586 0.08015942 0.00699991 0.04182791]\n",
      "[0.00503251 0.00122803 0.00734602 0.02048589 0.07473272]\n",
      "[0.00523215 0.01200285 0.00709897 0.02494677 0.04941807]\n",
      "[0.00523545 0.00120575 0.00784468 0.03015397 0.06252418]\n",
      "[0.02286106 0.02579185 0.05661179 0.00478017 0.03947605]\n",
      "[0.02903199 0.01680791 0.01268428 0.02700941 0.0281565 ]\n",
      "[0.07730023 0.00449281 0.08046733 0.04351107 0.00635221]\n",
      "[0.03674448 0.02081967 0.09638158 0.03206641 0.00627747]\n",
      "[0.04245715 0.00265101 0.03563033 0.01205745 0.06594464]\n",
      "[0.0229587  0.00336023 0.05850432 0.00574136 0.07902168]\n",
      "[0.00518942 0.01641884 0.00669261 0.020848   0.0465524 ]\n",
      "[0.11152869 0.00525621 0.09123854 0.03007843 0.00740418]\n",
      "[0.03210707 0.0038273  0.06977121 0.01346651 0.0641056 ]\n",
      "[0.02425131 0.00326579 0.06176272 0.05726962 0.01378767]\n",
      "[0.11687066 0.01452425 0.14249486 0.01049145 0.00981227]\n",
      "[0.0745595  0.01224761 0.02336922 0.01716618 0.02987364]\n",
      "[0.07232579 0.00621745 0.1272893  0.03863732 0.0084645 ]\n",
      "[0.02442015 0.00338063 0.0624089  0.03705163 0.03885212]\n",
      "[0.12517574 0.00699253 0.13328036 0.01939782 0.00959068]\n",
      "[0.0240289  0.03208012 0.05938747 0.01701406 0.01201123]\n",
      "[0.00511809 0.0526207  0.00404469 0.0005211  0.00624168]\n",
      "[0.16335211 0.01000875 0.04445615 0.00998979 0.00598007]\n",
      "[0.07376433 0.01480983 0.02387173 0.03467172 0.00351398]\n",
      "[0.01239033 0.00140625 0.0082786  0.00270789 0.09371078]\n",
      "[0.14737273 0.00999886 0.04859502 0.0077254  0.01501205]\n",
      "[0.04273485 0.02395684 0.01449034 0.00223393 0.04060275]\n",
      "[0.04100769 0.00457086 0.09244124 0.0544535  0.00633199]\n",
      "[0.10226975 0.01424309 0.17794305 0.01270227 0.01125366]\n",
      "[0.06467395 0.03394929 0.07532538 0.00561817 0.00559443]\n",
      "[0.0381689  0.00498984 0.1016002  0.03127609 0.035246  ]\n",
      "[0.0891132  0.02711136 0.05025926 0.0043149  0.01140675]\n",
      "[0.12110439 0.01818361 0.06387113 0.01058003 0.00612958]\n",
      "[0.07727717 0.00952016 0.21299804 0.02482321 0.01255605]\n",
      "[0.05032989 0.00648744 0.13639429 0.01043833 0.0516592 ]\n",
      "[0.10480785 0.02209279 0.08630736 0.00842647 0.00688499]\n",
      "[0.10279099 0.00514551 0.07690241 0.02514313 0.01819048]\n",
      "[0.05126298 0.00289283 0.0454051  0.05751947 0.00429418]\n",
      "[0.15193732 0.00725138 0.13279168 0.01015243 0.00999605]\n",
      "[0.06568354 0.0222086  0.08644439 0.02127886 0.00625986]\n",
      "[0.05665007 0.00720954 0.15437958 0.01152289 0.04534102]\n",
      "[0.06221304 0.00430793 0.07971607 0.04886812 0.00607561]\n",
      "[0.04152997 0.00528041 0.11100269 0.05165328 0.00720927]\n",
      "[0.00465708 0.00126923 0.00642355 0.00260076 0.09731748]\n",
      "[0.10733466 0.00970453 0.20964537 0.01483469 0.01288009]\n",
      "[0.0087138  0.00481649 0.01731768 0.05338233 0.0248019 ]\n",
      "[0.03692964 0.02644839 0.09665476 0.014303   0.01822137]\n",
      "[0.0905027  0.01803961 0.15601925 0.01142542 0.01200334]\n",
      "[0.0230039  0.03144214 0.05644086 0.02474787 0.00405794]\n",
      "[0.09336852 0.00512846 0.08979361 0.03643636 0.00704471]\n",
      "[0.05630157 0.0062046  0.12818695 0.04391575 0.00824884]\n",
      "[0.10084312 0.00806821 0.05981947 0.03228724 0.00571883]\n",
      "[0.02398221 0.0033693  0.06122981 0.02877445 0.04951188]\n",
      "[0.0240913  0.00774709 0.01078805 0.0026208  0.07739926]\n",
      "[0.11399136 0.005932   0.10772687 0.02128114 0.01521819]\n",
      "[0.16849236 0.00901887 0.04548943 0.00467367 0.01232935]\n",
      "[0.059673   0.01981224 0.16202591 0.02022052 0.00975692]\n",
      "[0.15105001 0.00664909 0.04208448 0.01914413 0.00570542]\n",
      "[0.1046925  0.00710215 0.14002704 0.01062197 0.0282304 ]\n",
      "[0.162083   0.0061375  0.10030475 0.008179   0.01241091]\n",
      "[0.06627748 0.01726076 0.09645672 0.02736301 0.0067945 ]\n",
      "[0.02624579 0.00360489 0.06763133 0.03404168 0.04116871]\n",
      "[0.00723075 0.04173582 0.01081063 0.00680727 0.01693751]\n",
      "[0.08036386 0.00807648 0.17409815 0.02923643 0.01078441]\n",
      "[0.02931081 0.02269727 0.07505299 0.02815111 0.0120603 ]\n",
      "[0.14730487 0.01579096 0.06214669 0.00545756 0.00649561]\n",
      "[0.0873628  0.02254405 0.13262946 0.00958861 0.00878622]\n",
      "[0.00465708 0.00126923 0.00642355 0.00260076 0.09731748]\n",
      "[0.00489273 0.00124337 0.00700256 0.01382678 0.08314162]\n",
      "[0.13931871 0.00862286 0.09929655 0.01526467 0.00819678]\n",
      "[0.01639922 0.00137328 0.01104922 0.04161922 0.04314148]\n",
      "[0.04397906 0.0065369  0.11821533 0.01526094 0.04917876]\n",
      "[0.00472369 0.00784388 0.00613756 0.00269549 0.08519946]\n",
      "[0.07250232 0.00897214 0.19940598 0.02453043 0.01667309]\n",
      "[0.06227947 0.03129594 0.10588284 0.00761127 0.00702668]\n",
      "[0.14106986 0.00732543 0.07578837 0.00662301 0.02214373]\n",
      "[0.03390267 0.00445055 0.08936987 0.04153471 0.02581344]\n",
      "[0.04043707 0.01795115 0.01574177 0.03503906 0.0112194 ]\n",
      "[0.08478497 0.00585762 0.11439947 0.03611927 0.00806046]\n",
      "[0.00465708 0.00126923 0.00642355 0.00260076 0.09731748]\n",
      "[0.12723612 0.02104659 0.03512743 0.0068829  0.00484097]\n",
      "[0.0773364  0.00952719 0.21316705 0.02477875 0.01256491]\n",
      "[0.08271734 0.01924379 0.02537259 0.02515648 0.00368219]\n",
      "[0.0100547  0.00188592 0.02178351 0.003527   0.09192158]\n",
      "[0.14347237 0.00771696 0.14737742 0.01104106 0.0105434 ]\n",
      "[0.06478079 0.01858097 0.17670994 0.01903051 0.01054554]\n",
      "[0.19768066 0.00468866 0.05273775 0.00552461 0.00698045]\n",
      "[0.04428779 0.04485773 0.01387625 0.0019559  0.00224929]\n",
      "[0.01806075 0.00150672 0.00963883 0.00278645 0.09106615]\n",
      "[0.00525561 0.0035259  0.00773556 0.03002831 0.05844937]\n",
      "[0.00944225 0.02710553 0.01813716 0.01221095 0.03549746]\n",
      "[0.11638881 0.00920655 0.1940444  0.01388421 0.01229464]\n",
      "[0.00500837 0.02794193 0.00546189 0.00684255 0.04326856]\n",
      "[0.08469365 0.00785719 0.16517639 0.01215778 0.03142891]\n",
      "[0.01889208 0.00194838 0.02903071 0.0683196  0.00647274]\n",
      "[0.0441426  0.00559028 0.11845715 0.04969237 0.00760005]\n",
      "[0.18918584 0.00710416 0.05056401 0.00505305 0.0067154 ]\n",
      "[0.04644296 0.00599977 0.0162537  0.00301755 0.07076773]\n",
      "[0.11245472 0.00539853 0.03618682 0.03431436 0.00481835]\n",
      "[0.07278704 0.00837248 0.18218045 0.01534254 0.03023897]\n",
      "[0.06563209 0.00813901 0.17977185 0.03356342 0.01081427]\n",
      "[0.04798368 0.00604584 0.12941668 0.04680945 0.00817456]\n",
      "[0.03231606 0.03437551 0.01238479 0.0212109  0.00209686]\n",
      "[0.0047251  0.00884524 0.00607259 0.00229394 0.08388085]\n",
      "[0.08714224 0.02255417 0.02537603 0.00567472 0.02032309]\n",
      "[0.12203187 0.00577562 0.10050347 0.01173177 0.0247003 ]\n",
      "[0.04977796 0.00625865 0.13453621 0.04546275 0.00844294]\n",
      "[0.04639771 0.00961258 0.04067591 0.01809131 0.04378199]\n",
      "[0.10579486 0.00604712 0.1129294  0.02278539 0.01609721]\n",
      "[0.03971379 0.01107793 0.10545972 0.04436349 0.00685698]\n",
      "[0.00467588 0.00336258 0.00632657 0.00251598 0.09360476]\n",
      "[0.03831198 0.00978807 0.10165003 0.03265847 0.02469979]\n",
      "[0.08046455 0.00671317 0.02628715 0.04392509 0.00382161]\n",
      "[0.01297379 0.00195975 0.02963991 0.05905494 0.02042477]\n",
      "[0.01011164 0.03569142 0.01951384 0.00211444 0.03216162]\n",
      "[0.03185398 0.00431485 0.08294354 0.01385386 0.06202713]\n",
      "[0.07383662 0.00770237 0.16358564 0.01206873 0.03628507]\n",
      "[0.11389662 0.00358494 0.04653572 0.03556043 0.00534938]\n",
      "[0.10282434 0.00300861 0.02997196 0.0039608  0.05153331]\n",
      "[0.09971822 0.00907109 0.19502842 0.01954758 0.01207394]\n",
      "[0.16618805 0.00570274 0.06077171 0.00574566 0.01702365]\n",
      "[0.04641761 0.01533268 0.1245346  0.01617859 0.03061995]\n",
      "[0.05400231 0.00207288 0.01948986 0.02969049 0.04120753]\n",
      "[0.04198263 0.00357652 0.05987638 0.05557673 0.008333  ]\n",
      "[0.03184797 0.03783451 0.08139322 0.00585877 0.01103336]\n",
      "[0.00465708 0.00126923 0.00642355 0.00260076 0.09731748]\n",
      "[0.01068702 0.03637494 0.02110674 0.00218718 0.03049517]\n",
      "[0.04418595 0.01036272 0.11839905 0.03055584 0.02290654]\n",
      "[0.05049985 0.00638103 0.13665969 0.03713072 0.01825964]\n",
      "[0.16679169 0.00726572 0.09930682 0.00807316 0.00865426]\n",
      "[0.03628245 0.02833995 0.07018508 0.0055204  0.02767485]\n",
      "[0.09571357 0.01123517 0.13000498 0.00984879 0.02588604]\n",
      "[0.19831561 0.00470058 0.05287844 0.00528377 0.0069972 ]\n",
      "[0.18074164 0.00750203 0.06574568 0.00598113 0.00729194]\n",
      "[0.0878618  0.01077554 0.24319856 0.0168789  0.01413922]\n",
      "[0.04835486 0.02306559 0.09443499 0.02512354 0.00634887]\n",
      "[0.10213695 0.00784842 0.16213719 0.02334565 0.0105729 ]\n",
      "[0.07742235 0.00730082 0.15373419 0.02693682 0.01751262]\n",
      "[0.03109105 0.00380413 0.07307157 0.04458354 0.02529102]\n",
      "[0.01563159 0.01870248 0.03635175 0.01996585 0.03748505]\n",
      "[0.07310502 0.01876446 0.20050922 0.01393946 0.01180139]\n",
      "[0.11912907 0.0044364  0.06611745 0.01865516 0.02171909]\n",
      "[0.11491788 0.01740144 0.09106138 0.00719852 0.01262688]\n",
      "[0.04567676 0.00600497 0.08871011 0.03895022 0.02153005]\n",
      "[0.08741118 0.00732975 0.15248837 0.02983208 0.00988556]\n",
      "[0.06223379 0.03613344 0.06007491 0.00459233 0.00481197]\n",
      "[0.09879399 0.01218724 0.09026239 0.00735063 0.02847581]\n",
      "[0.15725915 0.00538562 0.08215482 0.01544343 0.00771073]\n",
      "[0.0878618  0.01077554 0.24319856 0.0168789  0.01413922]\n",
      "[0.05067164 0.00646592 0.13726176 0.0233312  0.0353226 ]\n",
      "[0.09220509 0.00912467 0.19849367 0.02167367 0.01211593]\n",
      "[0.0734338  0.00587065 0.11483004 0.01409981 0.04021664]\n",
      "[0.06219759 0.02466945 0.16895555 0.01176678 0.0100734 ]\n",
      "[0.15260442 0.00561418 0.08945148 0.01603418 0.00797783]\n",
      "[0.16021348 0.01346616 0.05522974 0.00511233 0.0064016 ]\n",
      "[0.12379403 0.00866198 0.03474608 0.00403672 0.0324062 ]\n",
      "[0.07784477 0.01304744 0.02353621 0.0045796  0.042885  ]\n",
      "[0.0878618  0.01077554 0.24319856 0.0168789  0.01413922]\n",
      "[0.06480483 0.00520143 0.10256135 0.04474331 0.00718655]\n",
      "[0.02928784 0.02151032 0.07502813 0.03343834 0.00759816]\n",
      "[0.08324803 0.01533636 0.07910933 0.01352489 0.02191329]\n",
      "[0.03608724 0.00464721 0.09549468 0.05312578 0.00965113]\n",
      "[0.1048253  0.00678988 0.13160793 0.0104641  0.02945907]\n",
      "[0.11132262 0.02198981 0.08409844 0.00659586 0.00688675]\n",
      "[0.14258648 0.00776568 0.14890388 0.01113406 0.01060068]\n",
      "[0.05742101 0.01856126 0.15565951 0.02332662 0.00943328]\n",
      "[0.09306804 0.00484714 0.08466155 0.03023052 0.01578279]\n",
      "[0.11123994 0.01647025 0.11230792 0.012161   0.0082757 ]\n",
      "[0.082447   0.00631516 0.1270995  0.03514142 0.00861758]\n",
      "[0.00534425 0.00119381 0.00811201 0.03533718 0.05597898]\n",
      "[0.08296797 0.00728672 0.15256815 0.03136728 0.00981819]\n",
      "[0.01932073 0.01360804 0.00935541 0.00231315 0.06910266]\n",
      "[0.0641922  0.01237715 0.17548148 0.01860195 0.02270876]\n",
      "[0.09307636 0.0284567  0.06368806 0.00509461 0.00556069]\n",
      "[0.01934271 0.02320454 0.04646306 0.03872525 0.00361499]\n",
      "[0.05807883 0.00345866 0.05387873 0.01459075 0.05389621]\n",
      "[0.02682469 0.02582853 0.0677067  0.03061059 0.00471079]\n",
      "[0.05207213 0.01950868 0.05267683 0.01240035 0.02986483]\n",
      "[0.10654456 0.02410071 0.07479183 0.00594167 0.00634803]\n",
      "[0.08626669 0.01771767 0.16246366 0.01435001 0.01022822]\n",
      "[0.01764087 0.04879125 0.04005912 0.00289141 0.00301457]\n",
      "[0.0226854  0.04606028 0.05465223 0.00389624 0.00381374]\n",
      "[0.08705684 0.01068357 0.24090789 0.01674077 0.01494392]\n",
      "[0.10439384 0.01357988 0.1666375  0.01202634 0.01314848]\n",
      "[0.05800556 0.02227568 0.15710851 0.0176424  0.00947183]\n",
      "[0.14167235 0.00780834 0.15027825 0.01125834 0.01065039]\n",
      "[0.10196616 0.01260596 0.06156972 0.00793016 0.02746254]\n",
      "[0.10778009 0.00848302 0.17732385 0.01923921 0.01137414]\n",
      "[0.14637251 0.0162968  0.05943923 0.00527116 0.00634741]\n",
      "[0.02020326 0.00397105 0.02620027 0.0679646  0.00287559]\n",
      "[0.05232494 0.00855223 0.12942507 0.04174293 0.0082184 ]\n",
      "[0.10860284 0.00963478 0.20746022 0.01470156 0.01279809]\n",
      "[0.02403969 0.00981588 0.06100542 0.01967487 0.04916965]\n",
      "[0.01176166 0.00771931 0.02605342 0.02491682 0.05348412]\n",
      "[0.00489104 0.02732957 0.0052163  0.00154535 0.05109744]\n",
      "[0.05856195 0.0107727  0.15948899 0.02233313 0.02419133]\n",
      "[0.08075046 0.01885911 0.11467576 0.01454219 0.01304293]\n",
      "[0.05900987 0.01772643 0.16035757 0.01149661 0.02488104]\n",
      "[0.08632194 0.01684066 0.14916145 0.0108274  0.01704034]\n",
      "[0.04392223 0.00514329 0.10673459 0.05142276 0.00704775]\n",
      "[0.00624268 0.0010952  0.01031958 0.07813817 0.00193128]\n",
      "[0.05132808 0.00208308 0.0178467  0.0081381  0.06942084]\n",
      "[0.12415953 0.00855255 0.0899368  0.02122299 0.00751136]\n",
      "[0.11109351 0.00635728 0.11839386 0.00930808 0.02998662]\n",
      "[0.08396851 0.00551775 0.10566338 0.03763582 0.00763843]\n",
      "[0.03699716 0.01492318 0.09745833 0.04040525 0.00639475]\n",
      "[0.1035321  0.01391807 0.17819364 0.01272959 0.01128927]\n",
      "[0.03578154 0.03882953 0.03329335 0.00284114 0.0143646 ]\n",
      "[0.11557202 0.01305418 0.09180251 0.00740777 0.01998374]\n",
      "[0.07695159 0.00926487 0.20635733 0.02587332 0.01223997]\n",
      "[0.0591455  0.00842204 0.100421   0.04216168 0.00696025]\n",
      "[0.09415109 0.00476727 0.05179503 0.03997589 0.00526706]\n",
      "[0.03588824 0.03891262 0.09284621 0.00652615 0.00590538]\n",
      "[0.0718004  0.02350199 0.04231097 0.02118138 0.00426099]\n",
      "[0.02819864 0.01180832 0.07247839 0.04998973 0.00510652]\n",
      "[0.1081464  0.00581052 0.1066362  0.02789231 0.00955669]\n",
      "[0.00469158 0.00511155 0.00624555 0.00244515 0.09050283]\n",
      "[0.00514445 0.05555648 0.00390869 0.00040221 0.00103484]\n",
      "[0.05349239 0.0219194  0.14427214 0.01472951 0.01637705]\n",
      "[0.03911076 0.00172412 0.01739438 0.06120331 0.00839787]\n",
      "[0.17399452 0.00427508 0.04774118 0.00960678 0.01243778]\n",
      "[0.13555466 0.01114693 0.09146082 0.00745168 0.01539406]\n",
      "[0.05700263 0.00655699 0.02142037 0.04328447 0.01464037]\n",
      "[0.08953942 0.0197284  0.14605127 0.01177204 0.00948478]\n",
      "[0.02963549 0.01980241 0.01343487 0.04306014 0.0022574 ]\n",
      "[0.12380061 0.01089184 0.11253626 0.00877044 0.01764145]\n",
      "[0.05074368 0.02753831 0.01990901 0.00243207 0.03027185]\n",
      "[0.1106173  0.00751695 0.10101973 0.02627302 0.0078274 ]\n",
      "[0.1312127  0.00839124 0.16850174 0.01232804 0.01133612]\n",
      "[0.05452543 0.00683944 0.14811261 0.03814541 0.01383169]\n",
      "[0.09838044 0.012132   0.18804893 0.01617468 0.01169047]\n",
      "[0.06668273 0.00828298 0.18280315 0.02867207 0.01608462]\n",
      "[0.1221803  0.00733565 0.14216063 0.01073946 0.02049615]\n",
      "[0.06811196 0.01235391 0.17623235 0.02695551 0.01064253]\n",
      "[0.02173648 0.00832776 0.05460069 0.01213399 0.0626674 ]\n",
      "[0.08099895 0.00871652 0.18925679 0.01364332 0.02801094]\n",
      "[0.00637648 0.00146567 0.01131641 0.00289581 0.09559864]\n",
      "[0.13161452 0.00958555 0.15626497 0.01152514 0.01075221]\n",
      "[0.0631759  0.00285684 0.04120145 0.0539662  0.00428802]\n",
      "[0.03230034 0.02964437 0.01170257 0.00185077 0.03507706]\n",
      "[0.03320445 0.00167339 0.01503975 0.04097755 0.03639974]\n",
      "[0.00637648 0.00146567 0.01131641 0.00289581 0.09559864]\n",
      "[0.08579229 0.00532953 0.10020346 0.03777128 0.00741202]\n",
      "[0.14518879 0.01774781 0.0395169  0.00528874 0.00537236]\n",
      "[0.01066497 0.03397956 0.00758623 0.02940829 0.00152565]\n",
      "[0.14891719 0.00784744 0.13391515 0.01020059 0.00999413]\n",
      "[0.10927622 0.00858336 0.17956005 0.01840302 0.01150276]\n",
      "[0.05185175 0.00436512 0.0409852  0.02313675 0.04480593]\n",
      "[0.17603292 0.01013181 0.05135904 0.00499278 0.006509  ]\n",
      "[0.00520438 0.00120916 0.00776834 0.02867388 0.06439319]\n",
      "[0.05884181 0.00831245 0.09675557 0.02334495 0.03112826]\n",
      "[0.00471047 0.00126337 0.00655472 0.00514393 0.09410605]\n",
      "[0.08869717 0.02887703 0.02561977 0.00923074 0.00368831]\n",
      "[0.1042445  0.00744159 0.15083699 0.02420622 0.01007762]\n",
      "[0.04496151 0.00578647 0.12096555 0.02808559 0.03388447]\n",
      "[0.08605717 0.00671191 0.13657172 0.03254867 0.00911878]\n",
      "[0.12416323 0.00672489 0.12650173 0.02070647 0.00925715]\n",
      "[0.05911075 0.0390429  0.0177012  0.00185966 0.00678131]\n",
      "[0.10814777 0.00300894 0.03288383 0.03915132 0.00503719]\n",
      "[0.03570093 0.00458906 0.09437104 0.05602827 0.00633741]\n",
      "[0.00465708 0.00126923 0.00642355 0.00260076 0.09731748]\n",
      "[0.06470521 0.0343818  0.0711505  0.00534334 0.00539325]\n",
      "[0.11307472 0.00925573 0.09365935 0.02357836 0.00750108]\n",
      "[0.06871522 0.0049846  0.0957769  0.04433937 0.00693152]\n",
      "[0.08935924 0.02269863 0.12668032 0.00921369 0.00853586]\n",
      "[0.00706902 0.01901785 0.01160723 0.05186732 0.00181581]\n",
      "[0.17280702 0.00610355 0.09683163 0.00796159 0.0086466 ]\n",
      "[0.10566776 0.00429932 0.06761583 0.03545074 0.00620453]\n",
      "[0.0300607  0.00321336 0.05964783 0.06288969 0.00462164]\n",
      "[0.10798637 0.009332   0.19964701 0.01601832 0.01242246]\n",
      "[0.0114152  0.02302273 0.00899441 0.04486115 0.00172012]\n",
      "[0.00504554 0.00122659 0.00737804 0.02110671 0.07394877]\n",
      "[0.13144152 0.00594005 0.10382414 0.02137237 0.008312  ]\n",
      "[0.00582471 0.01199219 0.00855126 0.0531509  0.01370367]\n",
      "[0.05421629 0.00693147 0.1474538  0.01110524 0.04777403]\n",
      "[0.02710498 0.02236551 0.0687322  0.03356964 0.00713601]\n",
      "[0.14883151 0.0074222  0.13814321 0.01047847 0.01019687]\n",
      "[0.04475449 0.00213071 0.02381007 0.0346102  0.03837987]\n",
      "[0.05930328 0.00739953 0.16173355 0.03595303 0.01280946]\n",
      "[0.10200139 0.00289268 0.03153747 0.04181632 0.00445691]\n",
      "[0.05837218 0.00542501 0.10912477 0.03670683 0.01905273]\n",
      "[0.05101083 0.02204333 0.13714152 0.01892456 0.01231802]\n",
      "[0.00902482 0.01849144 0.01745349 0.02564664 0.03454918]\n",
      "[0.19355998 0.00461131 0.05182471 0.0070876  0.00687177]\n",
      "[0.12004791 0.01748425 0.10726986 0.0081975  0.00816901]\n",
      "[0.15054868 0.01249549 0.07181506 0.00830235 0.00703922]\n",
      "[0.06924403 0.01558823 0.18965607 0.02074911 0.01126036]\n",
      "[0.11547454 0.0053709  0.0931838  0.02843066 0.00755839]\n",
      "[0.02010706 0.00289391 0.05014569 0.03502688 0.04476482]\n",
      "[0.02812949 0.01700658 0.0722795  0.00607928 0.05079098]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04311427 0.00195064 0.01564868 0.00313355 0.07938146]\n",
      "[0.00490563 0.0289541  0.00514105 0.00147956 0.04821621]\n",
      "[0.0539042  0.00678564 0.14637457 0.03439704 0.01899135]\n",
      "[0.05651182 0.02499018 0.15270576 0.01075025 0.01404334]\n",
      "[0.04054181 0.02684964 0.07929836 0.02356685 0.0054683 ]\n",
      "[0.12801741 0.01144272 0.04469377 0.01966753 0.00540681]\n",
      "[0.04989196 0.00636706 0.13502605 0.02526923 0.03351999]\n",
      "[0.05817964 0.01233223 0.1582034  0.03185063 0.0096315 ]\n",
      "[0.05931271 0.00436843 0.08184853 0.04738597 0.00886166]\n",
      "[0.08155657 0.01002772 0.22520821 0.0216113  0.01319613]\n",
      "[0.05699113 0.00713631 0.15515553 0.03535601 0.01537045]\n",
      "[0.07349872 0.00913453 0.20232566 0.01441416 0.02849773]\n",
      "[0.05943976 0.01027886 0.16203849 0.02147717 0.0256578 ]\n",
      "[0.0587058  0.0031395  0.04855174 0.04312099 0.01873539]\n",
      "[0.05078566 0.00646132 0.13755565 0.0270856  0.030554  ]\n",
      "[0.15040607 0.006764   0.12000025 0.0093791  0.01325287]\n",
      "[0.00588199 0.00113479 0.0094333  0.06095475 0.02362995]\n",
      "[0.00769273 0.00141945 0.01472105 0.04478346 0.04236087]\n",
      "[0.05142769 0.02064963 0.10428417 0.02673948 0.00688896]\n",
      "[0.05284505 0.00670261 0.14342642 0.02616898 0.03007806]\n",
      "[0.06485928 0.01218412 0.05819254 0.01495131 0.03454195]\n",
      "[0.10392753 0.01616213 0.15600857 0.01127108 0.01022445]\n",
      "[0.06931931 0.02987255 0.02740778 0.01409305 0.00344999]\n",
      "[0.03643534 0.00474268 0.09658188 0.04138242 0.02401302]\n",
      "[0.03103794 0.01193326 0.07939636 0.01740526 0.04422035]\n",
      "[0.00941198 0.02103239 0.01840851 0.02174729 0.03459655]\n",
      "[0.06600886 0.02224398 0.18000275 0.01304711 0.01068205]\n",
      "[0.02143298 0.00289683 0.05366115 0.06673709 0.00420332]\n",
      "[0.09281978 0.00672151 0.13497677 0.03041996 0.00915233]\n",
      "[0.04334566 0.00617166 0.11614273 0.04931786 0.00747178]\n",
      "[0.04333907 0.01310382 0.10434851 0.04032599 0.00684149]\n",
      "[0.05852802 0.00736114 0.15961444 0.02518555 0.0268379 ]\n",
      "[0.10614295 0.01650321 0.11887186 0.00895759 0.01388516]\n",
      "[0.14039617 0.00788615 0.15267793 0.01136399 0.01074231]\n",
      "[0.07496995 0.00930262 0.20651233 0.01466663 0.02702697]\n",
      "[0.02984824 0.02495746 0.07661261 0.00604789 0.03537509]\n",
      "[0.02697845 0.00367929 0.06970008 0.03614113 0.0379765 ]\n",
      "[0.02492771 0.01143987 0.0634449  0.01718211 0.04883138]\n",
      "[0.08401405 0.0181155  0.18217683 0.01282488 0.01111847]\n",
      "[0.10683117 0.00435187 0.06619025 0.01382151 0.03288096]\n",
      "[0.02343436 0.02923244 0.05788814 0.01790148 0.01642096]\n",
      "[0.11582122 0.00584604 0.10440091 0.01630096 0.02109453]\n",
      "[0.15159329 0.00700802 0.12647034 0.01116391 0.00969462]\n",
      "[0.02191298 0.04011257 0.03099533 0.01478455 0.00274726]\n",
      "[0.04047328 0.00524829 0.10814939 0.03269416 0.03166787]\n",
      "[0.03297951 0.02639107 0.08536238 0.01632735 0.01806261]\n",
      "[0.09754949 0.01267478 0.11801497 0.00905145 0.02425616]\n",
      "[0.12059294 0.01387121 0.03399226 0.00958035 0.01728006]\n",
      "[0.02323676 0.02471274 0.05774818 0.00647165 0.03910002]\n",
      "[0.08551988 0.0079282  0.16878058 0.02819203 0.01061798]\n",
      "[0.11521742 0.00927098 0.1960628  0.01400718 0.01237038]\n",
      "[0.02063262 0.03614008 0.0493761  0.01936231 0.00363649]\n",
      "[0.02290248 0.02182154 0.05672831 0.03865126 0.00417164]\n",
      "[0.10261341 0.00300487 0.02992136 0.00395788 0.05163169]\n",
      "[0.11910147 0.00988927 0.18147504 0.01307918 0.01173767]\n",
      "[0.06279687 0.00790219 0.17185477 0.01461805 0.03665334]\n",
      "[0.02625877 0.01321779 0.06695961 0.03565128 0.02165342]\n",
      "[0.11520961 0.00927141 0.19607626 0.014008   0.01237089]\n",
      "[0.10253468 0.02390265 0.02927836 0.01149027 0.00413661]\n",
      "[0.12963134 0.0114228  0.14328085 0.01065255 0.01008778]\n",
      "[0.06592721 0.01645547 0.0793909  0.03011515 0.00599161]\n",
      "[0.05489163 0.02403692 0.12459552 0.00904577 0.02029043]\n",
      "[0.05998389 0.03190468 0.02254773 0.00546533 0.01462521]\n",
      "[0.0654239  0.01995379 0.17846706 0.01668202 0.01062435]\n",
      "[0.00489273 0.00124337 0.00700256 0.01382678 0.08314162]\n",
      "[0.05054734 0.03980022 0.04904252 0.00414104 0.004064  ]\n",
      "[0.04697174 0.00592582 0.12652938 0.04756896 0.00802321]\n",
      "[0.02085299 0.01063159 0.05153782 0.05594265 0.00401191]\n",
      "[0.10398388 0.00988883 0.21541902 0.01518645 0.01309675]\n",
      "[0.02600551 0.0029229  0.04945327 0.03440353 0.04316545]\n",
      "[0.08688871 0.00616556 0.12194232 0.034323   0.00844723]\n",
      "[0.11692173 0.00917724 0.19312614 0.01382827 0.01226018]\n",
      "[0.1640121  0.00609474 0.09869072 0.00808    0.01193622]\n",
      "[0.07601545 0.00606525 0.11931127 0.01305642 0.03985989]\n",
      "[0.14822547 0.00647628 0.1133736  0.01418361 0.00902763]\n",
      "[0.01612037 0.0314685  0.03675124 0.02854223 0.00321692]\n",
      "[0.07304427 0.03367362 0.02131588 0.00228088 0.01022163]\n",
      "[0.05968278 0.0074334  0.16279702 0.03802868 0.00992442]\n",
      "[0.06613146 0.0082928  0.18136071 0.01314992 0.03586265]\n",
      "[0.04786835 0.00564923 0.11899329 0.04832    0.00768476]\n",
      "[0.10471692 0.00345856 0.04342536 0.03906887 0.00505596]\n",
      "[0.09137841 0.00810099 0.17173476 0.02573623 0.01085003]\n",
      "[0.02740249 0.00386794 0.07114999 0.00650393 0.0745793 ]\n",
      "[0.0705025  0.00585053 0.11583906 0.02132517 0.03229958]\n",
      "[0.00541296 0.00118627 0.00828084 0.03861036 0.05184572]\n",
      "[0.13734076 0.00358723 0.03882519 0.01675588 0.01999796]\n",
      "[0.07994683 0.01760871 0.16275308 0.01658742 0.01014121]\n",
      "[0.09598138 0.00426172 0.06927131 0.03858853 0.00612703]\n",
      "[0.03243952 0.04008494 0.08291954 0.00586842 0.0065862 ]\n",
      "[0.08183567 0.00653119 0.13296113 0.0345273  0.0088822 ]\n",
      "[0.00647361 0.00147677 0.01159284 0.00291248 0.09550153]\n",
      "[0.07154721 0.01960782 0.19600268 0.01362915 0.0115546 ]\n",
      "[0.0712104  0.00679259 0.14275507 0.0368438  0.00917066]\n",
      "[0.06062197 0.01173457 0.16538947 0.01203315 0.0341789 ]\n",
      "[0.05245325 0.00560365 0.11239791 0.0120632  0.05184363]\n",
      "[0.07877927 0.02264625 0.06870319 0.01781562 0.00562859]\n",
      "[0.00948183 0.00182047 0.0201533  0.00342869 0.09249427]\n",
      "[0.06179943 0.01473384 0.06815694 0.0058982  0.04187858]\n",
      "[0.10324239 0.00456439 0.07465591 0.03005809 0.01303586]\n",
      "[0.02876661 0.00723729 0.07465418 0.02378055 0.0459836 ]\n",
      "[0.11373    0.01022691 0.13374683 0.0184987  0.00939408]\n",
      "[0.0469758  0.00895246 0.12639204 0.03936903 0.0128045 ]\n",
      "[0.09280141 0.00755592 0.13498542 0.01029664 0.03289989]\n",
      "[0.01801845 0.0382858  0.04189252 0.00340011 0.0212703 ]\n",
      "[0.05495584 0.03135975 0.03087651 0.0029661  0.02026898]\n",
      "[0.15803781 0.00454946 0.05989655 0.01828132 0.00671993]\n",
      "[0.02302329 0.00310044 0.05822469 0.06236652 0.00840055]\n",
      "[0.13560207 0.00755311 0.03806901 0.01343953 0.01767409]\n",
      "[0.15830683 0.00670625 0.11668115 0.01020822 0.00934379]\n",
      "[0.03877799 0.00495401 0.10315064 0.05371878 0.00679765]\n",
      "[0.09948541 0.00635158 0.12340384 0.02973257 0.00871723]\n",
      "[0.03483279 0.01501977 0.02468431 0.03557852 0.01759465]\n",
      "[0.08291366 0.01830362 0.12090915 0.01317124 0.01452648]\n",
      "[0.02489747 0.03014878 0.06211005 0.00495606 0.03015512]\n",
      "[0.01246883 0.0536282  0.00576546 0.0005873  0.00126091]\n",
      "[0.14751201 0.01072055 0.10475637 0.00828713 0.00950328]\n",
      "[0.04267545 0.00932029 0.11403666 0.04517544 0.00732824]\n",
      "[0.17162094 0.00575604 0.08773382 0.00741162 0.01100346]\n",
      "[0.11012834 0.01100502 0.1040296  0.01120041 0.02040093]\n",
      "[0.08799079 0.00849224 0.09895695 0.00803175 0.03817105]\n",
      "[0.04935561 0.00635276 0.13358127 0.01522316 0.04646159]\n",
      "[0.07147412 0.0088319  0.19644057 0.02917868 0.01168808]\n",
      "[0.04584421 0.00579209 0.12331225 0.04841523 0.00785456]\n",
      "[0.00520558 0.0013319  0.00798441 0.00269488 0.09676916]\n",
      "[0.03529223 0.00460174 0.09331099 0.0433764  0.02242626]\n",
      "[0.09289928 0.03245339 0.02615494 0.00261983 0.00374345]\n",
      "[0.06430744 0.02851975 0.10517143 0.00767099 0.01124264]\n",
      "[0.13442767 0.00861715 0.15913999 0.01173868 0.01094352]\n",
      "[0.0311595  0.0263562  0.04272529 0.0305601  0.00359557]\n",
      "[0.17121378 0.00423792 0.04743763 0.00989671 0.01327805]\n",
      "[0.04649144 0.02350457 0.01897492 0.00252742 0.03927483]\n",
      "[0.0643352  0.02905411 0.09429616 0.01116398 0.00653645]\n",
      "[0.07815311 0.00865168 0.07381667 0.03519587 0.00927014]\n",
      "[0.11631171 0.00877925 0.18280153 0.01549706 0.01176709]\n",
      "[0.0878618  0.01077554 0.24319856 0.0168789  0.01413922]\n",
      "[0.08223464 0.0314318  0.05979302 0.00474508 0.00517064]\n",
      "[0.00567689 0.00332271 0.00878141 0.05017102 0.03329994]\n",
      "[0.15851921 0.00688938 0.12145059 0.00946148 0.00957046]\n",
      "[0.08196546 0.00251658 0.02709798 0.04941607 0.00392847]\n",
      "[0.01137469 0.03604906 0.0063544  0.00128558 0.03284621]\n",
      "[0.07677595 0.00681343 0.14178365 0.03504375 0.00921425]\n",
      "[0.07756426 0.00822572 0.17682423 0.01286766 0.03202019]\n",
      "[0.01684392 0.0026616  0.04110352 0.00469205 0.08513452]\n",
      "[0.03933862 0.00513096 0.10494184 0.02989291 0.03605063]\n",
      "[0.11868026 0.00843982 0.17320668 0.01602622 0.01135583]\n",
      "[0.08385664 0.01800974 0.07727416 0.00633218 0.02593502]\n",
      "[0.12267052 0.00886106 0.18322055 0.01322478 0.01188846]\n",
      "[0.09476973 0.01006979 0.22270689 0.01736533 0.01329047]\n",
      "[0.08869356 0.00889949 0.06342987 0.00581596 0.04209821]\n",
      "[0.04775867 0.02164666 0.07306588 0.02921514 0.00534534]\n",
      "[0.08510712 0.01545344 0.09782117 0.00770045 0.02712096]\n",
      "[0.05853671 0.00729747 0.15952703 0.03888886 0.009753  ]\n",
      "[0.11549896 0.020993   0.0841826  0.00663718 0.00696855]\n",
      "[0.09667915 0.02422674 0.0957442  0.00723783 0.007177  ]\n",
      "[0.14502874 0.01218729 0.06739583 0.005919   0.01308246]\n",
      "[0.1211371  0.0089454  0.18586275 0.01338575 0.01198761]\n",
      "[0.00465708 0.00126923 0.00642355 0.00260076 0.09731748]\n",
      "[0.06499909 0.00664858 0.14065591 0.03930176 0.008973  ]\n",
      "[0.12650003 0.00865044 0.17662201 0.01282277 0.01164084]\n",
      "[0.10213428 0.00571805 0.10597995 0.03126859 0.00794394]\n",
      "[0.04969029 0.00624825 0.13428606 0.04552855 0.00842983]\n",
      "[0.04166583 0.00545986 0.11167366 0.01693987 0.05036487]\n",
      "[0.05955342 0.00741806 0.16242793 0.03812577 0.00990507]\n",
      "[0.1612479  0.0067393  0.11674885 0.00917503 0.00939402]\n",
      "[0.05651951 0.00711792 0.15387502 0.02775251 0.02521708]\n",
      "[0.0878618  0.01077554 0.24319856 0.0168789  0.01413922]\n",
      "[0.0347131  0.01441296 0.08061605 0.04335607 0.00556815]\n",
      "[0.02287766 0.04352776 0.05535419 0.00742919 0.00387677]\n",
      "[0.0251514  0.00632289 0.02576435 0.00436021 0.07647163]\n",
      "[0.1338886  0.00458655 0.06516052 0.00607028 0.03136878]\n",
      "[0.1542759  0.00712276 0.12876214 0.00990693 0.00984484]\n",
      "[0.08254414 0.0079145  0.16803443 0.01903411 0.02338153]\n",
      "[0.01325824 0.00216878 0.03075557 0.02169591 0.06676077]\n",
      "[0.11324804 0.00613702 0.11398749 0.02627085 0.00849665]\n",
      "[0.0371364  0.00766466 0.09856332 0.01899231 0.04638954]\n",
      "[0.00499517 0.03892857 0.00467898 0.00107561 0.03052573]\n",
      "[0.15547807 0.01597835 0.04201894 0.00420124 0.00567499]\n",
      "[0.03422866 0.00569954 0.09009317 0.05528397 0.00609996]\n",
      "[0.04799667 0.00942267 0.05668183 0.04820382 0.00470491]\n",
      "[0.03647889 0.00468133 0.09659076 0.05544437 0.00645377]\n",
      "[0.00624268 0.0010952  0.01031958 0.07813817 0.00193128]\n",
      "[0.05924565 0.01619298 0.12141497 0.00914247 0.03291744]\n",
      "[0.13711458 0.00806664 0.15833237 0.01170848 0.0109545 ]\n",
      "[0.11586454 0.00624394 0.11609108 0.02506343 0.00863699]\n",
      "[0.15755736 0.00907242 0.10289184 0.0082303  0.00865563]\n",
      "[0.08587388 0.01280798 0.16432124 0.01191814 0.02227906]\n",
      "[0.09142751 0.00866952 0.18549879 0.01338354 0.02445981]\n",
      "[0.03351337 0.00471184 0.08830633 0.03367919 0.03542008]\n",
      "[0.04669971 0.02186404 0.07792135 0.00623969 0.03392087]\n",
      "[0.05265183 0.03629665 0.07483761 0.00550367 0.00632046]\n",
      "[0.06452333 0.01562902 0.12565022 0.02778506 0.00816185]\n",
      "[0.13222029 0.01197568 0.13222141 0.00994596 0.00960148]\n",
      "[0.10827226 0.00917557 0.19514302 0.01395614 0.01545681]\n",
      "[0.0861975  0.01444626 0.09345425 0.00746753 0.02907854]\n",
      "[0.08094251 0.0165322  0.20409899 0.01424314 0.01212077]\n",
      "[0.04726258 0.01107534 0.10961383 0.00860819 0.0484595 ]\n",
      "[0.01439967 0.00235258 0.03409634 0.01057854 0.07971908]\n",
      "[0.0389788  0.00275687 0.03839795 0.00451349 0.07645142]\n",
      "[0.09918438 0.00731757 0.09500604 0.01483625 0.02751227]\n",
      "[0.12481904 0.00488181 0.03517613 0.00420525 0.03864993]\n",
      "[0.00502888 0.03917644 0.00474463 0.0025639  0.02818777]\n",
      "[0.14632863 0.00618208 0.10613644 0.01586474 0.00865848]\n",
      "[0.08468207 0.00421906 0.06709903 0.00728616 0.05017651]\n",
      "[0.07002304 0.03028903 0.05550965 0.0045269  0.01269966]\n",
      "[0.09222454 0.00917545 0.05703494 0.03379903 0.00543679]\n",
      "[0.04291328 0.00561335 0.11524254 0.01482974 0.05201441]\n",
      "[0.08373051 0.01214522 0.11348119 0.02138005 0.01557746]\n",
      "[0.00562575 0.04953678 0.00571537 0.00074044 0.01128412]\n",
      "[0.01813402 0.01364725 0.04357953 0.05317962 0.00356046]\n",
      "[0.05817182 0.0072542  0.15848589 0.03916273 0.00969842]\n",
      "[0.15594165 0.00442331 0.05549624 0.00547052 0.02414396]\n",
      "[0.15810008 0.00549024 0.0846828  0.01479413 0.00784253]\n",
      "[0.16662672 0.00536749 0.0784361  0.0068521  0.01499036]\n",
      "[0.01713379 0.01026761 0.01036779 0.03207177 0.03865343]\n",
      "[0.10275529 0.00466403 0.07600052 0.0178759  0.02826109]\n",
      "[0.0706427  0.0129409  0.08903216 0.03278855 0.00655997]\n",
      "[0.01530683 0.00182399 0.02198743 0.02978768 0.05694345]\n",
      "[0.03446004 0.00446967 0.09087867 0.05107254 0.01348872]\n",
      "[0.09472125 0.02341914 0.10780431 0.00801577 0.00772341]\n",
      "[0.08428466 0.00593519 0.11658094 0.03598566 0.00815458]\n",
      "[0.10098065 0.0048421  0.08320447 0.03488301 0.00685929]\n",
      "[0.10716215 0.01579134 0.15226569 0.01105215 0.01010377]\n",
      "[0.05452072 0.03226596 0.11351495 0.0081361  0.00725176]\n",
      "[0.06083131 0.01653084 0.06678788 0.03279104 0.00531367]\n",
      "[0.05188443 0.00210603 0.01775247 0.00325506 0.07529115]\n",
      "[0.1674218  0.00697476 0.10065348 0.0081673  0.00873107]\n",
      "[0.07637277 0.00748715 0.15965349 0.03266321 0.01004434]\n",
      "[0.03460408 0.00635968 0.09119712 0.04593624 0.01641265]\n",
      "[0.03881011 0.00743251 0.10309373 0.05013346 0.00676927]\n",
      "[0.05153138 0.00200895 0.01924753 0.03718263 0.03292683]\n",
      "[0.13217132 0.00800983 0.1581855  0.01344969 0.01086852]\n",
      "[0.14297181 0.00774449 0.14823992 0.0110936  0.01057577]\n",
      "[0.01852838 0.00148448 0.01028205 0.01419963 0.07655157]\n",
      "[0.07669814 0.02664102 0.11768981 0.0085128  0.00786569]\n",
      "[0.09777873 0.03091607 0.02979023 0.00290118 0.00400997]\n",
      "[0.06826337 0.01806908 0.14381983 0.02144762 0.00905417]\n",
      "[0.06930341 0.0086552  0.19038707 0.01369423 0.03269171]\n",
      "[0.04227348 0.01046768 0.11292593 0.03109811 0.02313767]\n",
      "[0.01010954 0.00162972 0.02148431 0.05915431 0.02255169]\n",
      "[0.09585952 0.00784191 0.1621019  0.01196421 0.02739864]\n",
      "[0.05487065 0.00700499 0.14931375 0.0114812  0.04679128]\n",
      "[0.10579778 0.01430604 0.16212368 0.01280115 0.01056294]\n",
      "[0.1238391  0.01653921 0.10772736 0.00826012 0.00826169]\n",
      "[0.11278424 0.01136818 0.11908586 0.01843041 0.00867456]\n",
      "[0.1328921  0.00565581 0.09593512 0.02198039 0.00796591]\n",
      "[0.02745696 0.01781955 0.01110992 0.00226062 0.05811014]\n",
      "[0.13379132 0.00824942 0.16405858 0.01205735 0.01116938]\n",
      "[0.00476139 0.00125778 0.00667985 0.00757006 0.09104241]\n",
      "[0.11799745 0.01193757 0.1645141  0.01195208 0.01089741]\n",
      "[0.18144013 0.00562873 0.08195614 0.00705531 0.00808838]\n",
      "[0.08269872 0.01016318 0.22846704 0.02075405 0.01336696]\n",
      "[0.09963236 0.01499769 0.11575523 0.0088234  0.019607  ]\n",
      "[0.1288868  0.00842796 0.17004744 0.01242317 0.01199037]\n",
      "[0.05920436 0.02468715 0.11136025 0.00820018 0.01924103]\n",
      "[0.04192915 0.00567201 0.10579979 0.05140367 0.00696591]\n",
      "[0.07493695 0.00620008 0.10830833 0.0087015  0.04618696]\n",
      "[0.02052992 0.00149815 0.01114117 0.02236786 0.06541523]\n",
      "[0.11349619 0.00920182 0.14841501 0.01879147 0.01009371]\n",
      "[0.16660417 0.0053746  0.07931079 0.01259212 0.00772713]\n",
      "[0.09601062 0.00409337 0.06362153 0.02902708 0.01877073]\n"
     ]
    }
   ],
   "source": [
    "final_pred = []\n",
    "\n",
    "model_NN = np.array([[0.66, 0.62, 0.62, 947],\n",
    "            [0.83, 0.90, 0.88, 1017],\n",
    "            [0.60, 0.49, 0.55, 988],\n",
    "            [0.84, 0.90, 0.87, 1034],\n",
    "            [0.79, 0.89, 0.85, 976],\n",
    "           ])\n",
    "model_SVM = np.array([[0.73, 0.57, 0.63, 947],\n",
    "             [0.85, 0.93, 0.89, 1017],\n",
    "             [0.66, 0.56, 0.61, 988],\n",
    "             [0.81, 0.89, 0.83, 1034],\n",
    "             [0.87, 0.92, 0.88, 976],\n",
    "            ])\n",
    "\n",
    "total_unidentified = 0\n",
    "proportion = []\n",
    "for i in range(5):\n",
    "    proportion.append(model_NN[i][3] - accuracy[i]*dict_count[i + 1])\n",
    "    total_unidentified += model_NN[i][3] - accuracy[i]*dict_count[i + 1]\n",
    "proportion = np.array(proportion/total_unidentified)  \n",
    "\n",
    "total_count = 0\n",
    "count = 0\n",
    "count_class = 0\n",
    "\n",
    "\n",
    "### compute the confusion matrix from the validation dataset\n",
    "from sklearn.preprocessing import normalize\n",
    "confusion_validation_SVM = confusion_matrix(Y_validation, pred_label_SVM)\n",
    "normed_matrix_SVM = normalize(confusion_validation_SVM, axis=1, norm='l1')\n",
    "confusion_validation_DNN = confusion_matrix(Y_validation, ensembel_trial_pred)\n",
    "normed_matrix_DNN = normalize(confusion_validation_DNN, axis=1, norm='l1')\n",
    "\n",
    "    \n",
    "for i in range(len(ensembel_test_pred)):\n",
    "    if ensembel_test_pred[i] == pred_label_test_SVM[i]:\n",
    "        final_pred.append(ensembel_test_pred[i])\n",
    "        if ensembel_test_pred[i] == 2:\n",
    "            count_class += 1\n",
    "    else:\n",
    "        total_count += 1\n",
    "        \n",
    "        #label_ensemble = int(ensembel_test_pred[i]-1)\n",
    "        #p1 = (model_NN[label_ensemble][3] - accuracy[label_ensemble]*dict_count[label_ensemble + 1]) /total_unidentified * model_NN[label_ensemble][1]*ensembel_prob[i]\n",
    "        \n",
    "        #label_SVM = int(pred_label_test_SVM[i]-1)\n",
    "        #p2 = (model_SVM[label_SVM][3] - accuracy[label_SVM]*dict_count[label_SVM + 1]) /total_unidentified * model_SVM[label_SVM][1]*SVM_prob[i, label_SVM]\n",
    "        \n",
    "        #if p1 > p2:\n",
    "        #    final_pred.append(label_ensemble + 1)\n",
    "        #    if label_ensemble + 1 == Y_test[i]:\n",
    "        #        count += 1\n",
    "        #else:\n",
    "        #    final_pred.append(label_SVM + 1)\n",
    "        #    if label_SVM + 1 == Y_test[i]:\n",
    "        #        count += 1\n",
    "        \n",
    "        #svm_prob_i = np.multiply(np.multiply(SVM_prob[i], model_SVM[:,0]), model_NN[:,3] - np.multiply(accuracy, count_consis))/total_unidentified\n",
    "        #dnn_prob_i = np.multiply(np.multiply(ensembel_prob_full[i], model_NN[:,0]), model_NN[:, 3] - np.multiply(accuracy, count_consis))/total_unidentified\n",
    "        #svm_prob_i = svm_prob_i/np.sum(svm_prob_i)\n",
    "        #dnn_prob_i = dnn_prob_i/np.sum(svm_prob_i)\n",
    "        \n",
    "        \n",
    "        #print (svm_prob_i)\n",
    "        #print (np.argmax(svm_prob_i))\n",
    "        #print (dnn_prob_i)\n",
    "        \n",
    "        #if np.max(svm_prob_i) > np.max(dnn_prob_i):\n",
    "        #    final_pred.append(np.argmax(svm_prob_i)+1)\n",
    "        #    if np.argmax(svm_prob_i) + 1 == Y_test[i]:\n",
    "        #        count += 1\n",
    "        #else:\n",
    "        #    final_pred.append(np.argmax(dnn_prob_i)+1)\n",
    "        #    if np.argmax(dnn_prob_i) + 1 == Y_test[i]:\n",
    "        #        count += 1\n",
    "        \n",
    "        #################  Method 3  ###################\n",
    "        #print (normed_matrix_SVM)\n",
    "        #print (SVM_prob[i])\n",
    "        #print (proportion)\n",
    "    \n",
    "        svm_prob_i = np.dot(normed_matrix_SVM, np.multiply(SVM_prob[i], proportion))\n",
    "        dnn_prob_i = np.dot(normed_matrix_DNN, np.multiply(ensembel_prob_full[i], proportion))\n",
    "        print (svm_prob_i)\n",
    "        \n",
    "        if np.max(svm_prob_i) > np.max(dnn_prob_i):\n",
    "            final_pred.append(np.argmax(svm_prob_i)+1)\n",
    "            if np.argmax(svm_prob_i) + 1 == Y_test[i]:\n",
    "                count += 1\n",
    "        else:\n",
    "            final_pred.append(np.argmax(dnn_prob_i)+1)\n",
    "            if np.argmax(dnn_prob_i) + 1 == Y_test[i]:\n",
    "                count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report on Hybrid model:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.66      0.66      0.66      1632\n",
      "          2       0.94      0.89      0.92      1877\n",
      "          3       0.62      0.70      0.65      1856\n",
      "          4       0.94      0.88      0.91      1950\n",
      "          5       0.88      0.87      0.88      1873\n",
      "\n",
      "avg / total       0.81      0.80      0.81      9188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print ('Classification report on Hybrid model:')\n",
    "print(classification_report(Y_test, final_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report on SVM:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.58      0.64      1632\n",
      "          2       0.86      0.93      0.89      1877\n",
      "          3       0.67      0.57      0.62      1856\n",
      "          4       0.79      0.91      0.85      1950\n",
      "          5       0.86      0.91      0.89      1873\n",
      "\n",
      "avg / total       0.78      0.79      0.78      9188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print ('Classification report on SVM:')\n",
    "print(classification_report(Y_test, pred_label_test_SVM, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report on deep learning:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.65      0.59      0.62      1632\n",
      "          2       0.83      0.91      0.87      1877\n",
      "          3       0.61      0.49      0.54      1856\n",
      "          4       0.83      0.90      0.86      1950\n",
      "          5       0.79      0.87      0.83      1873\n",
      "\n",
      "avg / total       0.75      0.76      0.75      9188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print ('Classification report on deep learning:')\n",
    "print(classification_report(Y_test, ensembel_test_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix of hybrid model: \n",
      " [[1011   90  402   72   57]\n",
      " [  50 1725   70   17   15]\n",
      " [ 325   67 1233  147   84]\n",
      " [  43   10  108 1757   32]\n",
      " [  44   33   92   28 1676]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print ('Confusion matrix of hybrid model: \\n', confusion_matrix(Y_test, final_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix of deep learning: \n",
      " [[ 962  129  358   75  108]\n",
      " [  42 1713   53   15   54]\n",
      " [ 395  136  911  213  201]\n",
      " [  27   23   96 1746   58]\n",
      " [  48   62   84   51 1628]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print ('Confusion matrix of deep learning: \\n', confusion_matrix(Y_test, ensembel_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix of support vector machine: \n",
      " [[ 944  130  345  127   86]\n",
      " [  35 1748   47   25   22]\n",
      " [ 283  112 1062  283  116]\n",
      " [  35   14   78 1780   43]\n",
      " [  31   40   62   32 1708]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print ('Confusion matrix of support vector machine: \\n', confusion_matrix(Y_test, pred_label_test_SVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.504428697962799"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[1073   54  425   26   54]\n",
      " [  58 1679   91    9   40]\n",
      " [ 383   30 1293   63   87]\n",
      " [  50    2  149 1712   37]\n",
      " [  69   14  143   15 1632]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x270be875b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "% matplotlib inline\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    #plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45, fontsize = 14, fontweight ='medium')\n",
    "    plt.yticks(tick_marks, classes, fontsize = 14, fontweight ='medium')\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label', fontsize=18, fontweight = 'medium')\n",
    "    plt.xlabel('Predicted label', fontsize=18, fontweight = 'medium')\n",
    "    \n",
    "    \n",
    "#plt.subplot(131)    \n",
    "plot_confusion_matrix(confusion_matrix(Y_test, final_pred), classes=target_names)\n",
    "\n",
    "plt.savefig('hybrid.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[ 962  129  358   75  108]\n",
      " [  42 1713   53   15   54]\n",
      " [ 395  136  911  213  201]\n",
      " [  27   23   96 1746   58]\n",
      " [  48   62   84   51 1628]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x270a45df0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(confusion_matrix(Y_test, ensembel_test_pred), classes=target_names)\n",
    "\n",
    "plt.savefig('dnn.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[ 944  130  345  127   86]\n",
      " [  35 1748   47   25   22]\n",
      " [ 283  112 1062  283  116]\n",
      " [  35   14   78 1780   43]\n",
      " [  31   40   62   32 1708]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x270dd2fa710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(confusion_matrix(Y_test, pred_label_test_SVM), classes=target_names)\n",
    "plt.savefig('svm.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
