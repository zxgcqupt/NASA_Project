{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load input and output variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from sklearn import datasets, metrics, cross_validation\n",
    "import mord\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import category_encoders as ce\n",
    "\n",
    "X = pd.read_pickle(\"./X_org.pkl\")\n",
    "Y = pd.read_pickle(\"./Y_org.pkl\")\n",
    "\n",
    "columns = ['Locale_Reference', 'State_Reference', 'Flight_Conditions', 'Weather_Elements_Visibility', \n",
    "                  'Work_Environment_Factor', 'Light', 'ATC_Advisory', 'Aircraft_Operator', 'Make_Model_Name', \n",
    "                  'Crew_Size', 'Flight_Plan', 'Mission', 'Flight_Phase1',\n",
    "                  'Route_In_Use','Airspace', 'Aircraft_Component', 'Manufacturer', 'Location_Of_Person', 'Location_In_Aircraft',\n",
    "                  'Reporter_Organization', 'Function', 'Qualification', 'Human_Factors', 'Anomaly', 'Detector', 'When_Detected',\n",
    "                  'Were_Passengers_Involved_In_Event', 'Contributing_Factors_Situations', 'Primary_Problem']\n",
    "\n",
    "features = X[columns]\n",
    "\n",
    "    \n",
    "encoder = ce.OrdinalEncoder(cols = columns)\n",
    "tmp = encoder.fit(features)\n",
    "\n",
    "X_org = encoder.transform(features)\n",
    "Y_org = Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building ordinal logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current fold:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\numpy\\lib\\arraysetops.py:391: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask &= (ar1 != a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error of LogisticRegression: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.43      0.48      0.46      1651\n",
      "          2       0.53      0.50      0.52      1885\n",
      "          3       0.31      0.28      0.30      1884\n",
      "          4       0.36      0.39      0.38      1884\n",
      "          5       0.37      0.38      0.37      1884\n",
      "\n",
      "avg / total       0.40      0.40      0.40      9188\n",
      "\n",
      "Mean Absolute Error of LogisticAT  \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.21      0.01      0.03      1651\n",
      "          2       0.26      0.11      0.15      1885\n",
      "          3       0.21      0.64      0.32      1884\n",
      "          4       0.31      0.41      0.35      1884\n",
      "          5       0.24      0.00      0.01      1884\n",
      "\n",
      "avg / total       0.25      0.24      0.18      9188\n",
      "\n",
      "Mean Absolute Error of LogisticIT  \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.19      0.01      0.03      1651\n",
      "          2       0.32      0.10      0.15      1885\n",
      "          3       0.21      0.57      0.30      1884\n",
      "          4       0.29      0.49      0.37      1884\n",
      "          5       0.33      0.02      0.04      1884\n",
      "\n",
      "avg / total       0.27      0.24      0.18      9188\n",
      "\n",
      "Mean Absolute Error of LogisticSE  \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.00      0.00      1651\n",
      "          2       0.25      0.16      0.19      1885\n",
      "          3       0.22      0.70      0.34      1884\n",
      "          4       0.34      0.35      0.34      1884\n",
      "          5       0.20      0.00      0.01      1884\n",
      "\n",
      "avg / total       0.30      0.25      0.18      9188\n",
      "\n",
      "current fold:  2\n",
      "Mean Absolute Error of LogisticRegression: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.45      0.48      0.46      1651\n",
      "          2       0.54      0.51      0.52      1885\n",
      "          3       0.30      0.26      0.28      1884\n",
      "          4       0.37      0.42      0.39      1884\n",
      "          5       0.39      0.38      0.39      1884\n",
      "\n",
      "avg / total       0.41      0.41      0.41      9188\n",
      "\n",
      "Mean Absolute Error of LogisticAT  \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.49      0.04      0.08      1651\n",
      "          2       0.22      0.10      0.14      1885\n",
      "          3       0.22      0.63      0.32      1884\n",
      "          4       0.32      0.43      0.37      1884\n",
      "          5       0.24      0.01      0.02      1884\n",
      "\n",
      "avg / total       0.29      0.25      0.19      9188\n",
      "\n",
      "Mean Absolute Error of LogisticIT  \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.14      0.22      1651\n",
      "          2       0.23      0.16      0.19      1885\n",
      "          3       0.22      0.54      0.31      1884\n",
      "          4       0.31      0.42      0.35      1884\n",
      "          5       0.30      0.03      0.05      1884\n",
      "\n",
      "avg / total       0.31      0.26      0.23      9188\n",
      "\n",
      "Mean Absolute Error of LogisticSE  \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      0.00      0.00      1651\n",
      "          2       0.23      0.13      0.17      1885\n",
      "          3       0.21      0.69      0.33      1884\n",
      "          4       0.33      0.33      0.33      1884\n",
      "          5       0.24      0.01      0.02      1884\n",
      "\n",
      "avg / total       0.39      0.24      0.17      9188\n",
      "\n",
      "current fold:  3\n",
      "Mean Absolute Error of LogisticRegression: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.43      0.46      0.44      1651\n",
      "          2       0.53      0.51      0.52      1885\n",
      "          3       0.30      0.25      0.27      1884\n",
      "          4       0.35      0.42      0.38      1884\n",
      "          5       0.38      0.38      0.38      1884\n",
      "\n",
      "avg / total       0.40      0.40      0.40      9188\n",
      "\n",
      "Mean Absolute Error of LogisticAT  \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.48      0.06      0.11      1651\n",
      "          2       0.20      0.10      0.13      1885\n",
      "          3       0.20      0.54      0.29      1884\n",
      "          4       0.31      0.46      0.37      1884\n",
      "          5       0.36      0.01      0.03      1884\n",
      "\n",
      "avg / total       0.30      0.24      0.19      9188\n",
      "\n",
      "Mean Absolute Error of LogisticIT  \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.46      0.06      0.10      1651\n",
      "          2       0.23      0.09      0.13      1885\n",
      "          3       0.20      0.54      0.30      1884\n",
      "          4       0.29      0.49      0.36      1884\n",
      "          5       0.43      0.02      0.03      1884\n",
      "\n",
      "avg / total       0.32      0.24      0.19      9188\n",
      "\n",
      "Mean Absolute Error of LogisticSE  \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      0.00      0.00      1651\n",
      "          2       0.25      0.14      0.18      1885\n",
      "          3       0.22      0.71      0.33      1884\n",
      "          4       0.34      0.35      0.34      1884\n",
      "          5       0.33      0.01      0.02      1884\n",
      "\n",
      "avg / total       0.41      0.25      0.18      9188\n",
      "\n",
      "current fold:  4\n",
      "Mean Absolute Error of LogisticRegression: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.44      0.47      0.46      1651\n",
      "          2       0.54      0.50      0.52      1884\n",
      "          3       0.31      0.30      0.30      1884\n",
      "          4       0.36      0.40      0.38      1884\n",
      "          5       0.39      0.37      0.38      1885\n",
      "\n",
      "avg / total       0.41      0.40      0.41      9188\n",
      "\n",
      "Mean Absolute Error of LogisticAT  \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.25      0.02      0.03      1651\n",
      "          2       0.30      0.11      0.16      1884\n",
      "          3       0.21      0.57      0.30      1884\n",
      "          4       0.30      0.49      0.37      1884\n",
      "          5       0.20      0.00      0.01      1885\n",
      "\n",
      "avg / total       0.25      0.24      0.18      9188\n",
      "\n",
      "Mean Absolute Error of LogisticIT  \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.31      0.40      0.35      1651\n",
      "          2       0.13      0.01      0.02      1884\n",
      "          3       0.21      0.10      0.14      1884\n",
      "          4       0.20      0.58      0.30      1884\n",
      "          5       0.29      0.10      0.15      1885\n",
      "\n",
      "avg / total       0.23      0.24      0.19      9188\n",
      "\n",
      "Mean Absolute Error of LogisticSE  \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.00      0.00      0.00      1651\n",
      "          2       0.25      0.15      0.18      1884\n",
      "          3       0.22      0.70      0.33      1884\n",
      "          4       0.32      0.33      0.32      1884\n",
      "          5       0.21      0.01      0.01      1885\n",
      "\n",
      "avg / total       0.20      0.24      0.17      9188\n",
      "\n",
      "current fold:  5\n",
      "Mean Absolute Error of LogisticRegression: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.43      0.46      0.45      1651\n",
      "          2       0.52      0.49      0.51      1884\n",
      "          3       0.28      0.27      0.28      1885\n",
      "          4       0.35      0.36      0.35      1884\n",
      "          5       0.39      0.39      0.39      1884\n",
      "\n",
      "avg / total       0.39      0.39      0.39      9188\n",
      "\n",
      "Mean Absolute Error of LogisticAT  \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.08      0.14      1651\n",
      "          2       0.23      0.13      0.17      1884\n",
      "          3       0.21      0.56      0.31      1885\n",
      "          4       0.31      0.46      0.37      1884\n",
      "          5       0.36      0.02      0.03      1884\n",
      "\n",
      "avg / total       0.32      0.25      0.21      9188\n",
      "\n",
      "Mean Absolute Error of LogisticIT  \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.44      0.20      0.27      1651\n",
      "          2       0.22      0.10      0.13      1884\n",
      "          3       0.21      0.44      0.28      1885\n",
      "          4       0.28      0.50      0.36      1884\n",
      "          5       0.37      0.03      0.06      1884\n",
      "\n",
      "avg / total       0.30      0.26      0.22      9188\n",
      "\n",
      "Mean Absolute Error of LogisticSE  \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.00      0.00      1651\n",
      "          2       0.22      0.14      0.17      1884\n",
      "          3       0.21      0.68      0.32      1885\n",
      "          4       0.32      0.33      0.33      1884\n",
      "          5       0.31      0.01      0.02      1884\n",
      "\n",
      "avg / total       0.31      0.24      0.17      9188\n",
      "\n",
      "current fold:  6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error of LogisticRegression: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.43      0.47      0.45      1651\n",
      "          2       0.56      0.53      0.54      1884\n",
      "          3       0.30      0.27      0.28      1885\n",
      "          4       0.35      0.40      0.37      1884\n",
      "          5       0.39      0.38      0.38      1884\n",
      "\n",
      "avg / total       0.41      0.41      0.41      9188\n",
      "\n",
      "Mean Absolute Error of LogisticAT  \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.38      0.03      0.06      1651\n",
      "          2       0.23      0.08      0.12      1884\n",
      "          3       0.21      0.62      0.32      1885\n",
      "          4       0.31      0.47      0.37      1884\n",
      "          5       0.41      0.01      0.01      1884\n",
      "\n",
      "avg / total       0.31      0.25      0.18      9188\n",
      "\n",
      "Mean Absolute Error of LogisticIT  \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.37      0.16      0.22      1651\n",
      "          2       0.19      0.06      0.09      1884\n",
      "          3       0.21      0.38      0.27      1885\n",
      "          4       0.26      0.59      0.36      1884\n",
      "          5       0.34      0.02      0.04      1884\n",
      "\n",
      "avg / total       0.27      0.25      0.20      9188\n",
      "\n",
      "Mean Absolute Error of LogisticSE  \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.00      0.00      0.00      1651\n",
      "          2       0.25      0.14      0.18      1884\n",
      "          3       0.22      0.72      0.34      1885\n",
      "          4       0.34      0.34      0.34      1884\n",
      "          5       0.42      0.01      0.02      1884\n",
      "\n",
      "avg / total       0.25      0.25      0.18      9188\n",
      "\n",
      "current fold:  7\n",
      "Mean Absolute Error of LogisticRegression: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.45      0.49      0.47      1651\n",
      "          2       0.54      0.52      0.53      1884\n",
      "          3       0.30      0.27      0.28      1884\n",
      "          4       0.38      0.43      0.40      1885\n",
      "          5       0.40      0.39      0.40      1884\n",
      "\n",
      "avg / total       0.41      0.42      0.41      9188\n",
      "\n",
      "Mean Absolute Error of LogisticAT  \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.45      0.05      0.10      1651\n",
      "          2       0.20      0.09      0.12      1884\n",
      "          3       0.21      0.56      0.30      1884\n",
      "          4       0.31      0.49      0.38      1885\n",
      "          5       0.40      0.01      0.02      1884\n",
      "\n",
      "avg / total       0.31      0.24      0.19      9188\n",
      "\n",
      "Mean Absolute Error of LogisticIT  \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.33      0.29      0.31      1651\n",
      "          2       0.17      0.01      0.02      1884\n",
      "          3       0.22      0.14      0.17      1884\n",
      "          4       0.20      0.63      0.30      1885\n",
      "          5       0.30      0.07      0.12      1884\n",
      "\n",
      "avg / total       0.24      0.23      0.18      9188\n",
      "\n",
      "Mean Absolute Error of LogisticSE  \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.00      0.00      1651\n",
      "          2       0.21      0.12      0.15      1884\n",
      "          3       0.21      0.68      0.32      1884\n",
      "          4       0.34      0.36      0.35      1885\n",
      "          5       0.44      0.01      0.03      1884\n",
      "\n",
      "avg / total       0.34      0.24      0.18      9188\n",
      "\n",
      "current fold:  8\n",
      "Mean Absolute Error of LogisticRegression: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.44      0.47      0.46      1651\n",
      "          2       0.54      0.49      0.52      1884\n",
      "          3       0.30      0.27      0.29      1884\n",
      "          4       0.35      0.41      0.38      1884\n",
      "          5       0.39      0.37      0.38      1885\n",
      "\n",
      "avg / total       0.40      0.40      0.40      9188\n",
      "\n",
      "Mean Absolute Error of LogisticAT  \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.09      0.15      1651\n",
      "          2       0.21      0.13      0.16      1884\n",
      "          3       0.21      0.55      0.31      1884\n",
      "          4       0.29      0.43      0.34      1884\n",
      "          5       0.33      0.01      0.03      1885\n",
      "\n",
      "avg / total       0.31      0.25      0.20      9188\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error of LogisticIT  \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.40      0.35      0.38      1651\n",
      "          2       0.23      0.40      0.29      1884\n",
      "          3       0.00      0.00      0.00      1884\n",
      "          4       0.22      0.38      0.28      1884\n",
      "          5       0.24      0.16      0.19      1885\n",
      "\n",
      "avg / total       0.22      0.26      0.23      9188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn import linear_model, metrics, preprocessing\n",
    "import mord\n",
    "\n",
    "test_random_state = 112\n",
    "cv = StratifiedShuffleSplit(n_splits = 10, test_size = 0.1, random_state = test_random_state)\n",
    "\n",
    "target_names = [str(i) for i in range(1, 6)]\n",
    "\n",
    "for k, (data_index, test_index) in enumerate(cv.split(X_org, Y_org)):\n",
    "    print ('current fold: ', k+1)\n",
    "      \n",
    "    ### Split the data into three parts: \n",
    "    ### X_train, Y_train: train the data\n",
    "    ### X_validation, Y_validation: trial data to obtain the performance metrics\n",
    "    ### X_test, Y_test: test data used to compare the performance of hybrid model with SVM and DNN\n",
    "    X = X_org.iloc[data_index]\n",
    "    Y = Y_org.iloc[data_index]\n",
    "      \n",
    "    X_test = X_org.iloc[test_index]\n",
    "    Y_test = Y_org.iloc[test_index]\n",
    "    \n",
    "    clf1 = linear_model.LogisticRegression(solver='lbfgs', multi_class='multinomial')\n",
    "    clf1.fit(X, Y)\n",
    "    \n",
    "    print('Mean Absolute Error of LogisticRegression: \\n',\n",
    "      metrics.classification_report(Y_test, clf1.predict(X_test), target_names))\n",
    "    \n",
    "    clf2 = mord.LogisticAT(alpha=1.)\n",
    "    clf2.fit(X, Y)\n",
    "    print('Mean Absolute Error of LogisticAT  \\n',\n",
    "          metrics.classification_report(Y_test, clf2.predict(X_test), target_names))\n",
    "\n",
    "    clf3 = mord.LogisticIT(alpha=1.)\n",
    "    clf3.fit(X, Y)\n",
    "    print('Mean Absolute Error of LogisticIT  \\n',\n",
    "          metrics.classification_report(Y_test, clf3.predict(X_test), target_names))\n",
    "\n",
    "    clf4 = mord.LogisticSE(alpha=1.)\n",
    "    clf4.fit(X, Y)\n",
    "    print('Mean Absolute Error of LogisticSE  \\n',\n",
    "          metrics.classification_report(Y_test, clf4.predict(X_test), target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the performance of all four algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
