{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The version of TensorFlow is 1.4.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from os import listdir\n",
    "from sklearn.model_selection import train_test_split\n",
    "print ('The version of TensorFlow is {}'.format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = './data'\n",
    "\n",
    "appended_data = []\n",
    "for file_name in listdir(root_path):\n",
    "    file_path = root_path + '/' + file_name.encode().decode('utf-8')\n",
    "    data_from_one_csv = pd.read_csv(file_path, skiprows=1)\n",
    "    appended_data.append(data_from_one_csv)\n",
    "    \n",
    "data = pd.concat(appended_data, axis=0)\n",
    "data = data.drop(columns = ['ACN', 'Date', 'Local Time Of Day', 'Ceiling', 'Callback', 'Callback.1', 'Unnamed: 96'])\n",
    "data = data.rename(index=str, columns={\"Flight Phase\": \"Flight Phase1\"})\n",
    "\n",
    "## drop the rows with empty synopsis description\n",
    "data = data[pd.notnull(data['Synopsis'])]\n",
    "\n",
    "X = data.drop(columns = 'Result')\n",
    "Y_raw = pd.DataFrame(data['Result'])\n",
    "\n",
    "processed_Y = []\n",
    "for index, row in Y_raw.iterrows():\n",
    "    #print (index, row['Result'])\n",
    "    outcome = row['Result']\n",
    "    if type(outcome) == np.float:\n",
    "        res = 'unknown'\n",
    "        processed_Y.append(res)\n",
    "    elif ';' in outcome:\n",
    "        res = str(outcome).split(';')[0]\n",
    "        processed_Y.append(res)\n",
    "    else:\n",
    "        res = outcome\n",
    "        processed_Y.append(res)\n",
    "\n",
    "Y = pd.DataFrame(processed_Y, columns = ['Result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compress the number of labels to be predicted --> map result to risk level\n",
    "rate_nine = ['General Declared Emergency', 'General Physical Injury / Incapacitation', 'Flight Crew Inflight Shutdown', \n",
    "             'Air Traffic Control Separated Traffic', 'Aircraft Aircraft Damaged']\n",
    "\n",
    "rate_seven = ['General Evacuated', 'Flight Crew Landed as Precaution', 'Flight Crew Regained Aircraft Control', \n",
    "              'Air Traffic Control Issued Advisory / Alert', 'Flight Crew Landed in Emergency Condition',\n",
    "              'Flight Crew Landed In Emergency Condition']\n",
    "\n",
    "rate_five = ['General Work Refused', 'Flight Crew Became Reoriented', 'Flight Crew Diverted', \n",
    "             'Flight Crew Executed Go Around / Missed Approach', \n",
    "             'Flight Crew Overcame Equipment Problem', 'Flight Crew Rejected Takeoff', 'Flight Crew Took Evasive Action', \n",
    "             'Air Traffic Control Issued New Clearance']\n",
    "\n",
    "rate_three = ['General Maintenance Action', 'General Flight Cancelled / Delayed', 'General Release Refused / Aircraft Not Accepted', \n",
    "              'Flight Crew Overrode Automation', 'Flight Crew FLC Overrode Automation',\n",
    "              'Flight Crew Exited Penetrated Airspace', \n",
    "              'Flight Crew Requested ATC Assistance / Clarification', 'Flight Crew Landed As Precaution',\n",
    "              'Flight Crew Returned To Clearance', 'Flight Crew Returned To Departure Airport',\n",
    "              'Aircraft Automation Overrode Flight Crew']\n",
    "\n",
    "rate_one = ['General Police / Security Involved', 'Flight Crew Returned To Gate', 'Aircraft Equipment Problem Dissipated', \n",
    "            'unknown', 'Air Traffic Control Provided Assistance',\n",
    "            'General None Reported / Taken', 'Flight Crew FLC complied w / Automation / Advisory']\n",
    "\n",
    "Y_ = []\n",
    "for i in range(Y.shape[0]):\n",
    "    if Y['Result'][i] in rate_nine:\n",
    "        Y_.append(5)\n",
    "    elif Y['Result'][i] in rate_seven:\n",
    "        Y_.append(4)\n",
    "    elif Y['Result'][i] in rate_five:\n",
    "        Y_.append(3)\n",
    "    elif Y['Result'][i] in rate_three:\n",
    "        Y_.append(2)\n",
    "    elif Y['Result'][i] in rate_one:\n",
    "        Y_.append(1)\n",
    "    else:\n",
    "        print (Y['Result'][i])\n",
    "\n",
    "outcomes = np.asarray(Y_)\n",
    "Y_pred = pd.DataFrame(Y_, index = X.index, columns = ['Result'])\n",
    "unique, counts = np.unique(outcomes, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rev = X.copy(deep=True)\n",
    "data_rev['Result'] = Y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upsampling the minority categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After the upsampling, the number of each item is: \n",
      "\n",
      "[1 2 3 4 5]\n",
      "[20985 20000 20848 20000 20000]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "df_majority_1 = data_rev[data_rev['Result']==1]\n",
    "df_majority_3 = data_rev[data_rev['Result']==3]\n",
    "df_minority_2 = data_rev[data_rev['Result']==2]\n",
    "df_minority_4 = data_rev[data_rev['Result']==4]\n",
    "df_minority_5 = data_rev[data_rev['Result']==5]\n",
    "\n",
    "# Upsample minority class\n",
    "df_minority_2_upsampled = resample(df_minority_2, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=20000,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    "df_minority_4_upsampled = resample(df_minority_4, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=20000,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    "df_minority_5_upsampled = resample(df_minority_5, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=20000,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    "\n",
    "df_upsampled = pd.concat([df_majority_1, df_majority_3, df_minority_2_upsampled, df_minority_4_upsampled, \n",
    "                          df_minority_5_upsampled])\n",
    "\n",
    "df_upsampled['Result'].value_counts()\n",
    "\n",
    "X = df_upsampled.drop(columns = 'Result')\n",
    "Y_pred = df_upsampled['Result']\n",
    "\n",
    "unique, counts = np.unique(Y_pred, return_counts=True)\n",
    "print ('After the upsampling, the number of each item is: \\n')\n",
    "print (unique)\n",
    "print (counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2601    3\n",
       "740     1\n",
       "378     4\n",
       "372     3\n",
       "1923    4\n",
       "Name: Result, dtype: int64"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_size_ratio = 0.2\n",
    "random_split_seed = 100\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X['Synopsis'], Y_pred, test_size = test_size_ratio, \n",
    "                                                    random_state = random_split_seed)\n",
    "Y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline: Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.46      0.49      4206\n",
      "          2       0.55      0.63      0.59      3937\n",
      "          3       0.46      0.40      0.43      4174\n",
      "          4       0.53      0.56      0.54      4032\n",
      "          5       0.63      0.70      0.66      4018\n",
      "\n",
      "avg / total       0.54      0.55      0.54     20367\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', MultinomialNB(alpha = 1, fit_prior=True)),\n",
    "                    ])\n",
    "\n",
    "text_clf.fit(X_train, Y_train)\n",
    "pred_label = text_clf.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "target_names = [str(i) for i in range(1, 5+1)]\n",
    "print(classification_report(Y_test, pred_label, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Support Vector Machine with Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.50      0.58      4206\n",
      "          2       0.80      0.91      0.85      3937\n",
      "          3       0.63      0.55      0.59      4174\n",
      "          4       0.78      0.91      0.84      4032\n",
      "          5       0.88      0.98      0.93      4018\n",
      "\n",
      "avg / total       0.75      0.77      0.75     20367\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words = 'english')),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', SGDClassifier(loss='epsilon_insensitive', penalty='l2',\n",
    "                                            alpha=1e-5, random_state=40,\n",
    "                                            max_iter=10, tol=None)),\n",
    "                    ])\n",
    "\n",
    "\n",
    "parameters = {'clf__loss': ['epsilon_insensitive', 'hinge', 'log', 'huber', 'modified_huber', 'perceptron', \n",
    "                            'squared_loss', 'squared_epsilon_insensitive', 'squared_hinge'],\n",
    "              'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'clf__alpha': (1e-2, 1e-3, 1e-4, 1e-5),\n",
    "              'clf__penalty': ['l1', 'l2', 'elasticnet'],\n",
    "              'clf__max_iter': (10, 20, 30, 40, 50, 60, 70, 80, 90, 100)\n",
    " }\n",
    "\n",
    "optimal_parameters = {'clf__loss': ['modified_huber'],\n",
    "              'vect__ngram_range':  [(1, 2)],\n",
    "              'tfidf__use_idf': [True],\n",
    "              'clf__alpha': [1e-5],\n",
    "              'clf__penalty': ['elasticnet'],\n",
    "              'clf__max_iter': [80],\n",
    " }\n",
    "\n",
    "gs_clf = GridSearchCV(text_clf, optimal_parameters, n_jobs=-1)\n",
    "\n",
    "gs_clf.fit(X_train, Y_train)\n",
    "pred_label = gs_clf.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "target_names = [str(i) for i in range(1, 6)]\n",
    "print(classification_report(Y_test, pred_label, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.765503019590514\n",
      "The best set of parameters is \n",
      " {'clf__alpha': 1e-05, 'clf__loss': 'modified_huber', 'clf__max_iter': 80, 'clf__penalty': 'elasticnet', 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "print ('Accuracy: ', np.sum(np.equal(Y_test, pred_label).astype(int))/20367)\n",
    "print ('The best set of parameters is \\n', gs_clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Processing other categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "The unique data types across all the items are: {<class 'numpy.float64'>, <class 'str'>}\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     2.0\n",
       "8     2.0\n",
       "13    2.0\n",
       "14    2.0\n",
       "15    2.0\n",
       "Name: Crew_Size, dtype: float64"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## change column names\n",
    "new_col_name = []\n",
    "for col in X.columns:\n",
    "    #print(type(col))\n",
    "    new_col_name.append(col.replace('/ ', '').replace(' ', '_'))\n",
    "    \n",
    "X.columns = new_col_name\n",
    "\n",
    "## output the headers from the csv file\n",
    "X.keys()\n",
    "\n",
    "data_type = []\n",
    "for item_name in X.keys():\n",
    "    data_type.append(type(X[item_name][0]))\n",
    "\n",
    "print ('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "print ('The unique data types across all the items are:', set(data_type))\n",
    "print ('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "\n",
    "for item_name in X.keys():\n",
    "    ## find the number of NaN in this item\n",
    "    no = np.sum(X[item_name].isna().astype(int))\n",
    "    #print ('The number of {} with value equal to NaN is {}'.format(item_name, no))\n",
    "    \n",
    "    ## Replace the missing value with corresponding values\n",
    "    if no > 0:\n",
    "        if type(X[item_name][0]) == np.float64:\n",
    "            X[item_name].fillna(-1, inplace = True)\n",
    "        else:\n",
    "            X[item_name].fillna('unknown', inplace = True)\n",
    "X['Crew_Size'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Location\n",
    "Locale_Reference = tf.feature_column.categorical_column_with_hash_bucket('Locale_Reference', \n",
    "                                                                         hash_bucket_size = len(set(X['Locale_Reference'])))\n",
    "State_Reference = tf.feature_column.categorical_column_with_hash_bucket('State_Reference', \n",
    "                                                                        hash_bucket_size = len(set(X['State_Reference'])))\n",
    "\n",
    "\n",
    "## Environment\n",
    "Flight_Conditions = tf.feature_column.categorical_column_with_hash_bucket('Flight_Conditions', \n",
    "                                                                hash_bucket_size = len(set(X['State_Reference'])))\n",
    "Weather_Elements_Visibility = tf.feature_column.categorical_column_with_hash_bucket('Weather_Elements_Visibility', \n",
    "                                                            hash_bucket_size = len(set(X['Weather_Elements_Visibility'])))\n",
    "Work_Environment_Factor = tf.feature_column.categorical_column_with_hash_bucket('Work_Environment_Factor', \n",
    "                                                            hash_bucket_size = len(set(X['Work_Environment_Factor'])))\n",
    "Light = tf.feature_column.categorical_column_with_hash_bucket('Light', hash_bucket_size = \n",
    "                                                              len(set(X['Work_Environment_Factor'])))\n",
    "\n",
    "\n",
    "## Aircraft\n",
    "ATC_Advisory = tf.feature_column.categorical_column_with_hash_bucket('ATC_Advisory', \n",
    "                                                            hash_bucket_size = len(set(X['ATC_Advisory'])))\n",
    "Aircraft_Operator = tf.feature_column.categorical_column_with_hash_bucket('Aircraft_Operator', \n",
    "                                                                hash_bucket_size = len(set(X['Aircraft_Operator'])))\n",
    "Make_Model_Name = tf.feature_column.categorical_column_with_hash_bucket('Make_Model_Name', \n",
    "                                                            hash_bucket_size = len(set(X['Make_Model_Name'])))\n",
    "Crew_Size = tf.feature_column.numeric_column('Crew_Size', [1])\n",
    "Flight_Plan = tf.feature_column.categorical_column_with_hash_bucket('Flight_Plan', \n",
    "                                                            hash_bucket_size = len(set(X['Flight_Plan'])))\n",
    "Mission = tf.feature_column.categorical_column_with_hash_bucket('Mission', \n",
    "                                                                hash_bucket_size = len(set(X['Mission'])))\n",
    "Flight_Phase1 = tf.feature_column.categorical_column_with_hash_bucket('Flight_Phase1', \n",
    "                                                                      hash_bucket_size = len(set(X['Flight_Phase1'])))\n",
    "Route_In_Use = tf.feature_column.categorical_column_with_hash_bucket('Route_In_Use', \n",
    "                                                                     hash_bucket_size = len(set(X['Route_In_Use'])))\n",
    "Airspace = tf.feature_column.categorical_column_with_hash_bucket('Airspace', \n",
    "                                                                 hash_bucket_size = len(set(X['Airspace'])))\n",
    "\n",
    "## Component\n",
    "Aircraft_Component = tf.feature_column.categorical_column_with_hash_bucket('Aircraft_Component', \n",
    "                                                             hash_bucket_size = len(set(X['Aircraft_Component'])))\n",
    "Manufacturer = tf.feature_column.categorical_column_with_hash_bucket('Manufacturer', \n",
    "                                                        hash_bucket_size = len(set(X['Manufacturer'])))\n",
    "\n",
    "## Person\n",
    "Location_Of_Person = tf.feature_column.categorical_column_with_hash_bucket('Location_Of_Person', \n",
    "                                                                hash_bucket_size = len(set(X['Location_Of_Person'])))\n",
    "Location_In_Aircraft = tf.feature_column.categorical_column_with_hash_bucket('Location_In_Aircraft',\n",
    "                                                            hash_bucket_size = len(set(X['Location_In_Aircraft'])))\n",
    "Reporter_Organization = tf.feature_column.categorical_column_with_hash_bucket('Reporter_Organization',\n",
    "                                                            hash_bucket_size = len(set(X['Reporter_Organization'])))\n",
    "Function = tf.feature_column.categorical_column_with_hash_bucket('Function', hash_bucket_size = len(set(X['Function'])))\n",
    "Qualification = tf.feature_column.categorical_column_with_hash_bucket('Qualification', \n",
    "                                                                      hash_bucket_size = len(set(X['Qualification'])))\n",
    "Human_Factors = tf.feature_column.categorical_column_with_hash_bucket('Human_Factors', \n",
    "                                                                      hash_bucket_size = len(set(X['Human_Factors'])))\n",
    "\n",
    "## Events\n",
    "Anomaly = tf.feature_column.categorical_column_with_hash_bucket('Anomaly', \n",
    "                                                                hash_bucket_size = len(set(X['Anomaly'])))\n",
    "Detector = tf.feature_column.categorical_column_with_hash_bucket('Detector', \n",
    "                                                                 hash_bucket_size = len(set(X['Detector'])))\n",
    "When_Detected = tf.feature_column.categorical_column_with_hash_bucket('When_Detected', \n",
    "                                                                      hash_bucket_size = len(set(X['When_Detected'])))\n",
    "Were_Passengers_Involved_In_Event = tf.feature_column.categorical_column_with_hash_bucket('Were_Passengers_Involved_In_Event',\n",
    "                                                    hash_bucket_size = len(set(X['Were_Passengers_Involved_In_Event'])))\n",
    "\n",
    "## Assessments\n",
    "Contributing_Factors_Situations = tf.feature_column.categorical_column_with_hash_bucket('Contributing_Factors_Situations', \n",
    "                                                   hash_bucket_size = len(set(X['Contributing_Factors_Situations'])))\n",
    "Primary_Problem = tf.feature_column.categorical_column_with_hash_bucket('Primary_Problem', \n",
    "                                                        hash_bucket_size = len(set(X['Primary_Problem'])))\n",
    "\n",
    "## Place\n",
    "Locale_Reference = tf.feature_column.embedding_column(Locale_Reference, len(set(X['Locale_Reference'])))\n",
    "State_Reference = tf.feature_column.embedding_column(State_Reference, len(set(X['State_Reference'])))\n",
    "\n",
    "\n",
    "## Environment\n",
    "Flight_Conditions = tf.feature_column.embedding_column(Flight_Conditions,  len(set(X['Flight_Conditions'])))\n",
    "Weather_Elements_Visibility = tf.feature_column.embedding_column(Weather_Elements_Visibility,  \n",
    "                                                                 len(set(X['Weather_Elements_Visibility'])))\n",
    "Work_Environment_Factor = tf.feature_column.embedding_column(Work_Environment_Factor,  len(set(X['Work_Environment_Factor'])))\n",
    "Light = tf.feature_column.embedding_column(Light, len(set(X['Light'])))\n",
    "\n",
    "\n",
    "## Aircraft\n",
    "ATC_Advisory = tf.feature_column.embedding_column(ATC_Advisory, len(set(X['ATC_Advisory'])))\n",
    "Aircraft_Operator = tf.feature_column.embedding_column(Aircraft_Operator, len(set(X['Aircraft_Operator'])))\n",
    "Make_Model_Name = tf.feature_column.embedding_column(Make_Model_Name, len(set(X['Make_Model_Name'])))\n",
    "Flight_Plan = tf.feature_column.embedding_column(Flight_Plan, len(set(X['Flight_Plan'])))\n",
    "Mission = tf.feature_column.embedding_column(Mission, len(set(X['Mission'])))\n",
    "Flight_Phase1 = tf.feature_column.embedding_column(Flight_Phase1, len(set(X['Flight_Phase1'])))\n",
    "Route_In_Use = tf.feature_column.embedding_column(Route_In_Use, len(set(X['Route_In_Use'])))\n",
    "Airspace = tf.feature_column.embedding_column(Airspace, len(set(X['Airspace'])))\n",
    "\n",
    "## Component\n",
    "Aircraft_Component = tf.feature_column.embedding_column(Aircraft_Component, len(set(X['Aircraft_Component'])))\n",
    "Manufacturer = tf.feature_column.embedding_column(Manufacturer, len(set(X['Manufacturer'])))\n",
    "\n",
    "## Person\n",
    "Location_Of_Person = tf.feature_column.embedding_column(Location_Of_Person, len(set(X['Location_Of_Person'])))\n",
    "Location_In_Aircraft = tf.feature_column.embedding_column(Location_In_Aircraft, len(set(X['Location_In_Aircraft'])))\n",
    "Reporter_Organization = tf.feature_column.embedding_column(Reporter_Organization, len(set(X['Reporter_Organization'])))\n",
    "Function = tf.feature_column.embedding_column(Function, len(set(X['Function'])))\n",
    "Qualification = tf.feature_column.embedding_column(Qualification, len(set(X['Qualification'])))\n",
    "Human_Factors = tf.feature_column.embedding_column(Human_Factors, len(set(X['Human_Factors'])))\n",
    "\n",
    "## Events\n",
    "Anomaly = tf.feature_column.embedding_column(Anomaly, len(set(X['Anomaly'])))\n",
    "Detector = tf.feature_column.embedding_column(Detector, len(set(X['Detector'])))\n",
    "When_Detected = tf.feature_column.embedding_column(When_Detected, len(set(X['When_Detected'])))\n",
    "Were_Passengers_Involved_In_Event = tf.feature_column.embedding_column(Were_Passengers_Involved_In_Event,\n",
    "                                                                       len(set(X['Were_Passengers_Involved_In_Event'])))\n",
    "\n",
    "## Assessments\n",
    "Contributing_Factors_Situations = tf.feature_column.embedding_column(Contributing_Factors_Situations,\n",
    "                                                                     len(set(X['Contributing_Factors_Situations'])))\n",
    "Primary_Problem = tf.feature_column.embedding_column(Primary_Problem, len(set(X['Primary_Problem'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_sub = X[['Locale_Reference', 'State_Reference', 'Flight_Conditions', 'Weather_Elements_Visibility', \n",
    "            'Work_Environment_Factor', 'Light', 'ATC_Advisory', 'Aircraft_Operator', 'Make_Model_Name', \n",
    "            'Crew_Size', 'Flight_Plan', 'Mission', 'Flight_Phase1',\n",
    "            'Route_In_Use','Airspace', 'Aircraft_Component', 'Manufacturer', 'Location_Of_Person', 'Location_In_Aircraft',\n",
    "            'Reporter_Organization', 'Function', 'Qualification', 'Human_Factors', 'Anomaly', 'Detector', 'When_Detected',\n",
    "            'Were_Passengers_Involved_In_Event', 'Contributing_Factors_Situations', 'Primary_Problem']]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_sub, Y_pred, test_size = test_size_ratio, \n",
    "                                                    random_state = random_split_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train the 1 model, please keep waiting !!!\n",
      "\n",
      "\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpustpcu7m\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\ZHANGX~1\\\\AppData\\\\Local\\\\Temp\\\\tmpustpcu7m', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000218C6698C18>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpustpcu7m\\model.ckpt.\n",
      "INFO:tensorflow:loss = 895.7074, step = 1\n",
      "INFO:tensorflow:global_step/sec: 0.647053\n",
      "INFO:tensorflow:loss = 631.00024, step = 101 (154.589 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.651062\n",
      "INFO:tensorflow:loss = 496.24252, step = 201 (153.588 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.65776\n",
      "INFO:tensorflow:loss = 452.97748, step = 301 (152.053 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 382 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpustpcu7m\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.583029\n",
      "INFO:tensorflow:loss = 374.50256, step = 401 (171.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.656519\n",
      "INFO:tensorflow:loss = 357.51758, step = 501 (152.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.650982\n",
      "INFO:tensorflow:loss = 318.4682, step = 601 (153.669 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659147\n",
      "INFO:tensorflow:loss = 248.71574, step = 701 (151.670 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 763 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpustpcu7m\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.598287\n",
      "INFO:tensorflow:loss = 250.87006, step = 801 (167.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.664538\n",
      "INFO:tensorflow:loss = 209.53206, step = 901 (150.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.647128\n",
      "INFO:tensorflow:loss = 211.86072, step = 1001 (154.526 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.649609\n",
      "INFO:tensorflow:loss = 189.30441, step = 1101 (153.924 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1146 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpustpcu7m\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.587642\n",
      "INFO:tensorflow:loss = 198.15388, step = 1201 (170.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.64158\n",
      "INFO:tensorflow:loss = 189.70425, step = 1301 (155.852 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.647973\n",
      "INFO:tensorflow:loss = 153.39925, step = 1401 (154.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.649301\n",
      "INFO:tensorflow:loss = 160.20718, step = 1501 (153.987 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1525 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpustpcu7m\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.590732\n",
      "INFO:tensorflow:loss = 157.93924, step = 1601 (169.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.651716\n",
      "INFO:tensorflow:loss = 122.0902, step = 1701 (153.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.651131\n",
      "INFO:tensorflow:loss = 106.07907, step = 1801 (153.582 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.65351\n",
      "INFO:tensorflow:loss = 141.97252, step = 1901 (153.078 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1906 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpustpcu7m\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.564698\n",
      "INFO:tensorflow:loss = 119.591, step = 2001 (177.023 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.656836\n",
      "INFO:tensorflow:loss = 99.88324, step = 2101 (152.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.647897\n",
      "INFO:tensorflow:loss = 95.39523, step = 2201 (154.335 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2281 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpustpcu7m\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.577445\n",
      "INFO:tensorflow:loss = 98.49239, step = 2301 (173.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.639289\n",
      "INFO:tensorflow:loss = 101.90852, step = 2401 (156.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.650384\n",
      "INFO:tensorflow:loss = 116.91901, step = 2501 (153.759 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.649895\n",
      "INFO:tensorflow:loss = 89.809074, step = 2601 (153.864 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2658 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpustpcu7m\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.584251\n",
      "INFO:tensorflow:loss = 96.40802, step = 2701 (171.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.651996\n",
      "INFO:tensorflow:loss = 91.59986, step = 2801 (153.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.639754\n",
      "INFO:tensorflow:loss = 91.096054, step = 2901 (156.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.663873\n",
      "INFO:tensorflow:loss = 90.8029, step = 3001 (150.649 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3039 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpustpcu7m\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.600251\n",
      "INFO:tensorflow:loss = 85.51163, step = 3101 (166.606 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659217\n",
      "INFO:tensorflow:loss = 102.65006, step = 3201 (151.687 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.652691\n",
      "INFO:tensorflow:loss = 51.853622, step = 3301 (153.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.641615\n",
      "INFO:tensorflow:loss = 60.509834, step = 3401 (155.843 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3421 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpustpcu7m\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.5838\n",
      "INFO:tensorflow:loss = 61.90535, step = 3501 (171.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.650391\n",
      "INFO:tensorflow:loss = 65.48152, step = 3601 (153.748 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.655266\n",
      "INFO:tensorflow:loss = 71.02202, step = 3701 (152.596 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3801 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpustpcu7m\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.589582\n",
      "INFO:tensorflow:loss = 63.68738, step = 3801 (169.589 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.647769\n",
      "INFO:tensorflow:loss = 60.189438, step = 3901 (154.419 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpustpcu7m\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 70.24685.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpustpcu7m\\model.ckpt-4000\n",
      "Train the 2 model, please keep waiting !!!\n",
      "\n",
      "\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpfgibw1gu\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\ZHANGX~1\\\\AppData\\\\Local\\\\Temp\\\\tmpfgibw1gu', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000218B1C52CC0>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpfgibw1gu\\model.ckpt.\n",
      "INFO:tensorflow:loss = 896.0503, step = 1\n",
      "INFO:tensorflow:global_step/sec: 0.643092\n",
      "INFO:tensorflow:loss = 613.24097, step = 101 (155.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.658505\n",
      "INFO:tensorflow:loss = 478.49506, step = 201 (151.861 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.674256\n",
      "INFO:tensorflow:loss = 372.39368, step = 301 (148.318 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 388 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpfgibw1gu\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.610969\n",
      "INFO:tensorflow:loss = 362.24133, step = 401 (163.633 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.67202\n",
      "INFO:tensorflow:loss = 333.67368, step = 501 (148.840 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.673551\n",
      "INFO:tensorflow:loss = 301.40198, step = 601 (148.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.671605\n",
      "INFO:tensorflow:loss = 251.33676, step = 701 (148.890 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 782 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpfgibw1gu\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.614315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 251.03018, step = 801 (162.749 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.671068\n",
      "INFO:tensorflow:loss = 228.25932, step = 901 (149.081 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.657448\n",
      "INFO:tensorflow:loss = 232.71298, step = 1001 (152.075 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.650375\n",
      "INFO:tensorflow:loss = 171.76004, step = 1101 (153.831 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1169 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpfgibw1gu\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.599216\n",
      "INFO:tensorflow:loss = 180.24825, step = 1201 (166.810 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.660215\n",
      "INFO:tensorflow:loss = 148.27768, step = 1301 (151.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.655477\n",
      "INFO:tensorflow:loss = 159.76556, step = 1401 (152.568 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.66589\n",
      "INFO:tensorflow:loss = 166.51727, step = 1501 (150.172 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1557 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpfgibw1gu\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.605182\n",
      "INFO:tensorflow:loss = 141.39699, step = 1601 (165.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.655434\n",
      "INFO:tensorflow:loss = 122.67583, step = 1701 (152.559 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.651185\n",
      "INFO:tensorflow:loss = 93.839615, step = 1801 (153.557 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.653236\n",
      "INFO:tensorflow:loss = 95.322334, step = 1901 (153.083 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1940 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpfgibw1gu\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.583833\n",
      "INFO:tensorflow:loss = 83.64895, step = 2001 (171.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.652831\n",
      "INFO:tensorflow:loss = 88.51594, step = 2101 (153.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.643129\n",
      "INFO:tensorflow:loss = 74.1368, step = 2201 (155.511 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.649922\n",
      "INFO:tensorflow:loss = 101.36056, step = 2301 (154.024 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2319 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpfgibw1gu\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.599036\n",
      "INFO:tensorflow:loss = 86.18272, step = 2401 (166.755 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.655916\n",
      "INFO:tensorflow:loss = 91.54912, step = 2501 (152.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.65987\n",
      "INFO:tensorflow:loss = 82.90065, step = 2601 (151.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.656808\n",
      "INFO:tensorflow:loss = 96.98871, step = 2701 (152.262 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2704 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpfgibw1gu\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.597032\n",
      "INFO:tensorflow:loss = 90.42883, step = 2801 (167.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.654263\n",
      "INFO:tensorflow:loss = 81.25127, step = 2901 (152.835 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.662862\n",
      "INFO:tensorflow:loss = 90.23419, step = 3001 (150.878 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3089 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpfgibw1gu\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.593162\n",
      "INFO:tensorflow:loss = 83.70276, step = 3101 (168.549 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.661897\n",
      "INFO:tensorflow:loss = 69.50552, step = 3201 (151.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.656446\n",
      "INFO:tensorflow:loss = 61.15009, step = 3301 (152.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.670223\n",
      "INFO:tensorflow:loss = 83.3407, step = 3401 (149.205 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3474 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpfgibw1gu\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.586844\n",
      "INFO:tensorflow:loss = 102.35817, step = 3501 (170.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.656215\n",
      "INFO:tensorflow:loss = 75.28758, step = 3601 (152.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.662268\n",
      "INFO:tensorflow:loss = 71.820564, step = 3701 (151.007 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.669695\n",
      "INFO:tensorflow:loss = 75.14347, step = 3801 (149.305 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3862 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpfgibw1gu\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.610406\n",
      "INFO:tensorflow:loss = 68.945114, step = 3901 (163.852 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpfgibw1gu\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 66.36391.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpfgibw1gu\\model.ckpt-4000\n",
      "Train the 3 model, please keep waiting !!!\n",
      "\n",
      "\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpqafd1r4y\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\ZHANGX~1\\\\AppData\\\\Local\\\\Temp\\\\tmpqafd1r4y', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000021958C3CBE0>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpqafd1r4y\\model.ckpt.\n",
      "INFO:tensorflow:loss = 895.56165, step = 1\n",
      "INFO:tensorflow:global_step/sec: 0.657718\n",
      "INFO:tensorflow:loss = 563.1317, step = 101 (152.072 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.667103\n",
      "INFO:tensorflow:loss = 464.21045, step = 201 (149.898 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.668148\n",
      "INFO:tensorflow:loss = 419.16714, step = 301 (149.672 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 391 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpqafd1r4y\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.607444\n",
      "INFO:tensorflow:loss = 316.8486, step = 401 (164.593 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.665417\n",
      "INFO:tensorflow:loss = 256.12585, step = 501 (150.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.666383\n",
      "INFO:tensorflow:loss = 277.26935, step = 601 (150.057 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.666905\n",
      "INFO:tensorflow:loss = 223.82132, step = 701 (149.940 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 781 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpqafd1r4y\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.603278\n",
      "INFO:tensorflow:loss = 222.78006, step = 801 (165.740 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.668146\n",
      "INFO:tensorflow:loss = 211.8277, step = 901 (149.927 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.664367\n",
      "INFO:tensorflow:loss = 174.93373, step = 1001 (150.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.666701\n",
      "INFO:tensorflow:loss = 147.15201, step = 1101 (149.997 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1171 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpqafd1r4y\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.603386\n",
      "INFO:tensorflow:loss = 196.66193, step = 1201 (165.707 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.662659\n",
      "INFO:tensorflow:loss = 182.81873, step = 1301 (150.935 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.669854\n",
      "INFO:tensorflow:loss = 153.79793, step = 1401 (149.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.671172\n",
      "INFO:tensorflow:loss = 107.52554, step = 1501 (148.999 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1562 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpqafd1r4y\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.608858\n",
      "INFO:tensorflow:loss = 111.33821, step = 1601 (164.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.672079\n",
      "INFO:tensorflow:loss = 130.38293, step = 1701 (148.790 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.672563\n",
      "INFO:tensorflow:loss = 117.463585, step = 1801 (148.688 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.672432\n",
      "INFO:tensorflow:loss = 101.05264, step = 1901 (148.797 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1956 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpqafd1r4y\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.616171\n",
      "INFO:tensorflow:loss = 118.95483, step = 2001 (162.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.673856\n",
      "INFO:tensorflow:loss = 108.27989, step = 2101 (148.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.67508\n",
      "INFO:tensorflow:loss = 73.99193, step = 2201 (148.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.672283\n",
      "INFO:tensorflow:loss = 111.77303, step = 2301 (148.715 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 2352 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpqafd1r4y\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.611429\n",
      "INFO:tensorflow:loss = 105.84696, step = 2401 (163.560 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.670096\n",
      "INFO:tensorflow:loss = 78.83223, step = 2501 (149.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.675007\n",
      "INFO:tensorflow:loss = 91.49517, step = 2601 (148.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.673238\n",
      "INFO:tensorflow:loss = 86.30971, step = 2701 (148.567 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2746 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpqafd1r4y\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.604739\n",
      "INFO:tensorflow:loss = 108.97676, step = 2801 (165.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.673066\n",
      "INFO:tensorflow:loss = 81.02835, step = 2901 (148.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.67308\n",
      "INFO:tensorflow:loss = 86.6936, step = 3001 (148.687 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.67174\n",
      "INFO:tensorflow:loss = 73.07594, step = 3101 (148.751 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3139 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpqafd1r4y\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.60868\n",
      "INFO:tensorflow:loss = 59.415604, step = 3201 (164.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.676245\n",
      "INFO:tensorflow:loss = 72.37036, step = 3301 (147.868 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.672762\n",
      "INFO:tensorflow:loss = 73.64386, step = 3401 (148.641 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.674502\n",
      "INFO:tensorflow:loss = 55.188183, step = 3501 (148.264 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3534 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpqafd1r4y\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.607105\n",
      "INFO:tensorflow:loss = 63.644264, step = 3601 (164.710 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.673692\n",
      "INFO:tensorflow:loss = 57.42794, step = 3701 (148.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.674156\n",
      "INFO:tensorflow:loss = 49.35246, step = 3801 (148.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.67598\n",
      "INFO:tensorflow:loss = 59.66047, step = 3901 (147.933 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3928 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpqafd1r4y\\model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpqafd1r4y\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 56.10343.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpqafd1r4y\\model.ckpt-4000\n",
      "Train the 4 model, please keep waiting !!!\n",
      "\n",
      "\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpd8lcey2f\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\ZHANGX~1\\\\AppData\\\\Local\\\\Temp\\\\tmpd8lcey2f', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000021958BC9780>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpd8lcey2f\\model.ckpt.\n",
      "INFO:tensorflow:loss = 895.97577, step = 1\n",
      "INFO:tensorflow:global_step/sec: 0.668228\n",
      "INFO:tensorflow:loss = 585.0054, step = 101 (149.683 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.672079\n",
      "INFO:tensorflow:loss = 441.46912, step = 201 (148.917 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.671325\n",
      "INFO:tensorflow:loss = 371.4842, step = 301 (148.824 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 393 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpd8lcey2f\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.610346\n",
      "INFO:tensorflow:loss = 330.15115, step = 401 (163.817 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.673651\n",
      "INFO:tensorflow:loss = 272.87488, step = 501 (148.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.673715\n",
      "INFO:tensorflow:loss = 282.64838, step = 601 (148.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.673847\n",
      "INFO:tensorflow:loss = 242.28821, step = 701 (148.407 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 787 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpd8lcey2f\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.600011\n",
      "INFO:tensorflow:loss = 229.11102, step = 801 (166.629 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.674379\n",
      "INFO:tensorflow:loss = 176.41217, step = 901 (148.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.672749\n",
      "INFO:tensorflow:loss = 180.6029, step = 1001 (148.651 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.673824\n",
      "INFO:tensorflow:loss = 161.118, step = 1101 (148.409 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1180 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpd8lcey2f\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.612955\n",
      "INFO:tensorflow:loss = 142.2811, step = 1201 (163.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.674702\n",
      "INFO:tensorflow:loss = 147.60687, step = 1301 (148.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.672075\n",
      "INFO:tensorflow:loss = 147.87352, step = 1401 (148.793 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.674675\n",
      "INFO:tensorflow:loss = 146.26538, step = 1501 (148.220 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1575 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpd8lcey2f\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.604552\n",
      "INFO:tensorflow:loss = 134.13509, step = 1601 (165.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.673474\n",
      "INFO:tensorflow:loss = 110.475075, step = 1701 (148.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.672292\n",
      "INFO:tensorflow:loss = 132.50935, step = 1801 (148.739 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.672726\n",
      "INFO:tensorflow:loss = 106.18512, step = 1901 (148.649 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1968 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpd8lcey2f\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.611451\n",
      "INFO:tensorflow:loss = 106.61844, step = 2001 (163.541 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.674215\n",
      "INFO:tensorflow:loss = 144.75128, step = 2101 (148.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.671664\n",
      "INFO:tensorflow:loss = 104.52211, step = 2201 (148.882 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.674647\n",
      "INFO:tensorflow:loss = 90.44857, step = 2301 (148.282 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2362 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpd8lcey2f\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.60527\n",
      "INFO:tensorflow:loss = 66.48749, step = 2401 (165.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.674902\n",
      "INFO:tensorflow:loss = 99.88498, step = 2501 (148.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.672713\n",
      "INFO:tensorflow:loss = 62.412945, step = 2601 (148.740 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.674989\n",
      "INFO:tensorflow:loss = 106.72673, step = 2701 (148.064 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2756 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpd8lcey2f\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.611593\n",
      "INFO:tensorflow:loss = 86.29051, step = 2801 (163.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.676474\n",
      "INFO:tensorflow:loss = 86.40181, step = 2901 (147.830 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.674474\n",
      "INFO:tensorflow:loss = 58.33143, step = 3001 (148.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.674279\n",
      "INFO:tensorflow:loss = 91.713005, step = 3101 (148.318 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3151 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpd8lcey2f\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.598473\n",
      "INFO:tensorflow:loss = 65.87045, step = 3201 (167.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.67508\n",
      "INFO:tensorflow:loss = 73.96944, step = 3301 (148.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.673306\n",
      "INFO:tensorflow:loss = 77.634995, step = 3401 (148.515 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.673724\n",
      "INFO:tensorflow:loss = 62.854267, step = 3501 (148.439 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3543 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpd8lcey2f\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.609099\n",
      "INFO:tensorflow:loss = 61.472626, step = 3601 (164.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.673556\n",
      "INFO:tensorflow:loss = 28.503149, step = 3701 (148.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.670307\n",
      "INFO:tensorflow:loss = 65.10584, step = 3801 (149.172 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.67259\n",
      "INFO:tensorflow:loss = 57.301857, step = 3901 (148.690 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3937 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpd8lcey2f\\model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpd8lcey2f\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 61.81904.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpd8lcey2f\\model.ckpt-4000\n",
      "Train the 5 model, please keep waiting !!!\n",
      "\n",
      "\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmplnfld5i5\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\ZHANGX~1\\\\AppData\\\\Local\\\\Temp\\\\tmplnfld5i5', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000021895CECAC8>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmplnfld5i5\\model.ckpt.\n",
      "INFO:tensorflow:loss = 895.8487, step = 1\n",
      "INFO:tensorflow:global_step/sec: 0.672713\n",
      "INFO:tensorflow:loss = 596.8937, step = 101 (148.686 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.675395\n",
      "INFO:tensorflow:loss = 468.07874, step = 201 (148.050 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.676488\n",
      "INFO:tensorflow:loss = 422.79825, step = 301 (147.823 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 396 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmplnfld5i5\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.610786\n",
      "INFO:tensorflow:loss = 361.99936, step = 401 (163.703 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.676859\n",
      "INFO:tensorflow:loss = 328.45273, step = 501 (147.772 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.675925\n",
      "INFO:tensorflow:loss = 304.28992, step = 601 (147.940 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.676341\n",
      "INFO:tensorflow:loss = 278.80594, step = 701 (147.861 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 792 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmplnfld5i5\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.612268\n",
      "INFO:tensorflow:loss = 237.97856, step = 801 (163.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.676804\n",
      "INFO:tensorflow:loss = 220.11832, step = 901 (147.780 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.674183\n",
      "INFO:tensorflow:loss = 240.7752, step = 1001 (148.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.677235\n",
      "INFO:tensorflow:loss = 170.85327, step = 1101 (147.673 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1188 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmplnfld5i5\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.612448\n",
      "INFO:tensorflow:loss = 196.39163, step = 1201 (163.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.6778\n",
      "INFO:tensorflow:loss = 172.17296, step = 1301 (147.567 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.67457\n",
      "INFO:tensorflow:loss = 133.15063, step = 1401 (148.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.67598\n",
      "INFO:tensorflow:loss = 156.47429, step = 1501 (147.942 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1583 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmplnfld5i5\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.609973\n",
      "INFO:tensorflow:loss = 122.2642, step = 1601 (163.914 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.676859\n",
      "INFO:tensorflow:loss = 146.57822, step = 1701 (147.770 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.67593\n",
      "INFO:tensorflow:loss = 152.55824, step = 1801 (147.946 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.67545\n",
      "INFO:tensorflow:loss = 132.61786, step = 1901 (148.050 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1978 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmplnfld5i5\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.603023\n",
      "INFO:tensorflow:loss = 144.17905, step = 2001 (165.799 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.676172\n",
      "INFO:tensorflow:loss = 128.10307, step = 2101 (147.922 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.676502\n",
      "INFO:tensorflow:loss = 110.96567, step = 2201 (147.811 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.666032\n",
      "INFO:tensorflow:loss = 119.22222, step = 2301 (150.141 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2369 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmplnfld5i5\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.605769\n",
      "INFO:tensorflow:loss = 122.78803, step = 2401 (165.089 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.670218\n",
      "INFO:tensorflow:loss = 97.75856, step = 2501 (149.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.677754\n",
      "INFO:tensorflow:loss = 128.90111, step = 2601 (147.562 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.676021\n",
      "INFO:tensorflow:loss = 95.671036, step = 2701 (147.912 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2764 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmplnfld5i5\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.612902\n",
      "INFO:tensorflow:loss = 87.25955, step = 2801 (163.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.676062\n",
      "INFO:tensorflow:loss = 108.81852, step = 2901 (147.900 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.676932\n",
      "INFO:tensorflow:loss = 84.778366, step = 3001 (147.736 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.675354\n",
      "INFO:tensorflow:loss = 90.33354, step = 3101 (148.186 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3160 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmplnfld5i5\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.617576\n",
      "INFO:tensorflow:loss = 73.21741, step = 3201 (161.850 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.675683\n",
      "INFO:tensorflow:loss = 81.66507, step = 3301 (147.958 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.676373\n",
      "INFO:tensorflow:loss = 55.69867, step = 3401 (147.897 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.67641\n",
      "INFO:tensorflow:loss = 103.0804, step = 3501 (147.788 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3557 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmplnfld5i5\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.615\n",
      "INFO:tensorflow:loss = 78.927795, step = 3601 (162.593 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.674966\n",
      "INFO:tensorflow:loss = 65.1144, step = 3701 (148.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.677956\n",
      "INFO:tensorflow:loss = 68.0982, step = 3801 (147.592 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.675217\n",
      "INFO:tensorflow:loss = 61.41572, step = 3901 (148.006 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3953 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmplnfld5i5\\model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmplnfld5i5\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 66.4565.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmplnfld5i5\\model.ckpt-4000\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.60      0.55      0.57      4206\n",
      "          2       0.79      0.87      0.83      3937\n",
      "          3       0.54      0.47      0.50      4174\n",
      "          4       0.83      0.88      0.85      4032\n",
      "          5       0.88      0.95      0.91      4018\n",
      "\n",
      "avg / total       0.72      0.74      0.73     20367\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label = []\n",
    "number_models = 5\n",
    "for i in range(number_models):\n",
    "    print ('Train the {} model, please keep waiting !!!'.format(i+1))\n",
    "    print ('\\n')\n",
    "    \n",
    "    X_train_set, X_test_tmp, Y_train_set, Y_test_tmp = train_test_split(X_train, Y_train, test_size = 0.2, random_state = i)\n",
    "\n",
    "    ## define input function\n",
    "    input_func = tf.estimator.inputs.pandas_input_fn(x = X_train_set, y = Y_train_set, batch_size = 500, \n",
    "                                                        num_epochs = 600, shuffle = True)\n",
    "\n",
    "    ## define the feature columns\n",
    "    feat_cols = [Locale_Reference, State_Reference, Flight_Conditions, Weather_Elements_Visibility, Work_Environment_Factor, \n",
    "                     Light, ATC_Advisory, Aircraft_Operator, Make_Model_Name, Crew_Size, Flight_Plan, Mission, Flight_Phase1, \n",
    "                     Route_In_Use, Airspace, Aircraft_Component, Manufacturer, Location_Of_Person, Location_In_Aircraft, \n",
    "                     Reporter_Organization, Function, Qualification, Human_Factors, Anomaly, Detector, When_Detected, \n",
    "                     Were_Passengers_Involved_In_Event, Contributing_Factors_Situations, Primary_Problem]\n",
    "\n",
    "    ## build the model\n",
    "    model = tf.estimator.DNNClassifier(hidden_units = [40, 40, 40, 40, 40, 40, 40, 40], feature_columns = feat_cols,\n",
    "                                           n_classes = 6, optimizer = tf.train.AdamOptimizer(learning_rate = 0.001))\n",
    "        \n",
    "    ## train the model\n",
    "    model.train(input_fn = input_func, steps = 4000)\n",
    "    \n",
    "    \n",
    "    ## make predictions\n",
    "    eval_input = tf.estimator.inputs.pandas_input_fn(x = X_test, shuffle = False)\n",
    "    prediction = list(model.predict(eval_input))\n",
    "\n",
    "    pred_label = [int(pred['class_ids']) for pred in prediction]\n",
    "    \n",
    "    label.append(pred_label)\n",
    "    \n",
    "    \n",
    "ensembel_pred = []\n",
    "for j in range(len(label[0])):\n",
    "    x = np.zeros(shape = (len(label), 1)) - 1\n",
    "    for i in range(len(label)):\n",
    "        x[i] =  label[i][j]\n",
    "    (values, counts) = np.unique(x, return_counts=True)\n",
    "    ind = np.argmax(counts)\n",
    "    ensembel_pred.append((values[ind]))\n",
    "\n",
    "ensembel_pred\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "target_names = [str(i) for i in range(1, 5+1)]\n",
    "print(classification_report(Y_test, ensembel_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20367"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ensembel_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = []\n",
    "for i in range(len(ensembel_pred)):\n",
    "    if pred_label[i] == ensembel_pred[i]:\n",
    "        label.append(pred_label[i])\n",
    "    else:\n",
    "        label.append(np.random.choice([pred_label[i], ensembel_pred[i]], p = [0.9, 0.1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.51      0.58      4206\n",
      "          2       0.80      0.91      0.85      3937\n",
      "          3       0.62      0.54      0.58      4174\n",
      "          4       0.78      0.91      0.84      4032\n",
      "          5       0.88      0.97      0.93      4018\n",
      "\n",
      "avg / total       0.75      0.76      0.75     20367\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, label, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2601    3\n",
       "740     1\n",
       "378     4\n",
       "372     3\n",
       "1923    4\n",
       "Name: Result, dtype: int64"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 4, ..., 2, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
