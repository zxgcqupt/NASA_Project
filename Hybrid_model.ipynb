{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from os import listdir\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "#print ('The version of TensorFlow is {}'.format(tf.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the 12-year incident/accident data from ASRS (Aviation Safety Reporting System)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = './Data'\n",
    "\n",
    "appended_data = []\n",
    "for file_name in listdir(root_path):\n",
    "    file_path = root_path + '/' + file_name.encode().decode('utf-8')\n",
    "    data_from_one_csv = pd.read_csv(file_path, skiprows=1)\n",
    "    appended_data.append(data_from_one_csv)\n",
    "    \n",
    "data = pd.concat(appended_data, axis=0)\n",
    "data = data.drop(columns = ['ACN', 'Date', 'Local Time Of Day', 'Ceiling', 'Callback', 'Callback.1', 'Unnamed: 96'])\n",
    "data = data.rename(index=str, columns={\"Flight Phase\": \"Flight Phase1\"})\n",
    "\n",
    "## drop the rows with empty synopsis description\n",
    "data = data[pd.notnull(data['Synopsis'])]\n",
    "\n",
    "X = data.drop(columns = 'Result')\n",
    "Y_raw = pd.DataFrame(data['Result'])\n",
    "\n",
    "processed_Y = []\n",
    "count_multiple_outcome = 0\n",
    "for index, row in Y_raw.iterrows():\n",
    "    #print (index, row['Result'])\n",
    "    outcome = row['Result']\n",
    "    if type(outcome) == np.float:\n",
    "        res = 'unknown'\n",
    "        processed_Y.append([res])\n",
    "    elif ';' in outcome:\n",
    "        count_multiple_outcome += 1\n",
    "        res = str(outcome).split(';')\n",
    "        # remove the space at the beginning of each event outcome\n",
    "        for i in range(len(res)):\n",
    "            res[i] = res[i].strip()\n",
    "        #print (res)\n",
    "        processed_Y.append(res)\n",
    "    else:\n",
    "        res = outcome\n",
    "        processed_Y.append([res])\n",
    "        \n",
    "X['res'] = processed_Y ## add the res column first for the use in the subsequent subcategory models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.502222291050439"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_multiple_outcome/X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_anomaly = list(set(X['Anomaly']))\n",
    "#for i in range(len(unique_anomaly)):\n",
    "#    print (i, \": \", unique_anomaly[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform risk-based event outcome cetegorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5] [16508  8636 18841  8261 12327]\n"
     ]
    }
   ],
   "source": [
    "## compress the number of labels to be predicted --> map result to risk level\n",
    "rate_five = ['General Declared Emergency', 'General Physical Injury / Incapacitation', 'Flight Crew Inflight Shutdown', \n",
    "             'Air Traffic Control Separated Traffic', 'Aircraft Aircraft Damaged']\n",
    "\n",
    "rate_four = ['General Evacuated', 'Flight Crew Regained Aircraft Control', \n",
    "              'Air Traffic Control Issued Advisory / Alert', 'Flight Crew Landed in Emergency Condition',\n",
    "              'Flight Crew Landed In Emergency Condition']\n",
    "\n",
    "rate_three = ['General Work Refused', 'Flight Crew Became Reoriented', 'Flight Crew Diverted', \n",
    "             'Flight Crew Executed Go Around / Missed Approach', \n",
    "             'Flight Crew Overcame Equipment Problem', 'Flight Crew Rejected Takeoff', 'Flight Crew Took Evasive Action', \n",
    "             'Air Traffic Control Issued New Clearance']\n",
    "\n",
    "rate_two = ['General Maintenance Action', 'General Flight Cancelled / Delayed', \n",
    "              'General Release Refused / Aircraft Not Accepted', \n",
    "              'Flight Crew Overrode Automation', 'Flight Crew FLC Overrode Automation',\n",
    "              'Flight Crew Exited Penetrated Airspace', \n",
    "              'Flight Crew Requested ATC Assistance / Clarification', 'Flight Crew Landed As Precaution',\n",
    "              'Flight Crew Returned To Clearance', 'Flight Crew Returned To Departure Airport',\n",
    "              'Aircraft Automation Overrode Flight Crew']\n",
    "\n",
    "rate_one = ['General Police / Security Involved', 'Flight Crew Returned To Gate', 'Aircraft Equipment Problem Dissipated', \n",
    "            'unknown', 'Air Traffic Control Provided Assistance',\n",
    "            'General None Reported / Taken', 'Flight Crew FLC complied w / Automation / Advisory']\n",
    "\n",
    "def risk_quantification(val):\n",
    "    event_risk = []\n",
    "    for i in range(len(val)):\n",
    "        item = val[i].lstrip() ## remove the space at the start of each item\n",
    "        if item in rate_five:\n",
    "            event_risk.append(5)\n",
    "        elif item in rate_four:\n",
    "            event_risk.append(4)\n",
    "        elif item in rate_three:\n",
    "            event_risk.append(3)\n",
    "        elif item in rate_two:\n",
    "            event_risk.append(2)\n",
    "        elif item in rate_one:\n",
    "            event_risk.append(1)\n",
    "    return max(event_risk)\n",
    "\n",
    "Y_ = []\n",
    "for i in range(len(processed_Y)):\n",
    "    if len(processed_Y[i]) > 1:\n",
    "        val = risk_quantification(processed_Y[i])\n",
    "        Y_.append(val)\n",
    "    else:\n",
    "        item_val = \"\".join(processed_Y[i]) ## convert a list to a string\n",
    "        #print (item_val)\n",
    "        if item_val in rate_five:\n",
    "            Y_.append(5)\n",
    "        elif item_val in rate_four:\n",
    "            Y_.append(4)\n",
    "        elif item_val in rate_three:\n",
    "            Y_.append(3)\n",
    "        elif item_val in rate_two:\n",
    "            Y_.append(2)\n",
    "        elif item_val in rate_one:\n",
    "            Y_.append(1)\n",
    "        else:\n",
    "            print (Y['Result'][i])\n",
    "\n",
    "outcomes = np.asarray(Y_)\n",
    "Y_true = pd.DataFrame(Y_, index = X.index, columns = ['Result'])\n",
    "unique, counts = np.unique(outcomes, return_counts=True)\n",
    "print (unique, counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Up-sampling the minority classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After the upsampling, the number of each item is: \n",
      "\n",
      "[1 2 3 4 5]\n",
      "[16508 18841 18841 18841 18841]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "data_rev = X.copy(deep=True)\n",
    "data_rev['Result'] = Y_true\n",
    "\n",
    "df_majority_1 = data_rev[data_rev['Result']==1]\n",
    "df_majority_3 = data_rev[data_rev['Result']==3]\n",
    "df_minority_2 = data_rev[data_rev['Result']==2]\n",
    "df_minority_4 = data_rev[data_rev['Result']==4]\n",
    "df_minority_5 = data_rev[data_rev['Result']==5]\n",
    "\n",
    "# Upsample minority class\n",
    "df_minority_2_upsampled = resample(df_minority_2, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=18841,    # to match majority class\n",
    "                                 random_state=145) # reproducible results\n",
    "df_minority_4_upsampled = resample(df_minority_4, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=18841,    # to match majority class\n",
    "                                 random_state=145) # reproducible results\n",
    "df_minority_5_upsampled = resample(df_minority_5, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=18841,    # to match majority class\n",
    "                                 random_state=145) # reproducible results\n",
    "\n",
    "df_upsampled = pd.concat([df_majority_1, df_majority_3, df_minority_2_upsampled, df_minority_4_upsampled, \n",
    "                          df_minority_5_upsampled])\n",
    "\n",
    "## reset the index of concatnated dataframe\n",
    "\n",
    "df_upsampled.reset_index(drop=True)\n",
    "df_upsampled['Result'].value_counts()\n",
    "\n",
    "\n",
    "X = df_upsampled.drop(columns = 'Result')\n",
    "Y_true = df_upsampled['Result']\n",
    "\n",
    "unique, counts = np.unique(Y_true, return_counts=True)\n",
    "print ('After the upsampling, the number of each item is: \\n')\n",
    "print (unique)\n",
    "print (counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91872, 90)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## copy the data\n",
    "X_org = X.copy(deep=True)\n",
    "Y_org = Y_true.copy(deep=True)\n",
    "X_org.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "The unique data types across all the items are: {<class 'numpy.float64'>, <class 'float'>, <class 'list'>, <class 'str'>}\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8     2.0\n",
       "13    2.0\n",
       "14    2.0\n",
       "17    2.0\n",
       "19    2.0\n",
       "Name: Crew_Size, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## change column names\n",
    "new_col_name = []\n",
    "for col in X_org.columns:\n",
    "    #print(type(col))\n",
    "    new_col_name.append(col.replace('/ ', '').replace(' ', '_'))\n",
    "    \n",
    "X_org.columns = new_col_name\n",
    "\n",
    "\n",
    "data_type = []\n",
    "for item_name in X_org.keys():\n",
    "    data_type.append(type(X_org[item_name][0]))\n",
    "\n",
    "print ('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "print ('The unique data types across all the items are:', set(data_type))\n",
    "print ('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "\n",
    "for item_name in X_org.keys():\n",
    "    ## find the number of NaN in this item\n",
    "    no = np.sum(X_org[item_name].isna().astype(int))\n",
    "    #print ('The number of {} with value equal to NaN is {}'.format(item_name, no))\n",
    "    \n",
    "    ## Replace the missing value with corresponding values\n",
    "    if no > 0:\n",
    "        if type(X_org[item_name][0]) == np.float64:\n",
    "            X_org[item_name].fillna(-1, inplace = True)\n",
    "        else:\n",
    "            X_org[item_name].fillna('unknown', inplace = True)\n",
    "X_org['Crew_Size'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "X_org.to_pickle(\"./X_org.pkl\")\n",
    "Y_org.to_pickle(\"./Y_org.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################\n",
    "############### Construct classification report from confusion matrix ###############\n",
    "#####################################################################################\n",
    "np.set_printoptions(suppress=True)\n",
    "def construct_classification_report(confusion_matrix):\n",
    "    no_of_class = len(confusion_matrix)\n",
    "    confusion_report = np.zeros((no_of_class, 4))\n",
    "    \n",
    "    for i in range(len(confusion_matrix)):\n",
    "        confusion_report[i, 0] = confusion_matrix[i, i]/np.sum(confusion_matrix[:, i])\n",
    "        confusion_report[i, 1] = confusion_matrix[i, i]/np.sum(confusion_matrix[i,:])\n",
    "        confusion_report[i, 2] = 2 * (confusion_report[i, 0] * confusion_report[i, 1])/(confusion_report[i, 0] + confusion_report[i, 1])\n",
    "        confusion_report[i, -1] = np.sum(confusion_matrix[i, :])\n",
    "    \n",
    "    return np.round(confusion_report, decimals = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Cross Validation\n",
    "\n",
    "### Split the data, the data has three parts: \n",
    "##### X_train, Y_train: train the data\n",
    "##### X_validation, Y_validation: trial data to obtain the performance metrics\n",
    "##### X_test, Y_test: test data used to compare the performance of hybrid model with SVM and DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current fold:  1\n",
      "Accuracy:  0.7815397017331721\n",
      "The best set of parameters is \n",
      " {'clf__alpha': 1e-05, 'clf__loss': 'modified_huber', 'clf__max_iter': 80, 'clf__penalty': 'elasticnet', 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "\n",
      "\n",
      "Train the 1 model, please keep waiting !!!\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp7om09l9i\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\ZHANGX~1\\\\AppData\\\\Local\\\\Temp\\\\tmp7om09l9i', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000025203AF5C18>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp7om09l9i\\model.ckpt.\n",
      "INFO:tensorflow:loss = 1793.9658, step = 1\n",
      "INFO:tensorflow:Loss for final step: 1793.9658.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp7om09l9i\\model.ckpt-1\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp7om09l9i\\model.ckpt-1\n",
      "\n",
      "\n",
      "\n",
      "Train the 2 model, please keep waiting !!!\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpz4zt47zs\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\ZHANGX~1\\\\AppData\\\\Local\\\\Temp\\\\tmpz4zt47zs', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000025213E73F98>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpz4zt47zs\\model.ckpt.\n",
      "INFO:tensorflow:loss = 1790.2031, step = 1\n",
      "INFO:tensorflow:Loss for final step: 1790.2031.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpz4zt47zs\\model.ckpt-1\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpz4zt47zs\\model.ckpt-1\n",
      "\n",
      "\n",
      "\n",
      "Train the 3 model, please keep waiting !!!\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpbbba41q_\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\ZHANGX~1\\\\AppData\\\\Local\\\\Temp\\\\tmpbbba41q_', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000025214B04B70>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpbbba41q_\\model.ckpt.\n",
      "INFO:tensorflow:loss = 1795.9302, step = 1\n",
      "INFO:tensorflow:Loss for final step: 1795.9302.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpbbba41q_\\model.ckpt-1\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpbbba41q_\\model.ckpt-1\n",
      "\n",
      "\n",
      "\n",
      "Train the 4 model, please keep waiting !!!\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmps2puigul\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\ZHANGX~1\\\\AppData\\\\Local\\\\Temp\\\\tmps2puigul', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000002520D7FDA90>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmps2puigul\\model.ckpt.\n",
      "INFO:tensorflow:loss = 1793.3949, step = 1\n",
      "INFO:tensorflow:Loss for final step: 1793.3949.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmps2puigul\\model.ckpt-1\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmps2puigul\\model.ckpt-1\n",
      "\n",
      "\n",
      "\n",
      "Train the 5 model, please keep waiting !!!\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpjz69g0d_\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\ZHANGX~1\\\\AppData\\\\Local\\\\Temp\\\\tmpjz69g0d_', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000025215664860>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpjz69g0d_\\model.ckpt.\n",
      "INFO:tensorflow:loss = 1798.8578, step = 1\n",
      "INFO:tensorflow:Loss for final step: 1798.8578.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpjz69g0d_\\model.ckpt-1\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpjz69g0d_\\model.ckpt-1\n",
      "\n",
      "\n",
      "\n",
      "Train the 6 model, please keep waiting !!!\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpqhzzt8hi\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\ZHANGX~1\\\\AppData\\\\Local\\\\Temp\\\\tmpqhzzt8hi', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000002520811FA20>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpqhzzt8hi\\model.ckpt.\n",
      "INFO:tensorflow:loss = 1798.4181, step = 1\n",
      "INFO:tensorflow:Loss for final step: 1798.4181.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpqhzzt8hi\\model.ckpt-1\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpqhzzt8hi\\model.ckpt-1\n",
      "\n",
      "\n",
      "\n",
      "Train the 7 model, please keep waiting !!!\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp25u60_uc\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\ZHANGX~1\\\\AppData\\\\Local\\\\Temp\\\\tmp25u60_uc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000252048F5B38>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp25u60_uc\\model.ckpt.\n",
      "INFO:tensorflow:loss = 1799.5432, step = 1\n",
      "INFO:tensorflow:Loss for final step: 1799.5432.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp25u60_uc\\model.ckpt-1\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmp25u60_uc\\model.ckpt-1\n",
      "\n",
      "\n",
      "\n",
      "Train the 8 model, please keep waiting !!!\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpgylnh_55\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\ZHANGX~1\\\\AppData\\\\Local\\\\Temp\\\\tmpgylnh_55', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000025207ED1C88>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpgylnh_55\\model.ckpt.\n",
      "INFO:tensorflow:loss = 1792.0884, step = 1\n",
      "INFO:tensorflow:Loss for final step: 1792.0884.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpgylnh_55\\model.ckpt-1\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpgylnh_55\\model.ckpt-1\n",
      "\n",
      "\n",
      "\n",
      "Train the 9 model, please keep waiting !!!\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpubzbczr4\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\ZHANGX~1\\\\AppData\\\\Local\\\\Temp\\\\tmpubzbczr4', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000002520860FBA8>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpubzbczr4\\model.ckpt.\n",
      "INFO:tensorflow:loss = 1790.9475, step = 1\n",
      "INFO:tensorflow:Loss for final step: 1790.9475.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpubzbczr4\\model.ckpt-1\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ZHANGX~1\\AppData\\Local\\Temp\\tmpubzbczr4\\model.ckpt-1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn import metrics\n",
    "\n",
    "test_random_state = 111\n",
    "cv = StratifiedShuffleSplit(n_splits = 10, test_size = 0.1, random_state = test_random_state)\n",
    "\n",
    "test_size_ratio = 0.06\n",
    "random_split_seed = 200\n",
    "for k, (data_index, test_index) in enumerate(cv.split(X_org, Y_org)):\n",
    "    print ('current fold: ', k+1)\n",
    "    \n",
    "    ### Split the data into three parts: \n",
    "    ### X_train, Y_train: train the data\n",
    "    ### X_validation, Y_validation: trial data to obtain the performance metrics\n",
    "    ### X_test, Y_test: test data used to compare the performance of hybrid model with SVM and DNN\n",
    "    \n",
    "    X = X_org.iloc[data_index]\n",
    "    Y = Y_org.iloc[data_index]\n",
    "    \n",
    "    X_test = X_org.iloc[test_index]\n",
    "    Y_test = Y_org.iloc[test_index]\n",
    "    \n",
    "    X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size = test_size_ratio, \n",
    "                                                    random_state = random_split_seed + i)\n",
    "    \n",
    "    ###########################################################\n",
    "    ################# Support Vector Machine ##################\n",
    "    ###########################################################\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.linear_model import SGDClassifier\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    from sklearn.feature_extraction.text import TfidfTransformer\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.metrics import classification_report\n",
    "\n",
    "    text_clf = Pipeline([('vect', CountVectorizer(stop_words = 'english')),\n",
    "                          ('tfidf', TfidfTransformer()),\n",
    "                          ('clf', SGDClassifier(loss='epsilon_insensitive', penalty='l2',\n",
    "                                                alpha=1e-5, random_state=40,\n",
    "                                                max_iter=10, tol=None)),\n",
    "                        ])\n",
    "\n",
    "\n",
    "    parameters = {'clf__loss': ['epsilon_insensitive', 'hinge', 'log', 'huber', 'modified_huber', 'perceptron', \n",
    "                                'squared_loss', 'squared_epsilon_insensitive', 'squared_hinge'],\n",
    "                  'vect__ngram_range': [(1, 1), (1, 2), (1, 3), (1, 4)],\n",
    "                  'tfidf__use_idf': (True, False),\n",
    "                  'clf__alpha': (1e-2, 1e-3, 1e-4, 1e-5),\n",
    "                  'clf__penalty': ['l1', 'l2', 'elasticnet'],\n",
    "                  'clf__max_iter': (10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 120, 150)\n",
    "     }\n",
    "\n",
    "    optimal_parameters = {'clf__loss': ['modified_huber'],\n",
    "                  'vect__ngram_range':  [(1, 2)],\n",
    "                  'tfidf__use_idf': [True],\n",
    "                  'clf__alpha': [1e-5],\n",
    "                  'clf__penalty': ['elasticnet'],\n",
    "                  'clf__max_iter': [80],\n",
    "     }\n",
    "\n",
    "    gs_clf = GridSearchCV(text_clf, optimal_parameters, n_jobs=-1)\n",
    "\n",
    "    gs_clf.fit(X_train['Synopsis'], Y_train)\n",
    "    pred_label_SVM = gs_clf.predict(X_validation['Synopsis'])\n",
    "\n",
    "    \n",
    "    #target_names = [str(i) for i in range(1, 6)]\n",
    "    #print(classification_report(Y_validation, pred_label_SVM, target_names=target_names))\n",
    "    \n",
    "    print ('Accuracy: ', np.sum(np.equal(Y_validation, pred_label_SVM).astype(int))/len(Y_validation))\n",
    "    print ('The best set of parameters is \\n', gs_clf.best_params_)\n",
    "    \n",
    "    #######################################################################\n",
    "    ################## Construct confusion matrix for SVM #################\n",
    "    #######################################################################\n",
    "    SVM_confusion_matrix = confusion_matrix(Y_validation, pred_label_SVM)\n",
    "    model_SVM = construct_classification_report(SVM_confusion_matrix)\n",
    "    \n",
    "    \n",
    "    #######################################################################\n",
    "    ######################## Deep Neural Network ##########################\n",
    "    #######################################################################\n",
    "    ## Location\n",
    "    Locale_Reference = tf.feature_column.categorical_column_with_hash_bucket('Locale_Reference', \n",
    "                                                                             hash_bucket_size = len(set(X['Locale_Reference'])))\n",
    "    State_Reference = tf.feature_column.categorical_column_with_hash_bucket('State_Reference', \n",
    "                                                                            hash_bucket_size = len(set(X['State_Reference'])))\n",
    "\n",
    "    ## Environment\n",
    "    Flight_Conditions = tf.feature_column.categorical_column_with_hash_bucket('Flight_Conditions', \n",
    "                                                                    hash_bucket_size = len(set(X['State_Reference'])))\n",
    "    Weather_Elements_Visibility = tf.feature_column.categorical_column_with_hash_bucket('Weather_Elements_Visibility', \n",
    "                                                                hash_bucket_size = len(set(X['Weather_Elements_Visibility'])))\n",
    "    Work_Environment_Factor = tf.feature_column.categorical_column_with_hash_bucket('Work_Environment_Factor', \n",
    "                                                                hash_bucket_size = len(set(X['Work_Environment_Factor'])))\n",
    "    Light = tf.feature_column.categorical_column_with_hash_bucket('Light', hash_bucket_size = \n",
    "                                                                  len(set(X['Work_Environment_Factor'])))\n",
    "    \n",
    "    ## Aircraft\n",
    "    ATC_Advisory = tf.feature_column.categorical_column_with_hash_bucket('ATC_Advisory', \n",
    "                                                                hash_bucket_size = len(set(X['ATC_Advisory'])))\n",
    "    Aircraft_Operator = tf.feature_column.categorical_column_with_hash_bucket('Aircraft_Operator', \n",
    "                                                                    hash_bucket_size = len(set(X['Aircraft_Operator'])))\n",
    "    Make_Model_Name = tf.feature_column.categorical_column_with_hash_bucket('Make_Model_Name', \n",
    "                                                                hash_bucket_size = len(set(X['Make_Model_Name'])))\n",
    "    Crew_Size = tf.feature_column.numeric_column('Crew_Size', [1])\n",
    "    Flight_Plan = tf.feature_column.categorical_column_with_hash_bucket('Flight_Plan', \n",
    "                                                                hash_bucket_size = len(set(X['Flight_Plan'])))\n",
    "    Mission = tf.feature_column.categorical_column_with_hash_bucket('Mission', \n",
    "                                                                    hash_bucket_size = len(set(X['Mission'])))\n",
    "    Flight_Phase1 = tf.feature_column.categorical_column_with_hash_bucket('Flight_Phase1', \n",
    "                                                                          hash_bucket_size = len(set(X['Flight_Phase1'])))\n",
    "    Route_In_Use = tf.feature_column.categorical_column_with_hash_bucket('Route_In_Use', \n",
    "                                                                         hash_bucket_size = len(set(X['Route_In_Use'])))\n",
    "    Airspace = tf.feature_column.categorical_column_with_hash_bucket('Airspace', \n",
    "                                                                     hash_bucket_size = len(set(X['Airspace'])))\n",
    "\n",
    "    ## Component\n",
    "    Aircraft_Component = tf.feature_column.categorical_column_with_hash_bucket('Aircraft_Component', \n",
    "                                                                 hash_bucket_size = len(set(X['Aircraft_Component'])))\n",
    "    Manufacturer = tf.feature_column.categorical_column_with_hash_bucket('Manufacturer', \n",
    "                                                            hash_bucket_size = len(set(X['Manufacturer'])))\n",
    "\n",
    "    ## Person\n",
    "    Location_Of_Person = tf.feature_column.categorical_column_with_hash_bucket('Location_Of_Person', \n",
    "                                                                    hash_bucket_size = len(set(X['Location_Of_Person'])))\n",
    "    Location_In_Aircraft = tf.feature_column.categorical_column_with_hash_bucket('Location_In_Aircraft',\n",
    "                                                                hash_bucket_size = len(set(X['Location_In_Aircraft'])))\n",
    "    Reporter_Organization = tf.feature_column.categorical_column_with_hash_bucket('Reporter_Organization',\n",
    "                                                                hash_bucket_size = len(set(X['Reporter_Organization'])))\n",
    "    Function = tf.feature_column.categorical_column_with_hash_bucket('Function', hash_bucket_size = len(set(X['Function'])))\n",
    "    Qualification = tf.feature_column.categorical_column_with_hash_bucket('Qualification', \n",
    "                                                                          hash_bucket_size = len(set(X['Qualification'])))\n",
    "    Human_Factors = tf.feature_column.categorical_column_with_hash_bucket('Human_Factors', \n",
    "                                                                          hash_bucket_size = len(set(X['Human_Factors'])))\n",
    "\n",
    "    ## Events\n",
    "    Anomaly = tf.feature_column.categorical_column_with_hash_bucket('Anomaly', \n",
    "                                                                    hash_bucket_size = len(set(X['Anomaly'])))\n",
    "    Detector = tf.feature_column.categorical_column_with_hash_bucket('Detector', \n",
    "                                                                     hash_bucket_size = len(set(X['Detector'])))\n",
    "    When_Detected = tf.feature_column.categorical_column_with_hash_bucket('When_Detected', \n",
    "                                                                          hash_bucket_size = len(set(X['When_Detected'])))\n",
    "    Were_Passengers_Involved_In_Event = tf.feature_column.categorical_column_with_hash_bucket('Were_Passengers_Involved_In_Event',\n",
    "                                                        hash_bucket_size = len(set(X['Were_Passengers_Involved_In_Event'])))\n",
    "\n",
    "    ## Assessments\n",
    "    Contributing_Factors_Situations = tf.feature_column.categorical_column_with_hash_bucket('Contributing_Factors_Situations', \n",
    "                                                       hash_bucket_size = len(set(X['Contributing_Factors_Situations'])))\n",
    "    Primary_Problem = tf.feature_column.categorical_column_with_hash_bucket('Primary_Problem', \n",
    "                                                            hash_bucket_size = len(set(X['Primary_Problem'])))\n",
    "\n",
    "    ## Place\n",
    "    Locale_Reference = tf.feature_column.embedding_column(Locale_Reference, len(set(X['Locale_Reference'])))\n",
    "    State_Reference = tf.feature_column.embedding_column(State_Reference, len(set(X['State_Reference'])))\n",
    "\n",
    "\n",
    "    ## Environment\n",
    "    Flight_Conditions = tf.feature_column.embedding_column(Flight_Conditions,  len(set(X['Flight_Conditions'])))\n",
    "    Weather_Elements_Visibility = tf.feature_column.embedding_column(Weather_Elements_Visibility,  \n",
    "                                                                     len(set(X['Weather_Elements_Visibility'])))\n",
    "    Work_Environment_Factor = tf.feature_column.embedding_column(Work_Environment_Factor,  len(set(X['Work_Environment_Factor'])))\n",
    "    Light = tf.feature_column.embedding_column(Light, len(set(X['Light'])))\n",
    "\n",
    "\n",
    "    ## Aircraft\n",
    "    ATC_Advisory = tf.feature_column.embedding_column(ATC_Advisory, len(set(X['ATC_Advisory'])))\n",
    "    Aircraft_Operator = tf.feature_column.embedding_column(Aircraft_Operator, len(set(X['Aircraft_Operator'])))\n",
    "    Make_Model_Name = tf.feature_column.embedding_column(Make_Model_Name, len(set(X['Make_Model_Name'])))\n",
    "    Flight_Plan = tf.feature_column.embedding_column(Flight_Plan, len(set(X['Flight_Plan'])))\n",
    "    Mission = tf.feature_column.embedding_column(Mission, len(set(X['Mission'])))\n",
    "    Flight_Phase1 = tf.feature_column.embedding_column(Flight_Phase1, len(set(X['Flight_Phase1'])))\n",
    "    Route_In_Use = tf.feature_column.embedding_column(Route_In_Use, len(set(X['Route_In_Use'])))\n",
    "    Airspace = tf.feature_column.embedding_column(Airspace, len(set(X['Airspace'])))\n",
    "\n",
    "    ## Component\n",
    "    Aircraft_Component = tf.feature_column.embedding_column(Aircraft_Component, len(set(X['Aircraft_Component'])))\n",
    "    Manufacturer = tf.feature_column.embedding_column(Manufacturer, len(set(X['Manufacturer'])))\n",
    "\n",
    "    ## Person\n",
    "    Location_Of_Person = tf.feature_column.embedding_column(Location_Of_Person, len(set(X['Location_Of_Person'])))\n",
    "    Location_In_Aircraft = tf.feature_column.embedding_column(Location_In_Aircraft, len(set(X['Location_In_Aircraft'])))\n",
    "    Reporter_Organization = tf.feature_column.embedding_column(Reporter_Organization, len(set(X['Reporter_Organization'])))\n",
    "    Function = tf.feature_column.embedding_column(Function, len(set(X['Function'])))\n",
    "    Qualification = tf.feature_column.embedding_column(Qualification, len(set(X['Qualification'])))\n",
    "    Human_Factors = tf.feature_column.embedding_column(Human_Factors, len(set(X['Human_Factors'])))\n",
    "\n",
    "    ## Events\n",
    "    Anomaly = tf.feature_column.embedding_column(Anomaly, len(set(X['Anomaly'])))\n",
    "    Detector = tf.feature_column.embedding_column(Detector, len(set(X['Detector'])))\n",
    "    When_Detected = tf.feature_column.embedding_column(When_Detected, len(set(X['When_Detected'])))\n",
    "    Were_Passengers_Involved_In_Event = tf.feature_column.embedding_column(Were_Passengers_Involved_In_Event,\n",
    "                                                                           len(set(X['Were_Passengers_Involved_In_Event'])))\n",
    "    \n",
    "    ## Assessments\n",
    "    Contributing_Factors_Situations = tf.feature_column.embedding_column(Contributing_Factors_Situations,\n",
    "                                                                         len(set(X['Contributing_Factors_Situations'])))\n",
    "    Primary_Problem = tf.feature_column.embedding_column(Primary_Problem, len(set(X['Primary_Problem'])))\n",
    "    \n",
    "    \n",
    "    ### start training the model\n",
    "    X_sub = X[['Locale_Reference', 'State_Reference', 'Flight_Conditions', 'Weather_Elements_Visibility', \n",
    "                'Work_Environment_Factor', 'Light', 'ATC_Advisory', 'Aircraft_Operator', 'Make_Model_Name', \n",
    "                'Crew_Size', 'Flight_Plan', 'Mission', 'Flight_Phase1',\n",
    "                'Route_In_Use','Airspace', 'Aircraft_Component', 'Manufacturer', 'Location_Of_Person', 'Location_In_Aircraft',\n",
    "                'Reporter_Organization', 'Function', 'Qualification', 'Human_Factors', 'Anomaly', 'Detector', 'When_Detected',\n",
    "                'Were_Passengers_Involved_In_Event', 'Contributing_Factors_Situations', 'Primary_Problem']]\n",
    "\n",
    "    X_train, X_validation, Y_train, Y_validation = train_test_split(X_sub, Y, test_size = test_size_ratio, \n",
    "                                                        random_state = random_split_seed + i)\n",
    "\n",
    "    ## extract the test data\n",
    "    X_test_sub = X_test[['Locale_Reference', 'State_Reference', 'Flight_Conditions', 'Weather_Elements_Visibility', \n",
    "                'Work_Environment_Factor', 'Light', 'ATC_Advisory', 'Aircraft_Operator', 'Make_Model_Name', \n",
    "                'Crew_Size', 'Flight_Plan', 'Mission', 'Flight_Phase1',\n",
    "                'Route_In_Use','Airspace', 'Aircraft_Component', 'Manufacturer', 'Location_Of_Person', 'Location_In_Aircraft',\n",
    "                'Reporter_Organization', 'Function', 'Qualification', 'Human_Factors', 'Anomaly', 'Detector', 'When_Detected',\n",
    "                'Were_Passengers_Involved_In_Event', 'Contributing_Factors_Situations', 'Primary_Problem']]\n",
    "    \n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    label_trial = []\n",
    "    label_test = []\n",
    "    number_models = 10\n",
    "    for i in range(number_models):\n",
    "        print ('\\n\\n')\n",
    "        print ('Train the {} model, please keep waiting !!!'.format(i+1))\n",
    "        \n",
    "        X_train_set, X_test_tmp, Y_train_set, Y_test_tmp = train_test_split(X_train, Y_train, test_size = 0.15, \n",
    "                                                                            random_state = 20 + i)\n",
    "        \n",
    "        ## define input function\n",
    "        input_func = tf.estimator.inputs.pandas_input_fn(x = X_train_set, y = Y_train_set, batch_size = 1000, \n",
    "                                                            num_epochs = 600, shuffle = True)\n",
    "\n",
    "        ## define the feature columns\n",
    "        feat_cols = [Locale_Reference, State_Reference, Flight_Conditions, Weather_Elements_Visibility, Work_Environment_Factor, \n",
    "                         Light, ATC_Advisory, Aircraft_Operator, Make_Model_Name, Crew_Size, Flight_Plan, Mission, Flight_Phase1, \n",
    "                         Route_In_Use, Airspace, Aircraft_Component, Manufacturer, Location_Of_Person, Location_In_Aircraft, \n",
    "                         Reporter_Organization, Function, Qualification, Human_Factors, Anomaly, Detector, When_Detected, \n",
    "                         Were_Passengers_Involved_In_Event, Contributing_Factors_Situations, Primary_Problem]\n",
    "\n",
    "        ## build the model\n",
    "        model = tf.estimator.DNNClassifier(hidden_units = [24, 12], feature_columns = feat_cols,\n",
    "                                           n_classes = 6, optimizer = tf.train.AdamOptimizer(learning_rate = 0.001))\n",
    "\n",
    "        ## train the model\n",
    "        model.train(input_fn = input_func, steps = 4000)\n",
    "\n",
    "\n",
    "        ## make predictions on the trial test data\n",
    "        eval_input = tf.estimator.inputs.pandas_input_fn(x = X_validation, shuffle = False)\n",
    "        prediction = list(model.predict(eval_input))\n",
    "        pred_label = [int(pred['class_ids']) for pred in prediction]\n",
    "        label_trial.append(pred_label)\n",
    "\n",
    "\n",
    "        ## make predictions on the test data\n",
    "        eval_input = tf.estimator.inputs.pandas_input_fn(x = X_test_sub, shuffle = False)\n",
    "        prediction = list(model.predict(eval_input))\n",
    "        pred_label = [int(pred['class_ids']) for pred in prediction]\n",
    "        label_test.append(pred_label)\n",
    "    \n",
    "    \n",
    "    #######################################################################\n",
    "    ################## Construct confusion matrix for DNN #################\n",
    "    #######################################################################\n",
    "    ensembel_trial_pred = []\n",
    "    for j in range(len(label_trial[0])):\n",
    "        x = np.zeros(shape = (len(label_trial), 1)) - 1\n",
    "        for i in range(len(label_trial)):\n",
    "            x[i] =  label_trial[i][j]\n",
    "        (values, counts) = np.unique(x, return_counts=True)\n",
    "        ind = np.argmax(counts)\n",
    "        ensembel_trial_pred.append((values[ind]))\n",
    "\n",
    "    ## DNN confusion matrix\n",
    "    DNN_confusion_matrix = confusion_matrix(Y_validation, ensembel_trial_pred)\n",
    "    model_NN = construct_classification_report(DNN_confusion_matrix)\n",
    "    \n",
    "    \n",
    "    #######################################################################\n",
    "    ######################### Building hybrid model #######################\n",
    "    #######################################################################\n",
    "    validation_list = list(Y_validation)\n",
    "    dict_count = {1: 0, 2: 0, 3: 0, 4: 0, 5: 0}\n",
    "    common_count = {1: 0, 2: 0, 3: 0, 4: 0, 5: 0}\n",
    "    for i in range(len(ensembel_trial_pred)):\n",
    "        if ensembel_trial_pred[i] == pred_label_SVM[i]:\n",
    "            dict_count[ensembel_trial_pred[i]] += 1\n",
    "            if ensembel_trial_pred[i] == validation_list[i]:\n",
    "                common_count[ensembel_trial_pred[i]] += 1\n",
    "                \n",
    "    print ('common count', common_count)\n",
    "    print ('dict_count', dict_count)\n",
    "                \n",
    "    accuracy = []\n",
    "    for (key, val) in dict_count.items():\n",
    "        common_acuracy = common_count[key]/dict_count[key]\n",
    "        print (key, val)\n",
    "        accuracy.append(common_acuracy)\n",
    "    accuracy = np.array(accuracy)\n",
    "    \n",
    "    print ('accuracy', accuracy)\n",
    "    \n",
    "    ## The predictions from the trained SVM model on the test data\n",
    "    pred_label_test_SVM = gs_clf.predict(X_test['Synopsis'])\n",
    "    SVM_prob = gs_clf.predict_proba(X_test['Synopsis'])\n",
    "\n",
    "    ## The predictions from deep learning ensemble on the test data\n",
    "    ensembel_test_pred = []\n",
    "    ensembel_prob = []\n",
    "    ensembel_prob_full = []\n",
    "    for j in range(len(label_test[0])):\n",
    "        x = np.zeros(shape = (len(label_test), 1)) - 1\n",
    "        for i in range(len(label_test)):\n",
    "            x[i] =  label_test[i][j]\n",
    "        (values, counts) = np.unique(x, return_counts=True)\n",
    "        #print (values, counts)\n",
    "        prob_tmp = np.zeros(shape = 5)\n",
    "\n",
    "        for j in range(len(values)):\n",
    "            prob_tmp[int(values[j]-1)] = counts[j]/10\n",
    "        ensembel_prob_full.append(prob_tmp)    \n",
    "        #print (prob_tmp)\n",
    "\n",
    "        ind = np.argmax(counts)\n",
    "        ensembel_test_pred.append((values[ind]))\n",
    "        ensembel_prob.append(counts[ind]/10)\n",
    "\n",
    "    ensembel_prob_full = np.array(ensembel_prob_full)\n",
    "    \n",
    "    \n",
    "    ## Blend the predictions from the two models\n",
    "    final_pred = []\n",
    "\n",
    "    total_unidentified = 0\n",
    "    proportion = []\n",
    "    for i in range(5):\n",
    "        proportion.append(model_NN[i][3] - accuracy[i]*dict_count[i + 1])\n",
    "        total_unidentified += model_NN[i][3] - accuracy[i]*dict_count[i + 1]\n",
    "    proportion = np.array(proportion/total_unidentified)\n",
    "    \n",
    "    print ('proportion of disagreed records', proportion)\n",
    "    proportion = proportion/0.2\n",
    "    \n",
    "\n",
    "    total_count = 0\n",
    "    count = 0\n",
    "    count_class = 0\n",
    "    ### Compute the confusion matrix from the validation dataset\n",
    "    from sklearn.preprocessing import normalize\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    confusion_validation_SVM = confusion_matrix(Y_validation, pred_label_SVM)\n",
    "    normed_matrix_SVM = normalize(confusion_validation_SVM, axis=0, norm='l1')\n",
    "    confusion_validation_DNN = confusion_matrix(Y_validation, ensembel_trial_pred)\n",
    "    normed_matrix_DNN = normalize(confusion_validation_DNN, axis=0, norm='l1')\n",
    "\n",
    "    count_SVM = 0\n",
    "    count_DNN = 0\n",
    "    count_SVM_correct = 0\n",
    "    count_DNN_correct = 0\n",
    "    for i in range(len(ensembel_test_pred)):\n",
    "        if ensembel_test_pred[i] == pred_label_test_SVM[i]:\n",
    "            final_pred.append(ensembel_test_pred[i])\n",
    "            if ensembel_test_pred[i] == 2:\n",
    "                count_class += 1\n",
    "        else:\n",
    "            total_count += 1\n",
    "\n",
    "            #################  Method 3  ###################\n",
    "            productSVM = np.multiply(SVM_prob[i], proportion)\n",
    "            productSVM = productSVM/np.sum(productSVM)\n",
    "            svm_prob_i = np.dot(normed_matrix_SVM, np.multiply(SVM_prob[i], proportion))\n",
    "            svm_prob_i = svm_prob_i/np.sum(svm_prob_i)\n",
    "            #print ('SVM prob: ---------------->  ', svm_prob_i)\n",
    "\n",
    "            productDNN = np.multiply(ensembel_prob_full[i], proportion)\n",
    "            productDNN = productDNN/np.sum(productDNN)\n",
    "            dnn_prob_i = np.dot(normed_matrix_DNN, productDNN)\n",
    "            #print ('DNN prob: ---------------->  ', np.sum(dnn_prob_i))\n",
    "\n",
    "            if np.max(svm_prob_i) > np.max(dnn_prob_i):\n",
    "                final_pred.append(np.argmax(svm_prob_i)+1)\n",
    "                if np.argmax(svm_prob_i) + 1 == Y_test[i]:\n",
    "                    count += 1\n",
    "                    count_SVM_correct += 1\n",
    "                count_SVM += 1\n",
    "            else:\n",
    "                final_pred.append(np.argmax(dnn_prob_i)+1)\n",
    "                if np.argmax(dnn_prob_i) + 1 == Y_test[i]:\n",
    "                    count += 1\n",
    "                    count_DNN_correct += 1\n",
    "                count_DNN += 1\n",
    "                \n",
    "    ### Report performance #####  \n",
    "    target_names = [str(i) for i in range(1, 6)]\n",
    "    print ('Classification report on Hybrid model:')\n",
    "    print(classification_report(Y_test, final_pred, target_names=target_names))\n",
    "    \n",
    "    print ('Classification report on SVM:')\n",
    "    print(classification_report(Y_test, pred_label_test_SVM, target_names=target_names))\n",
    "    \n",
    "    print ('Classification report on deep learning:')\n",
    "    print(classification_report(Y_test, ensembel_test_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline: Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', MultinomialNB(alpha = 1, fit_prior=True)),\n",
    "                    ])\n",
    "\n",
    "text_clf.fit(X_train['Synopsis'], Y_train)\n",
    "pred_label_NB = text_clf.predict(X_validation['Synopsis'])\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "target_names = [str(i) for i in range(1, 5+1)]\n",
    "print(classification_report(Y_validation, pred_label_NB, target_names=target_names))\n",
    "\n",
    "## DNN confusion matrix\n",
    "NB_confusion_matrix = confusion_matrix(Y_validation, pred_label_NB)\n",
    "print (NB_confusion_matrix)\n",
    "print ('Classification report: \\n', construct_classification_report(NB_confusion_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Support Vector Machine with Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words = 'english')),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', SGDClassifier(loss='epsilon_insensitive', penalty='l2',\n",
    "                                            alpha=1e-5, random_state=40,\n",
    "                                            max_iter=10, tol=None)),\n",
    "                    ])\n",
    "\n",
    "\n",
    "parameters = {'clf__loss': ['epsilon_insensitive', 'hinge', 'log', 'huber', 'modified_huber', 'perceptron', \n",
    "                            'squared_loss', 'squared_epsilon_insensitive', 'squared_hinge'],\n",
    "              'vect__ngram_range': [(1, 1), (1, 2), (1, 3), (1, 4)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'clf__alpha': (1e-2, 1e-3, 1e-4, 1e-5),\n",
    "              'clf__penalty': ['l1', 'l2', 'elasticnet'],\n",
    "              'clf__max_iter': (10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 120, 150)\n",
    " }\n",
    "\n",
    "optimal_parameters = {'clf__loss': ['modified_huber'],\n",
    "              'vect__ngram_range':  [(1, 2)],\n",
    "              'tfidf__use_idf': [True],\n",
    "              'clf__alpha': [1e-5],\n",
    "              'clf__penalty': ['elasticnet'],\n",
    "              'clf__max_iter': [80],\n",
    " }\n",
    "\n",
    "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)\n",
    "\n",
    "gs_clf.fit(X_train['Synopsis'], Y_train)\n",
    "pred_label_SVM = gs_clf.predict(X_validation['Synopsis'])\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "target_names = [str(i) for i in range(1, 6)]\n",
    "print(classification_report(Y_validation, pred_label_SVM, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Accuracy: ', np.sum(np.equal(Y_validation, pred_label_SVM).astype(int))/20367)\n",
    "print ('The best set of parameters is \\n', gs_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['Synopsis']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the performance metrics of two individual models on the trial test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_list = list(Y_validation)\n",
    "dict_count = {1: 0, 2: 0, 3: 0, 4: 0, 5: 0}\n",
    "common_count = {1: 0, 2: 0, 3: 0, 4: 0, 5: 0}\n",
    "for i in range(len(ensembel_trial_pred)):\n",
    "    if ensembel_trial_pred[i] == pred_label_SVM[i]:\n",
    "        dict_count[ensembel_trial_pred[i]] += 1\n",
    "        if ensembel_trial_pred[i] == validation_list[i]:\n",
    "            common_count[ensembel_trial_pred[i]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute the accuracy for the commonly records identified by the two classifiers\n",
    "print (dict_count)\n",
    "print (common_count)\n",
    "accuracy = []\n",
    "for (key, val) in dict_count.items():\n",
    "    common_acuracy = common_count[key]/dict_count[key]\n",
    "    print (key, val)\n",
    "    accuracy.append(common_acuracy)\n",
    "accuracy = np.array(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct hybrid model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The predictions from the trained SVM model on the test data\n",
    "pred_label_test_SVM = gs_clf.predict(X_test['Synopsis']) \n",
    "SVM_prob = gs_clf.predict_proba(X_test['Synopsis'])\n",
    "\n",
    "## The predictions from deep learning ensemble on the test data\n",
    "ensembel_test_pred = []\n",
    "ensembel_prob = []\n",
    "ensembel_prob_full = []\n",
    "for j in range(len(label_test[0])):\n",
    "    x = np.zeros(shape = (len(label_test), 1)) - 1\n",
    "    for i in range(len(label_test)):\n",
    "        x[i] =  label_test[i][j]\n",
    "    (values, counts) = np.unique(x, return_counts=True)\n",
    "    #print (values, counts)\n",
    "    prob_tmp = np.zeros(shape = 5)\n",
    "    \n",
    "    for j in range(len(values)):\n",
    "        prob_tmp[int(values[j]-1)] = counts[j]/10\n",
    "    ensembel_prob_full.append(prob_tmp)    \n",
    "    #print (prob_tmp)\n",
    "    \n",
    "    ind = np.argmax(counts)\n",
    "    ensembel_test_pred.append((values[ind]))\n",
    "    ensembel_prob.append(counts[ind]/10)\n",
    "    \n",
    "ensembel_prob_full = np.array(ensembel_prob_full)\n",
    "print (SVM_prob[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Blend the predictions from the two models\n",
    "final_pred = []\n",
    "\n",
    "model_NN = np.array([[0.66, 0.62, 0.62, 947],\n",
    "            [0.83, 0.90, 0.88, 1017],\n",
    "            [0.60, 0.49, 0.55, 988],\n",
    "            [0.84, 0.90, 0.87, 1034],\n",
    "            [0.79, 0.89, 0.85, 976],\n",
    "           ])\n",
    "model_SVM = np.array([[0.73, 0.57, 0.63, 947],\n",
    "             [0.85, 0.93, 0.89, 1017],\n",
    "             [0.66, 0.56, 0.61, 988],\n",
    "             [0.81, 0.89, 0.83, 1034],\n",
    "             [0.87, 0.92, 0.88, 976],\n",
    "            ])\n",
    "\n",
    "\n",
    "total_unidentified = 0\n",
    "proportion = []\n",
    "for i in range(5):\n",
    "    proportion.append(model_NN[i][3] - accuracy[i]*dict_count[i + 1])\n",
    "    total_unidentified += model_NN[i][3] - accuracy[i]*dict_count[i + 1]\n",
    "proportion = np.array(proportion/total_unidentified)\n",
    "proportion = proportion/0.2\n",
    "\n",
    "total_count = 0\n",
    "count = 0\n",
    "count_class = 0\n",
    "\n",
    "\n",
    "### Compute the confusion matrix from the validation dataset\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_validation_SVM = confusion_matrix(Y_validation, pred_label_SVM)\n",
    "normed_matrix_SVM = normalize(confusion_validation_SVM, axis=0, norm='l1')\n",
    "confusion_validation_DNN = confusion_matrix(Y_validation, ensembel_trial_pred)\n",
    "normed_matrix_DNN = normalize(confusion_validation_DNN, axis=0, norm='l1')\n",
    "\n",
    "count_SVM = 0\n",
    "count_DNN = 0\n",
    "count_SVM_correct = 0\n",
    "count_DNN_correct = 0\n",
    "for i in range(len(ensembel_test_pred)):\n",
    "    if ensembel_test_pred[i] == pred_label_test_SVM[i]:\n",
    "        final_pred.append(ensembel_test_pred[i])\n",
    "        if ensembel_test_pred[i] == 2:\n",
    "            count_class += 1\n",
    "    else:\n",
    "        total_count += 1\n",
    "        \n",
    "        ################ Method 1 ######################\n",
    "        #label_ensemble = int(ensembel_test_pred[i]-1)\n",
    "        #p1 = (model_NN[label_ensemble][3] - accuracy[label_ensemble]*dict_count[label_ensemble + 1]) /total_unidentified * model_NN[label_ensemble][1]*ensembel_prob[i]\n",
    "        \n",
    "        #label_SVM = int(pred_label_test_SVM[i]-1)\n",
    "        #p2 = (model_SVM[label_SVM][3] - accuracy[label_SVM]*dict_count[label_SVM + 1]) /total_unidentified * model_SVM[label_SVM][1]*SVM_prob[i, label_SVM]\n",
    "        \n",
    "        #if p1 > p2:\n",
    "        #    final_pred.append(label_ensemble + 1)\n",
    "        #    if label_ensemble + 1 == Y_test[i]:\n",
    "        #        count += 1\n",
    "        #else:\n",
    "        #    final_pred.append(label_SVM + 1)\n",
    "        #    if label_SVM + 1 == Y_test[i]:\n",
    "        #        count += 1\n",
    "        \n",
    "        \n",
    "        ############### Method 2 ######################\n",
    "        #svm_prob_i = np.multiply(np.multiply(SVM_prob[i], model_SVM[:,0]), model_NN[:,3] - np.multiply(accuracy, count_consis))/total_unidentified\n",
    "        #dnn_prob_i = np.multiply(np.multiply(ensembel_prob_full[i], model_NN[:,0]), model_NN[:, 3] - np.multiply(accuracy, count_consis))/total_unidentified\n",
    "        #svm_prob_i = svm_prob_i/np.sum(svm_prob_i)\n",
    "        #dnn_prob_i = dnn_prob_i/np.sum(svm_prob_i)\n",
    "        \n",
    "        \n",
    "        #print (svm_prob_i)\n",
    "        #print (np.argmax(svm_prob_i))\n",
    "        #print (dnn_prob_i)\n",
    "        \n",
    "        #if np.max(svm_prob_i) > np.max(dnn_prob_i):\n",
    "        #    final_pred.append(np.argmax(svm_prob_i)+1)\n",
    "        #    if np.argmax(svm_prob_i) + 1 == Y_test[i]:\n",
    "        #        count += 1\n",
    "        #else:\n",
    "        #    final_pred.append(np.argmax(dnn_prob_i)+1)\n",
    "        #    if np.argmax(dnn_prob_i) + 1 == Y_test[i]:\n",
    "        #        count += 1\n",
    "        \n",
    "        #################  Method 3  ###################\n",
    "        productSVM = np.multiply(SVM_prob[i], proportion)\n",
    "        productSVM = productSVM/np.sum(productSVM)\n",
    "        svm_prob_i = np.dot(normed_matrix_SVM, np.multiply(SVM_prob[i], proportion))\n",
    "        svm_prob_i = svm_prob_i/np.sum(svm_prob_i)\n",
    "        print ('SVM prob: ---------------->  ', svm_prob_i)\n",
    "        \n",
    "        productDNN = np.multiply(ensembel_prob_full[i], proportion)\n",
    "        productDNN = productDNN/np.sum(productDNN)\n",
    "        dnn_prob_i = np.dot(normed_matrix_DNN, productDNN)\n",
    "        print ('DNN prob: ---------------->  ', np.sum(dnn_prob_i))\n",
    "        \n",
    "        if np.max(svm_prob_i) > np.max(dnn_prob_i):\n",
    "            final_pred.append(np.argmax(svm_prob_i)+1)\n",
    "            if np.argmax(svm_prob_i) + 1 == Y_test[i]:\n",
    "                count += 1\n",
    "                count_SVM_correct += 1\n",
    "            count_SVM += 1\n",
    "        else:\n",
    "            final_pred.append(np.argmax(dnn_prob_i)+1)\n",
    "            if np.argmax(dnn_prob_i) + 1 == Y_test[i]:\n",
    "                count += 1\n",
    "                count_DNN_correct += 1\n",
    "            count_DNN += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_SVM/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_SVM_correct/count_SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_DNN_correct/count_DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Classification report on Hybrid model:')\n",
    "print(classification_report(Y_test, final_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Classification report on SVM:')\n",
    "print(classification_report(Y_test, pred_label_test_SVM, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Classification report on deep learning:')\n",
    "print(classification_report(Y_test, ensembel_test_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print ('Confusion matrix of hybrid model: \\n', confusion_matrix(Y_test, final_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print ('Confusion matrix of deep learning: \\n', confusion_matrix(Y_test, ensembel_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print ('Confusion matrix of support vector machine: \\n', confusion_matrix(Y_test, pred_label_test_SVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "% matplotlib inline\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    #plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45, fontsize = 14, fontweight ='medium')\n",
    "    plt.yticks(tick_marks, classes, fontsize = 14, fontweight ='medium')\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label', fontsize=18, fontweight = 'medium')\n",
    "    plt.xlabel('Predicted label', fontsize=18, fontweight = 'medium')\n",
    "    \n",
    "    \n",
    "#plt.subplot(131)   \n",
    "plot_confusion_matrix(confusion_matrix(Y_test, final_pred), classes=target_names)\n",
    "\n",
    "plt.savefig('hybrid.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(confusion_matrix(Y_test, ensembel_test_pred), classes=target_names)\n",
    "\n",
    "plt.savefig('dnn.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(confusion_matrix(Y_test, pred_label_test_SVM), classes=target_names)\n",
    "plt.savefig('svm.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct event-level decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_five = ['General Declared Emergency', 'General Physical Injury / Incapacitation', 'Flight Crew Inflight Shutdown', \n",
    "             'Air Traffic Control Separated Traffic', 'Aircraft Aircraft Damaged']\n",
    "\n",
    "rate_four = ['General Evacuated', 'Flight Crew Regained Aircraft Control', \n",
    "              'Air Traffic Control Issued Advisory / Alert', 'Flight Crew Landed in Emergency Condition',\n",
    "              'Flight Crew Landed In Emergency Condition']\n",
    "\n",
    "rate_three = ['General Work Refused', 'Flight Crew Became Reoriented', 'Flight Crew Diverted', \n",
    "             'Flight Crew Executed Go Around / Missed Approach', \n",
    "             'Flight Crew Overcame Equipment Problem', 'Flight Crew Rejected Takeoff', 'Flight Crew Took Evasive Action', \n",
    "             'Air Traffic Control Issued New Clearance']\n",
    "\n",
    "rate_two = ['General Maintenance Action', 'General Flight Cancelled / Delayed', \n",
    "              'General Release Refused / Aircraft Not Accepted', \n",
    "              'Flight Crew Overrode Automation', 'Flight Crew FLC Overrode Automation',\n",
    "              'Flight Crew Exited Penetrated Airspace', \n",
    "              'Flight Crew Requested ATC Assistance / Clarification', 'Flight Crew Landed As Precaution',\n",
    "              'Flight Crew Returned To Clearance', 'Flight Crew Returned To Departure Airport',\n",
    "              'Aircraft Automation Overrode Flight Crew']\n",
    "\n",
    "rate_one = ['General Police / Security Involved', 'Flight Crew Returned To Gate', 'Aircraft Equipment Problem Dissipated', \n",
    "            'unknown', 'Air Traffic Control Provided Assistance',\n",
    "            'General None Reported / Taken', 'Flight Crew FLC complied w / Automation / Advisory']\n",
    "\n",
    "X_five = []\n",
    "X_four = []\n",
    "X_three = []\n",
    "X_two = []\n",
    "X_one = []\n",
    "\n",
    "Y_five = []\n",
    "Y_four = []\n",
    "Y_three = []\n",
    "Y_two = []\n",
    "Y_one = []\n",
    "\n",
    "for i in range(len(X_train.index)):\n",
    "    print (X_train.index[i])\n",
    "    print (Y_train[X_train.index][i])\n",
    "    outcome = X_train['res'][i].tolist()\n",
    "    \n",
    "    if Y_train[X_train.index][i] == 5:\n",
    "        # find the location of event outcome in the corresponding risk category\n",
    "        item = set(outcome).intersection(rate_five)\n",
    "        item = list(item)\n",
    "        \n",
    "        if len(item) > 1:\n",
    "            item = item[0]\n",
    "            \n",
    "        item = \"\".join(item)\n",
    "        if item in rate_five:\n",
    "            print ('Find it')\n",
    "        label_five = rate_five.index(item) + 1\n",
    "        X_five.append(X_train['Synopsis'][i])\n",
    "        Y_five.append(label_five)\n",
    "        \n",
    "    elif Y_train[X_train.index][i] == 4:\n",
    "        # find the location of event outcome in the corresponding risk category\n",
    "        item = set(outcome).intersection(rate_four)\n",
    "        item = list(item)\n",
    "        \n",
    "        if len(item) > 1:\n",
    "            item = item[0]\n",
    "            \n",
    "        item = \"\".join(item)\n",
    "        if item in rate_four:\n",
    "            print ('Find it')\n",
    "        label_four = rate_four.index(item) + 1\n",
    "        X_four.append(X_train['Synopsis'][i])\n",
    "        Y_four.append(label_four)\n",
    "        \n",
    "    elif Y_train[X_train.index][i] == 3:\n",
    "        # find the location of event outcome in the corresponding risk category\n",
    "        item = set(outcome).intersection(rate_three)\n",
    "        item = list(item)\n",
    "        \n",
    "        if len(item) > 1:\n",
    "            item = item[0]\n",
    "            \n",
    "        item = \"\".join(item)\n",
    "        if item in rate_three:\n",
    "            print ('Find it')\n",
    "        label_three = rate_three.index(item) + 1\n",
    "        X_three.append(X_train['Synopsis'][i])\n",
    "        Y_three.append(label_three)\n",
    "        \n",
    "    elif Y_train[X_train.index][i] == 2:\n",
    "        # find the location of event outcome in the corresponding risk category\n",
    "        item = set(outcome).intersection(rate_two)\n",
    "        item = list(item)\n",
    "        \n",
    "        if len(item) > 1:\n",
    "            item = item[0]\n",
    "            \n",
    "        item = \"\".join(item)\n",
    "        if item in rate_two:\n",
    "            print ('Find it')\n",
    "        label_two = rate_two.index(item) + 1\n",
    "        X_two.append(X_train['Synopsis'][i])\n",
    "        Y_two.append(label_two)\n",
    "        \n",
    "    elif Y_train[X_train.index][i] == 1:\n",
    "        # find the location of event outcome in the corresponding risk category\n",
    "        item = set(outcome).intersection(rate_one)\n",
    "        item = list(item)\n",
    "        \n",
    "        if len(item) > 1:\n",
    "            item = item[0]\n",
    "            \n",
    "        item = \"\".join(item)\n",
    "        if item in rate_one:\n",
    "            print ('Find it')\n",
    "        label_one = rate_one.index(item) + 1\n",
    "        X_one.append(X_train['Synopsis'][i])\n",
    "        Y_one.append(label_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(X_test['Synopsis'])):\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    print (X_test['Synopsis'][i])\n",
    "    raw_document = pd.Series(X_test['Synopsis'][i])\n",
    "    print ('result:: --> ', final_pred[i])\n",
    "    if final_pred[i] == 1:\n",
    "        tfidf = tfidf_vectorizer.fit(X_one)\n",
    "        tfidf_matrix = tfidf.transform(X_one)\n",
    "        cosine = cosine_similarity(tfidf.transform(raw_document), tfidf_matrix)\n",
    "        \n",
    "        cosine_group = pd.DataFrame([cosine.flatten(), np.asarray(Y_one)])\n",
    "        cosine_group = cosine_group.transpose()\n",
    "        cosine_group.columns = ['Similarity', 'Outcome']\n",
    "        \n",
    "        group_event, group_event_counts = np.unique(Y_one, return_counts=True)\n",
    "        \n",
    "    elif final_pred[i] == 2:\n",
    "        tfidf = tfidf_vectorizer.fit(X_two)\n",
    "        tfidf_matrix = tfidf.transform(X_two)\n",
    "        cosine = cosine_similarity(tfidf.transform(raw_document), tfidf_matrix)\n",
    "                \n",
    "        cosine_group = pd.DataFrame([cosine.flatten(), np.asarray(Y_two)])\n",
    "        cosine_group = cosine_group.transpose()\n",
    "        cosine_group.columns = ['Similarity', 'Outcome']\n",
    "        \n",
    "        group_event, group_event_counts = np.unique(Y_two, return_counts=True)\n",
    "        \n",
    "    elif final_pred[i] == 3:\n",
    "        tfidf = tfidf_vectorizer.fit(X_three)\n",
    "        tfidf_matrix = tfidf.transform(X_three)\n",
    "        cosine = cosine_similarity(tfidf.transform(raw_document), tfidf_matrix)\n",
    "                \n",
    "        cosine_group = pd.DataFrame([cosine.flatten(), np.asarray(Y_three)])\n",
    "        cosine_group = cosine_group.transpose()\n",
    "        cosine_group.columns = ['Similarity', 'Outcome']\n",
    "        \n",
    "        group_event, group_event_counts = np.unique(Y_three, return_counts=True)\n",
    "        \n",
    "    elif final_pred[i] == 4:\n",
    "        tfidf = tfidf_vectorizer.fit(X_four)\n",
    "        tfidf_matrix = tfidf.transform(X_four)\n",
    "        cosine = cosine_similarity(tfidf.transform(raw_document), tfidf_matrix)\n",
    "                \n",
    "        cosine_group = pd.DataFrame([cosine.flatten(), np.asarray(Y_four)])\n",
    "        cosine_group = cosine_group.transpose()\n",
    "        cosine_group.columns = ['Similarity', 'Outcome']\n",
    "        \n",
    "        group_event, group_event_counts = np.unique(Y_four, return_counts=True)\n",
    "        \n",
    "    elif final_pred[i] == 5:\n",
    "        tfidf = tfidf_vectorizer.fit(X_five)\n",
    "        tfidf_matrix = tfidf.transform(X_five)\n",
    "        cosine = cosine_similarity(tfidf.transform(raw_document), tfidf_matrix)\n",
    "                \n",
    "        cosine_group = pd.DataFrame([cosine.flatten(), np.asarray(Y_five)])\n",
    "        cosine_group = cosine_group.transpose()\n",
    "        cosine_group.columns = ['Similarity', 'Outcome']\n",
    "        \n",
    "        group_event, group_event_counts = np.unique(Y_five, return_counts=True)\n",
    "    \n",
    "    event_prob = cosine_group.groupby(['Outcome'])['Similarity'].mean()\n",
    "    #event_prob = np.multiply(event_prob, group_event_counts/np.sum(group_event_counts))\n",
    "    norm_event_prob = event_prob/np.sum(event_prob)\n",
    "    \n",
    "    #print(group_event, group_event_counts)\n",
    "    print(norm_event_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
